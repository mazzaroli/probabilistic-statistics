{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matemáticas para Ciencias de Datos: Estadística Probabilistica\n",
    "\n",
    "En este articulo buscamos entender por que la probabilidad es tan importante en Ciencias de datos y el Machine Learning en general\n",
    "\n",
    "Para esto primero abordaremos el concepto de **probabilidad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 1: Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es la probabilidad?\n",
    "\n",
    "En que situaciones necesitamos usar la probabildiad? para eso iremos al concepto basico que nos induce a esto. Por ello nos haremos esta pregunta:\n",
    "\n",
    "**Que es la probabilidad?**\n",
    "\n",
    "**La probabilidad es la herramienta a la que recurrimos cuando hay incertdibumbre.**\n",
    "\n",
    "La incertidumbre surge a la hora de tomar decisiones cuando tenemos informacion incompleta. Los juegos de azar son el ejemplo perfecto, ya que no podemos predecir el resutlado en un juego de cartas o dados en un casino.\n",
    "\n",
    "Esto se debe a situaciones que tienen un grado de complejidad donde no es posible tener todas las variables suficiente, con todos los datos para predecir de que si lanzas los dados de cierta manera o juegas las cartas de cierta manera se terminara por dar un resultado.\n",
    "\n",
    "Podemos resumir lo anterior como **la incertidumbre es la toma de decisiones con informacion incompleta**.\n",
    "\n",
    ">\"El azar no es mas que la medida de nuestra ignorancia. \n",
    ">Los fenomenos fortuitos son, por definicion, aquellos cuyas leyes o causas simplemente ignoramos\"\n",
    ">\n",
    "> **Henri Poincaré**\n",
    "\n",
    "Por el hecho de que vivimos en una realidad donde la gran mayoria de nuestras decisiones las tomamos con informacion incompleta, los matematicos desarrollaron un esquema para cuantificar esta incertidumbre, dando asi el area de la Probabilidad en estadistica.\n",
    "\n",
    "**Probabilidad**\n",
    "\n",
    "En matematicos decimos que la probabilidad es el lenguaje y conjunto de herramientas matematicas que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Asi entendemos la propia palabra *probabilidad* como el area de investigacion, el concepto matematico puntual de la probabilidad tiene algunas sutilesas que conducen con frecuencia a confusiones.\n",
    "\n",
    "### Axiomas de la probabilidad\n",
    "\n",
    "Entender los elementos escenciales de la probabilidad\n",
    "\n",
    "Todo conjunto logico tiene que estar basado a un conjunto de axiomas, que significa que es un conjunto de setencias o afirmaciones, que no son derivables de algo mas fundamental, es decir que no requiere demostracion, por que lo asumimos como verdad.\n",
    "\n",
    "\n",
    "#### Sucesos\n",
    "\n",
    "Para comenzar definiremos los sucesos, ya que en cualquier libro de referencia, cualquier curso, o idioma donde estudies las matematicas de la probabilidad, encontraras que la definicion mas simple es que la probabilidad $(P)$, es la division de dos cantidades, numeros de sucesos exitodos sobre numero de sucesos totales.\n",
    "\n",
    "$\\displaystyle{P=\\underbrace{\\frac{N° \\text{sucesos exitosos}}{N° \\text{sucesos totales}}}_\\text{creencia del total}}$\n",
    "\n",
    "\n",
    "\n",
    "Ejemplo, cuando lanzas un dato, el resutlado son 6 posibiladades, cada una de esas posibilidades, es un suceso. \n",
    "Los sucesos totales son 6, pero cuando queremos saber cuales son las probabilidades de que el dado caiga en 2, como el 2 es un suceso de los seis, decimos que la probabilidad es de un sexto $({\\frac{1}{6}})$. \n",
    "\n",
    "Pero esto tiene una sutileza que nos conduce a dos escuelas de pensamientos en estadistica, la escuela Frecuentista y escuela Bayesiana.\n",
    "\n",
    "### Por que se divide el pensamiento estadistico?\n",
    "\n",
    "Cuando definimos que un sexto es la probabilidad de que un dado caiga en 2, aunque no parezca evidente, estamos asumiendo que todas las caras son igualmente probables. por lo tanto asumimos que todas las caras son igualmente probables. \n",
    "\n",
    "Lo mismo podemos definir con una moneda, donde tenemos dos posibles sucedos (cara o cruz), donde asumimos que la probabilidad de que caiga cara es de un medio $(\\frac{1}{2})$ y que caiga cruz tambien es de un medio.\n",
    "\n",
    "Pero que tan cierto es esto?\n",
    "\n",
    "Dependiendo de como interpretemos que es un suceso, o el numero de sucesos exitosos, podriamos hacer un ejercicio donde tiramos una moneda al aire 10 veces, y si la probabilidad es como la entendemos hasta ahora, de las 10 probabilidades, 5 deberian caer en cara y 5 en cruz.\n",
    "\n",
    "Haz el ejercicio y anota si realmente de las 10 veces te cayo 5 veces en cara o cruz. \n",
    "\n",
    "Probablemente no fue asi verdad, no?\n",
    "\n",
    "Aca es cuando diferenciamos las escuelas Frecuentistas y Bayesianas.\n",
    "\n",
    "#### Escuela Frecuentista\n",
    "\n",
    "Este pensamiento de probabilidad, nos explica que estos numeros que llamamos probabilidad (en esta ocacion puede ser la cara y la cruz), son numeros que solo se alcazan a la medida que haces infinitos lanzamientos de la moneda o dado, la proporcion del numero de lanzamientos exitosos y el numero de lanzamientos totales tiende a un medio, se acerca cada vez mas a 0.5. Como no hay forma de demostrar esto, por eso denominamos esto como un axioma.\n",
    "\n",
    "Las probabilidades sobre estos posibles sucesos que llamamos elementales, es por que son las ocurrencias mas basicas sobre un suceso probabilistico, donde una moneda solo tendria dos opciones, un dado seis opciones. Por esto debemos diferenciar sobre lo que es un suces elemental y un suceso\n",
    "\n",
    "**Suceso elemental:**\n",
    "\n",
    "Podemos entender a un suceso elemental como:\n",
    "> \"El resultado de lanzar un dado es 4\"\n",
    "\n",
    "Donde decimos que es elemental por que el resultado 4 solo se puede dar de una manera, que es que el daido caiga en 4 y nada mas.\n",
    "\n",
    "Suceso\n",
    "\n",
    "Un suceso en general se percibe como:\n",
    "> \"El suceso de lanzar un dado es par\"\n",
    "\n",
    "No es elemental porque es la union de varios sucesos elementales, donde el resultado puedo ser 2, 4 o 6.\n",
    "\n",
    "El uso de sucesos y sucesos elementales, se encuentran en el espacio muestral, que es el conjunto de todos los posibles resultados de un evento aleatorio. El dado tendria un espacio de seis, ya que tiene seis caras en la que puede caer, a cada uno de estos elementos del espacio muestral es lo que llamamos los sucesos elementales.\n",
    "\n",
    "En probabilidad entendequemos que todo evento aleatorio, viene escrito en un espacio muestral donde cada elemento son todas las posibles ocurrencias de ese evento aleatorio probabilistico, donde cada uno de los elementos le asignamos un numero que es una propiedad intrinseca. En el ejemplo de los dados le dariamos el elemento 1/6, ya que cada cara es igualmente probable y a esto lo asumimos como un axioma.\n",
    "\n",
    "<img src=\"./img/espacio muestral.PNG\" width=\"500\">\n",
    "\n",
    "Este tipo de probabilidad fundamental, sobre cada suceso elemental, de un espacio muestral, definimos a un sexto como la probabilidad de que caiga cada cara, a esto lo definimos como un axioma.\n",
    "\n",
    "En la vida real tendriamos que hacer infinitos intentos de esta situacion en particular, al ser un escenario abstracto, lo asumimos cierto dentro de un esquema axiomatica, es decir, la probabilidad hace parte de los axiomas y de esas propiedades intrinsecas de un problema aleatorio.\n",
    "\n",
    "La probabilidad que se le asigna a cada posible ocurrencia de un sistema aleatorio, posee varias propiedades que deben cumplirse para que el equema axiomatico tenga sentido:\n",
    "\n",
    "- $0 < P < 1$ Tienen que ser numeros que vayan del 0% al 100%, donde 0 es igual a 0% y 1 es igual a 100%.\n",
    "- $certeza \\rightarrow P=1$ Un elemento totalmente certero lo llamos con un 1.\n",
    "- $imposibilidad \\rightarrow p=0$ Un elemento imposiblemente certero lo llamos con un 0.\n",
    "- $disjuntos \\rightarrow P(A \\cup B)=P(A) + P(B)$ la probabilidad de dos elementos disjuntos sucedan, es la suma de las probabilidades de cada uno de estos.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "La posibilidad de que al arrojar un dado caiga en 2 y en 4 es la suma de la probabilidad de ambos sucesos, ya que no puede caer en 2 y en 4 al mismo tiempo\n",
    "\n",
    "Por lo que decimos que la probabilidad de que el dado caiga en 2 o en 4 es de dos sexto $(\\frac{2}{6})$, ya que son dos eventos posibles dentro de los seis eventos posibles.\n",
    "\n",
    "### Que es realmente la probabilidad?\n",
    "\n",
    "Para concluir debemos determinar que es realmente la probabilidad.\n",
    "\n",
    "Muchos dicen que es la creencia que tenemos sobre sucesos elementales. Ya que desde la perspectiva frecuentista, no tenemos forma de determinarlos realmente, asi que la probabilidad se incluye como un axioma en un conjunto de reglas que nos permite cuantificar la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad en Machine Learning\n",
    "\n",
    "En este módulo entenderemos como el Machine Learning y Ciencias de dato en general, como, el concepto o herramientas de probabilidad \n",
    "\n",
    "Recordemos que la probabilidad es un conjunto de herramientas y lenguaje matemático que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Pero... donde se encuentra la incertidumbre en el machine learning?\n",
    "\n",
    "La fuente de la incertidumbre se encuentra en: \n",
    "- Los datos.\n",
    "- Atributos del modelo.\n",
    "- Arquitectura del modelo.\n",
    "\n",
    "Recuerda que en la vida real, recolectar y hacer la medición de los datos es un proceso imperfecto, ya que todos los instrumentos de medición tienen un margen de error, que ya nos introduce parte de incertidumbre en los datos.\n",
    "\n",
    "En Machine learning hablamos que un modelo se alimenta de atributos, o variables predictoras, estas variables con frecuencia son subconjuntos reducidos del problema total y real, lo que hace que esta reducción de variables ya es otra capa de incertidumbre.\n",
    "\n",
    "En matemáticas un modelo se entiende como una representación simplificada de la realidad, y al ser una representación simplificada, ya induce otra capa más de incertidumbre.\n",
    "\n",
    "Estas tres son las principales fuentes de incertidumbre dentro del ML (Machine Learning), y por supuesto, estas fuentes de incertidumbre, son cuantificable con probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Clasificación\n",
    "\n",
    "Ejemplo, un clasificador de documento de texto, donde tenemos un conjunto de documentos de texto de distintas categorías, y nuestro modelo tiene que leer e identificar cual es el tema de conversación y ubicarlos en una categoría correspondiente de cada documento.\n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "Entonces, el modelo asignara cierta probabilidad a cada documento y así de determinara la clasificación de los documentos.\n",
    "\n",
    "A este modelo es lo que llamamos un clasificador probabilístico, y por definición del uso del propio modelo, ya damos uso a la probabilidad para identificar cual es la categoría más probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funcionamiento interno del modelo de Clasificador Probabilístico \n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "En nuestro caso, lo que hace el modelo es que tiene documentos, donde cada uno tiene etiquetas, la etiqueta sería la categoría o tema al que se refiere.\n",
    "\n",
    "#### Fase de Entrenamiento\n",
    "\n",
    "<img src=\"./img/entrenamiento.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "Los documentos tienen una función que extra los atributos, es decir, simplifica los elementos fundamentales del documento que me ayudaran a hacer la extracción de la categoría, a esto es lo que llamamos el **Extractor de Atributos**. \n",
    "\n",
    "Una vez realizada la extracción, el documento fue reducido a un conjunto de atributos (Vector), que se pasara como input al algoritmo de Machine Learning de clasificación. El cual sería un algoritmo de Machine Learning supervisado, porque le doy las etiquetas, donde el algoritmo leería los atributos y en base a esto, asignaría una etiqueta.\n",
    "\n",
    "Así es como entrenaríamos a un algoritmo de ML supervisado\n",
    "\n",
    "#### fase de Predicción\n",
    "\n",
    "Luego de la fase de entrenamiento, viene la fase de Predicción\n",
    "\n",
    "<img src=\"./img/prediccion.PNG\" width=\"500\">\n",
    "\n",
    "En el proceso donde el algoritmo aprendió a unir los atributos con las etiquetas correctas, ya podemos agarrar el modelo, entregarles documentos, en el cual usando el mismo proceso de extracción de atributos, para luego entrar en el modelo de clasificación y predecir la etiqueta.\n",
    "\n",
    "Entonces podríamos decir que tengo una tarea donde tengo que clasificar muchos documentos, pero como físicamente no se puedo por el tamaño y número de documentos, usaría mi algoritmo que está bien entrenado y el modelo me diría si el texto está hablando sobre política, deportes, etc\n",
    "\n",
    "> *La mayoría de modelos de clasificación funcionan con este esquema en general* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas las etapas del modelo probabilístico\n",
    "\n",
    "<img src=\"./img/etp modelos.PNG\" width=\"500\">\n",
    "\n",
    "Todas las etapas de un modelo, en ciertos aspectos involucra probabilidad.\n",
    "\n",
    "¿Pero como?\n",
    "\n",
    "#### Entrenamiento\n",
    "\n",
    "En la parte de entrenamiento, antes de pasar los documentos para extraer atributos e identificar la arquitectura, debemos escoger el modelo a usar\n",
    "\n",
    "- Diseño\n",
    "\n",
    "    El modelo a usar es lo que definimos por diseño, donde escogeremos si el modelo usaría probabilidad o no (No todos los modelos se apoyaran de la matemática probabilística, ya que no todos los modelos son probabilísticos)\n",
    "\n",
    "    En este caso usaremos de ejemplo el modelo de Naive Bayes, ya que es un modelo probabilístico, ya que el clasificador Naïve-Bayes aprende de los datos de entrenamiento y luego predice la clase de la instancia de prueba con la mayor probabilidad posterior.\n",
    "\n",
    "- Entrenamiento\n",
    "\n",
    "    Una vez elegido el diseño, tenemos que definir el entrenamiento.\n",
    "\n",
    "    El entrenamiento básicamente es que el modelo aprenda algo que sabrá mas adelante, que es el concepto de distribución de probabilidad.\n",
    "\n",
    "    Esto es una manera de saber que probabilidad asignarle a cada una de las posibles ocurrencias de los datos, donde nos encontramos con el esquema MLE (Maximum Likelihood Estimation)\n",
    "\n",
    "    **¿Qué es un parámetro de un modelo?** \n",
    "\n",
    "    En los modelos de aprendizaje automático, los parámetros son las variables que se estiman durante el proceso de entrenamiento con los conjuntos de datos. Por lo que sus valores no los indica manualmente el científico de datos, sino que son obtenidos.\n",
    "\n",
    "    **MLE**\n",
    "\n",
    "    En estadística, **la estimación de máxima verosimilitud** (MLE) es un método para estimar los parámetros de una distribución de probabilidad supuesta, dados algunos datos observados. Esto se logra maximizando una función de verosimilitud para que, bajo el modelo estadístico asumido, los datos observados sean los más probables.\n",
    "\n",
    "- Calibración\n",
    "\n",
    "    Luego llegaría la calibración, que es el ajuste del modelo a través de los hiperparametros, donde iremos calibrando el modelo para que el error del modelo sea cada vez más pequeño. \n",
    "\n",
    "    Los hiperparametros se encuentran por fuera del esquema de optimización, donde a veces se lo denomina como tuneo o calibración de hiperparametros, donde hay veces que se usan algoritmos de optimización bayesiana\n",
    "\n",
    "    **¿Qué es un hiper parámetro?**\n",
    "\n",
    "    Son valores que generalmente no puedo configurar con la optimización del modelo, por lo que suelen ser indicados por el científico de datos. El valor óptimo de un hiper parámetro no se puede conocer a priori para un problema dado. Por lo que se tiene que utilizar valores genéricos, reglas genéricas, los valores que han funcionado anteriormente en problemas similares o buscar la mejor opción mediante prueba y error. Siendo una buena opción buscar los hiper parámetros la validación cruzada.\n",
    "\n",
    "#### Predicción\n",
    "\n",
    "Luego del proceso de entrenamiento, viene el proceso de predicción, donde nos encontramos con la fase de interpretación del modelo\n",
    "\n",
    "- interpretación de la predicción\n",
    "\n",
    "    Independientemente de si el modelo es probabilístico o no, para la correcta interpretación  del modelo, la persona requiere de ciertos conceptos de probabilidad, ya que entender cómo funciona el cálculo de probabilidad del modelo, nos permite tener una interpretación correcta del mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 2: Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de probabilidad\n",
    "\n",
    "Profundizaremos sobre el concepto de probabilidad mismo, hablando de los distintos tipos de probabilidad\n",
    "\n",
    "Distintos tipos de situaciones tienen que cuantificar con conceptos adicionales sobre el concepto de probabilidad basico\n",
    "\n",
    "**Tipos de probabilidades**\n",
    "\n",
    "- Conjunta (Joint)\n",
    "\n",
    "- Marginal\n",
    "\n",
    "- Condicional $P(A|B)$\n",
    "\n",
    "Para explicar estos conceptos que suelen darse de manera muy abstracta, seran explicado con un juego de dos dados, estudiando el espacio muestral, donde la malla será la matriz por la que las filas y columnas representan el estado del primer dado y del segundo, teniendo un espacio muestral de 36 combinaciones\n",
    "\n",
    "<img src=\"./img/dados.PNG\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifiquemos las siguientes probabilidades y sus interpretaciones formulando la siguiente pregunta\n",
    "\n",
    "### Probabilidad Conjunta \n",
    "\n",
    "**Formula General:**\n",
    "\n",
    "$P(A\\cap B)$\n",
    "\n",
    "**¿Cual es la probabilidad de que ambos dados caigan en número par?**\n",
    "\n",
    "Esta pregunta se puede responder de forma sencilla, considerando, que el espacio muestral de los 2 dados y sus 36 posibilidades solo tenemos 9 sucesos exitosos que cumplan con el.\n",
    "\n",
    "<img src=\"./img/dosdadospar.PNG\" width='500'>\n",
    "\n",
    "Entonces decimos que los estados o sucesos exitosos son 9 posibilidades de 36, por la tanto la probabilidad quedaría como $\\frac{9}{36}$ y simplificado $\\frac{1}{4}$.\n",
    "\n",
    "- $P(par, par) = \\frac{9}{36} = \\frac{1}{4}$\n",
    "\n",
    "Esta probabilidad que corresponde a un suceso como tal, en realidad seria la unión de dos sucesos, es decir que el dado A haya caído en par y el dado B también haya caído en par, por lo tanto corresponde a dos sucesos separados, que es lo que llamamos una probabilidad conjunta (joint)\n",
    "\n",
    "- ${P(\\underbrace{\\underbrace{par}_{A}, \\underbrace{par}_{B}}_{\\text{Conjunta (joint)}}) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Una probabilidad conjunta es una probabilidad de dos o más sucesos, que calculamos haciendo un conteo directo al espacio muestral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Condicional \n",
    "\n",
    "$P(A|B)$\n",
    "\n",
    "\n",
    "**¿Cual es la probabilidad es de que un dado caiga en par, sabiendo que el dado B ya cayó en par?**\n",
    "\n",
    "Como ves, esta pregunta es ligeramente distinta a la pregunta anterior, ya que supone una condición previa que restringe el uso enteró del espacio muestral.\n",
    " \n",
    "Ahora solo tenemos que considerar las situaciones donde ya sabemos que B es par\n",
    "\n",
    "<img src=\"./img/bpar.PNG\" width='400'>\n",
    "\n",
    "La parte de la pregunta que nos dice \"el dado B ya cayó en par\", lo que hace es restringir el espacio muestral, teniendo antes 36 posibilidades a tener ahora solo 18 \n",
    "posibilidades.\n",
    "\n",
    "Entonces ahora que reducimos el espacio muestral, decimos ?cual es la probabilidad de que a caiga en par, sabiendo que b ya es par?.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}}}$\n",
    "\n",
    "Como esto impone una condición previa a este tipo de probabilidades con la barrita vertical [(\"|\" o \"tal que\")](https://es.wikipedia.org/wiki/Notaci%C3%B3n_matem%C3%A1tica#Expresiones), la definimos como Probabilidad Condicional.\n",
    "\n",
    "Habiendo ya restringido el espacio muestral, volveremos a realizar un conteo pero solo teniendo en cuenta el espacio restringido\n",
    "\n",
    "<img src=\"./img/bparR.PNG\" width='400'>\n",
    "\n",
    "El número de sucesos exitosos no cambio, sino solo el número de sucesos posibles por lo que el resultado con el espacio muestral reducido quedará tal que\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}} = \\frac{9}{18}}$\n",
    "\n",
    "Así vemos que tenemos dos probabilidades distintas, para dos preguntas distintas. Pero entonces nos preguntamos...\n",
    "\n",
    "**¿Cómo están relacionadas estas probabilidades?**\n",
    "\n",
    "Resulta que podemos formular la pregunta de cuál es la probabilidad de que B caiga en par, esto seria una probabilidad tradicional, ya que no ponemos ninguna condición, donde disponemos del espacio muestral completo teniendo las 36 opciones disponibles, pero... ¿cuántos de ésos sucesos corresponden al estado par?\n",
    "\n",
    "<img src=\"./img/bebesito fiu fiu.png\" width='400'>\n",
    "\n",
    "Entonces de la misma manera 36 opciones, donde tenemos 3 columnas con 6 sucesos que cumplen la premisa de la pregunta, dándonos 18 sobre 36\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(B=par)}_{\\text{EM completo}} = \\frac{18}{36}}$\n",
    "\n",
    "Ahora vemos que tenemos 3 probabilidades que fueron los resultados de 3 preguntas diferentes, pero podemos decir que **la probabilidad conjunta del suceso A y B, es igual a la probabilidad condicional de A dado B, por, la probabilidad de B**\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)}_{\\text{conjunta}} = \\underbrace{P(A | B)}_{\\text{condicional}}  * \\underbrace{P(B)}_{\\text{prob de B}}}$\n",
    "\n",
    "Esto no es un caso particular del ejemplo dado, sino, que es una fórmula general, **la Regla del Producto**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)=P(A|B)*P(B)}_{\\text{Regla del producto}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Marginal\n",
    "\n",
    "Es cuando se obtiene una probabilidad sencilla a partir de una probabilidad conjunta. Es decir cuando se tiene las probabilidades conjuntas de 2 sucesos y se quiere saber solo la probabilidad de que suceda el primer suceso independiente de lo que pasa con el otro, así eso se define como **la suma de todas la probabilidades conjuntas sobre los demás estados que no está considerando A**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A) = \\Sigma p(A,B)}_{Marginal}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Por medio del juego de los dados logramos definir de forma natural tres tipos de probabilidades\n",
    "\n",
    "Primero definimos la **Probabilidad Conjunta** que como vimos, es una probabilidad que considera la ocurrencia de diferentes, pero simultáneos eventos aleatorios.\n",
    "\n",
    "Luego esta se relaciona con la **Probabilidad Condicional** por medio de la Regla del Producto. Es importante aclarar que la probabilidad condicional **NO IMPLICA CAUSALIDAD**, es decir, que la probabilidad de que suceda A dado que sucedio B, no quiere decir que B sea la causa de A. Puede que en situaciones particulares ocurra, pero son dos conceptos diferentes.\n",
    "\n",
    "Con esto terminamos por decir que la **Probabilidad Marginal**, se obtienen haciendo sumas sobre ciertas variables aleatorias o ciertos sucesos sobre ciertas variables aleatorias dentro de la probabilidad conjunta. Siempre que hagamos sumas de probabilidades conjuntas y dejemos libre una de las variables, decimos que estamos obteniendo la probabilidad marginal de dicho evento aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de cálculo de probabilidad\n",
    "\n",
    "### Correlación de eventos\n",
    "\n",
    "Con un par de ejemplos sencillos, buscaremos ganar más intuición sobre el uso de la probabilidad, como calcularla y cómo debemos interpretarlas. Aprenderemos cómo la correlación de eventos nos permite descubrir y aplicar asociaciones lógicas entre distintos eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Juego de los Dados\n",
    "\n",
    "Para este ejemplo, tendremos en cuenta 3 eventos aleatorios:\n",
    "\n",
    "- $A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "- $B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "- $C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "Podríamos preguntarnos sobre la probabilidades de cada uno de estos eventos, sin condicionarlos a la ocurrencia previa de otro evento.\n",
    "\n",
    "Veamos la diferencia entre la probabilidad condicionada entre uno u otros sucesos, y las probabilidades sin condicionar para ver qué conceptos surgen.\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "Dados nuestros tres sucesos, consideraremos nuestras probabilidades de una manera sencilla.\n",
    "\n",
    "Veamos en primer lugar una probabilidad tradicional.\n",
    "\n",
    "Dónde queremos saber cual es la probabilidad de que suceda A, sin ninguna condición adicional. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    " \n",
    "Al ser un dado, sabemos que las posibilidades son 6, y que caiga en 4 es solo una de ellas, por lo tanto decimos que la probabilidad de A, es un sexto:\n",
    "\n",
    "$\\displaystyle{ P(A)=\\frac{1}{6} \\rightarrow{16.6\\%}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlación Positiva\n",
    "\n",
    "Que sucede, si ahora nos preguntamos, ? cual es la probabilidad de que suceda A, sabiendo que ya ha sucedido B?\n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Gramaticalmente esto lo traduciríamos a la vida real como el hecho de que lance una vez el dado, y cayó en un número par, provocando que nuestro espacio muestral se haya reducido, así que el número de posibilidades ya no es 6, sino 3, y de esas 3, solo una posibilidad corresponde a 4. \n",
    "\n",
    "$\\displaystyle{P(A|B)=\\frac{1}{3} \\rightarrow 33.3\\%}?$\n",
    "\n",
    "Por lo tanto decimos esta probabilidad condicional de que suceda A dado B, es mayor que la probabilidad tradicional de que suceda A, nos dice, que el hecho de que haya ocurrido B, aumenta la probabilidad de que ocurra A. Entonces es cuando decimos que los eventos A y B están **positivamente correlacionados**.\n",
    "\n",
    "Recordemos el concepto de Correlación de manera sencilla. La correlación es lo que nos dice como dos variables, eventos, sucesos o activos se relacionan el uno al otro. ([Profundizar conceptos de Correlacion. Tema 3, Capitulo VI](https://deepnote.com/@mazzaroli/Estadistica-Descriptiva-para-Ciencias-de-Datos-b8622ee2-5fb0-44f3-8791-96915665574e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlación Negativa\n",
    "\n",
    "Por otro lado también podemos preguntarnos sobre cuál es la probabilidad de que suceda A sabiendo que ya sucedió C. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "$P(A|C) = ?$\n",
    "\n",
    "Entonces, si ya sabemos que C sucedió, y el resultado es algún número impar, vemos que el espacio muestral se vio limitado a estas opciones: $\\{1,3,5\\}$, y resulta que A solo puede ser el número $\\{4\\}$.\n",
    "\n",
    "Como no hay una intersección entre el  $\\{1,3,5\\}$ y el elemento $\\{4\\}$, esto representa sucesos excluyentes, por lo tanto quedamos con un intersección o conjunto vacío.\n",
    "\n",
    "$\\{1,3,5\\} \\cap  \\{4\\} = \\varnothing$\n",
    "\n",
    "Por lo tanto decimos que la condición $C$ reduce el espacio muestral, diciéndonos que los sucesos posibles son 3, pero los sucesos exitosos son 0, dándonos una probabilidad de 0. Entonces decimos que la ocurrencia de $C$, redujo la ocurrencia de $A$, por lo tanto decimos que los eventos A y C están **negativamente correlacionados**\n",
    "\n",
    "Que la probabilidad nos de 0, osea que los elementos sean Excluyente, no quiere decir que los elementos sean independientes, sino, son altamente dependientes\n",
    "\n",
    "$Excluyente \\neq Independiente$\n",
    "\n",
    "**Conclusión del Juego de los dados**\n",
    "\n",
    "Con este sencillo ejercicio evidenciamos como cuando dos eventos pueden estar tanto positivamente y negativamente correlacionados. Y concluimos en:\n",
    "\n",
    "- Correlación Positiva es cuando la ocurrencia de un evento, **aumenta** la probabilidad de suceso de otro evento correlacionados\n",
    "\n",
    "- Correlación negativa es cuando la ocurrencia de un suceso **disminuye** la probabilidad de ocurrencia del otro.\n",
    "\n",
    "- Dos elementos excluyentes, no son independientes, por lo contrario, tienen correlación negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Juego de ruleta\n",
    "\n",
    "Para este ejemplo, usaremos el conocido juego de la ruleta que se pueden ver en muchos casinos, donde tendremos a dos jugadores, que cada uno apostará a cuatro números dentro de las ocho posibilidades dentro del rango del espacio muestral.\n",
    "\n",
    "<img src=\"./img/ruleta.png\" width=\"400\">\n",
    "\n",
    "El conjunto del $jugador\\,1$ lo llamaremos como conjunto $A$ y al del $jugador\\,2$ conjunto $B$, donde diferenciaremos los conjuntos de números que apostaron por el color rojo y azul.\n",
    "\n",
    "<img src=\"./img/ruleta color.png\" width=\"400\">\n",
    "\n",
    "Para facilitar el entendimiento del ejercicio, pasaremos a llamar los conjuntos de los jugadores a conjunto $A$ y $B$.\n",
    "\n",
    "$Jugador\\,1 \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 \\longrightarrow B = \\{5,6,7,8\\}$\n",
    "\n",
    "Aclarado esto, comenzamos el ejercicio preguntándonos:\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1?**\n",
    "\n",
    "En este caso, tanto los sucesos del $jugador\\,1$ y el $jugador\\,2$ son excluyentes, ya que sus apuestas son diferentes, por lo tanto no tienen un conjunto de intersecciones.\\\n",
    "Al analizar la probabilidad de que gane el $jugador\\,1$, está dada por las 8 casillas de la ruleta y de esas 8 posibilidades, solo 4 harán que gane el $jugador\\,1$.\n",
    "\n",
    "Quedando tal que:\n",
    "\n",
    "$P(A) = 4/8 = 1/2 = 50\\%$\n",
    "\n",
    "Pero... ¿Qué pasaría si ahora agregamos una condición?\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Vemos que la condición de restringir el espacio muestral completo, al conjunto B, redujo el número de eventos exitosos, teniendo como el número de eventos exitosos igual a 0, ya que al no existir un punto de intersección entre el conjunto A y B, no queda más que un conjunto vacío.\n",
    "\n",
    "$P(A|B) = \\frac{0}{4} = 0$\n",
    "\n",
    "Entonces evidenciamos un ejercicio de eventos excluyentes.\n",
    "\n",
    "____\n",
    "\n",
    "**¿Qué sucedería si presentamos una situación ligeramente diferente?**\n",
    "\n",
    "Donde el $Jugador\\,2$ cambie su apuesta al conjunto de números 4,5,6,7 y el $Jugador\\,1$ mantiene su conjunto del principio.\\\n",
    "Quedando los conjuntos tal que: \n",
    "\n",
    "$Jugador\\,1 = {1,2,3,4} \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 = {4,5,6,7} \\longrightarrow B = \\{4,5,6,7\\}$\n",
    "\n",
    "Recuerda que en general lo que elija el $Jugador\\,1$ y el $Jugador\\,2$, no tienen porque tener haber relación alguna entre sus apuestas, ya que cada uno está apostando a las posibilidades, donde cada uno eligió números a su propio criterio.\n",
    "\n",
    "En este caso logramos ver que si ocurre una intersección entre el conjunto del $Jugador\\,1$ y el nuevo conjunto del $Jugador\\,2$.\n",
    "\n",
    "<img src=\"./img/ruletaAyB.png\" width=\"500\">\n",
    "\n",
    "Entonces nos volvemos a preguntar...\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "Al igual que la vez anterior, **la condición B restringe el espacio muestral** a 4 de las 8 posibilidades, y la intersección entre el conjunto A y B solo ocurre en una posibilidad, por lo tanto la probabilidad de A dado B quedaría tal que:\n",
    "\n",
    "$P(A|B) = 1/4 = 25\\%$\n",
    "\n",
    "**¿Qué buscamos demostrar con este ejemplo?**\n",
    "\n",
    "Lo que queremos decir, es que gracias el conocimiento previo de saber que el $Jugador\\,2$ haya ganado, la probabilidad de que el $Jugador\\,1$ también ganará, es del 25%.\\\n",
    "A diferencia de antes, cuando las probabilidades de que el $Jugador\\,1$ gané, sabiendo que el $Jugador\\,2$ gano, eran del 0%.\n",
    "\n",
    "**Conclusiones del Juego de la Ruleta**\n",
    "\n",
    "- La ocurrencia del conocimiento previo de que el jugador 2 haya ganado, lo que provocó fue que se reduzca la probabilidad de que el jugador 1 haya ganado. Por lo tanto sabemos que la coincidencia de los eventos A y B representan eventos que se encuentran negativamente correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reto para practicar\n",
    "\n",
    "Sabemos que el jugador 1 mantiene los números que eligió al principio y jugador 2 cambio los suyos por el 2, 3, 6 y 7.\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1, sabiendo que el jugador 2 gano?**\n",
    "\n",
    "$jugador \\,1 = {1,2,3,4}$\\\n",
    "$jugador \\,2 = {2,3,6,7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos avanzados con probabilidad\n",
    "\n",
    "Continuaremos desarrollando ejemplos para \n",
    "\n",
    "### Paradoja ¿niño o niña?\n",
    "\n",
    "1. Una mujer tiene dos bebés donde el mayor es un varón.\n",
    "1. Una mujer tiene dos bebés donde uno de ellos es varón.\n",
    "\n",
    "Parecen parecidos pero no, en probabilidades cambia\n",
    "\n",
    "Tablero formulamos la siguiente pregunta\n",
    "\n",
    "Cual es la probabilidad de esta mujer tenga dos hijos varones.\n",
    "\n",
    "El fin del ejercicio es darse cuenta que la información de cada enunciado es diferente.\\\n",
    "Y para el cálculo de probabilidades de un ejerc q parece tan sencillo, primero deberemos calcular el espacio muestral, donde dibujaremos una matriz, donde en un eje se encontrarán los posibles géneros de un hijo, y en el otro eje los géneros del otro hijo.\n",
    "\n",
    "\n",
    "$\\underbrace{\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & MM  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}}_\\text{Espacio Muestral} \\hspace{3em} \\begin{matrix} F=Femenino \\\\ M=Masculino \\end{matrix}$\n",
    "\n",
    "Para dar un ejemplo, daremos que sin conocimiento previo nos preguntamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **¿Cual es la posibilidad de que una mujer tenga 2 hijos varones?**\n",
    "\n",
    "Tal cual lo presentamos sin ninguna condición, planteamos una probabilidad tradicional, y consideramos el espacio muestral completo, donde el número de eventos posibles es $4$, y el número de eventos exitosos es $1$.\n",
    "\n",
    "$\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & (MM)  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}$\n",
    "\n",
    "Y la probabilidad quedaría tal que:\n",
    "\n",
    "$\\displaystyle{P(MM) = \\frac{1}{4}=25\\%}$\n",
    "\n",
    "Por lo tanto, la probabilidad es solamente de $\\frac{1}{4}$ sin ninguna condición previa, donde esta probabilidad no representa ni al caso 1 ni 2 mencionados anteriormente, sino simplemente a una situación general donde no tenemos información previa al género de los hijos de dicha mujer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situación 1\n",
    "\n",
    "Pero qué sucedería si ahora imponemos la situación donde tenemos la información previa de que el mayor de los hijos es un varón. Entonces replantearíamos el ejercicio ahora de esta forma:\n",
    "\n",
    "**¿Cual es la probabilidad de que ambos hijos sean varones, sabiendo que el mayor es varón?**\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor Varón}) = ?$\n",
    "\n",
    "Con la información que tenemos podemos restringir el espacio muestral sabiendo que uno de los ejes (hijos) es el mayor, restringiendo el espacio muestral a solamente dos estados.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        FM & |MM|  \\\\\n",
    "        FF & |MF|  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Y de esta manera apreciamos que entre estos dos estados, solo uno satisface el enunciado. Quedando la probabilidad tal que:\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor M}) = \\frac{1}{2}=50\\%$\n",
    "\n",
    "Este resultado funciona bien con la situación 1, pero ¿Qué diferencia existe entre la situación 1 y 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situación 2\n",
    "\n",
    "Comparemos la sutileza gramatical entre la situación 1 y 2\n",
    "\n",
    "1. Una mujer tiene dos bebés donde <u>el mayor es un varón</u>.\n",
    "\n",
    "1. Una mujer tiene dos bebés donde <u>uno de ellos es varón</u>.\n",
    "\n",
    "La diferencia de decir entre el hijo mayor es varón, y uno de ellos es varón, implica que en realidad no sabemos cuál de ellos es varón.\\\n",
    "Aunque escape de la intuición, este pequeño cambio genera una diferencia en el espacio muestral, y lo demostraremos en la matriz para que se pueda apreciar el cambio del enunciado 2.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        [FM] & [MM]  \\\\\n",
    "        FF & [MF]  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "El hecho de decir que, uno de ellos es el varón, representan 3 posibles estados en el espacio muestral, porque en cada uno de los ejes, al menos uno de los hijos es varón.\n",
    "\n",
    "Cuando escribimos esto en la probabilidad, decimos, que la probabilidad de que ambos hijos sean varones, sabiendo que alguno de ellos es varón es de un estado exitoso sobre tres posibles estados:\n",
    "\n",
    "$\\displaystyle{P(MM \\, | \\, \\text{alguno M}) = \\frac{1}{3} = 33.\\hat{3}\\%}$\n",
    "\n",
    "Así podemos demostrar que las posibilidades de la situación 1 y 2 son diferentes, aunque parezcan igual y se debe a que la cantidad de información que contiene cada frase debido a esa sutileza gramatical es diferente y esto determina distintos resultados en probabilidad.\\\n",
    "Donde en la situación 1 la probabilidad de que los dos hijos sean varones es mayor, debido a la mayor cantidad de información dada en el enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de Monthy Hall\n",
    "\n",
    "<img src=\"https://m.media-amazon.com/images/M/MV5BNjUxNjMyZmUtYWE4Yi00Mzg2LWJkZmYtY2YyNjQ4ZmIyMGQwL2ltYWdlXkEyXkFqcGdeQXVyMTIxMDUyOTI@._V1_.jpg\" width=\"400\">\n",
    "\n",
    "En nuestra segunda paradoja trataremos el caso del programa de televisión *Let's make a deal*, dado por el conductor Monthy Hall, al que de se debe su nombre en probabilidad a esta paradoja, cómo, **El problema de Monthy Hall**  \n",
    "\n",
    "El ejercicio consistía en que el presentador le presentaba a un participante tres puertas, donde el participante tenía que elegir una entre las tres posibles puertas, donde detrás de dos puertas no había nada y solo en una había un premio.\n",
    "\n",
    "En una situación tradicional, el presentador le preguntaría al participante que elija una puerta, entonces nos preguntariamos\n",
    "\n",
    "**¿Cual es la posibilidad de que el participante elija la puerta correcta?**\n",
    "\n",
    "Siendo una probabilidad tradicional, dibujaremos el espacio muestral y veriamo todas las opciones, donde podremos ver que las tres opciones inicialmente, todas son igualmente probables, por lo tanto el participante piense que la probabilidad de elegir la puerta correcta sea de un tercio por la naturaleza de la situación.\n",
    "\n",
    "$\\displaystyle{\\begin{vmatrix} P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\\begin{matrix}  \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\ \\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\end{matrix}}$\n",
    "\n",
    "El truco del show era de que una vez que el participante eligiera una puerta, Monthy Hall abre una de las puertas (obviamente el presentador abriría una puerta sin recompensa, este era el punto de información adicional), luego de el presentador abriera la puerta sin recompensa, Monthy le preguntaría al participante, que ahora cuenta de información adicional (la puerta que abrió Monthy):\n",
    "\n",
    "Ahora que sabe que esta puerta no tenía recompensa, ¿mantiene la puerta que eligió, o prefiere cambiar de puerta?\n",
    "\n",
    "Entonces, la intuición a primera vista nos hace decir:\n",
    "\n",
    "¿Cual es la probabilidad de que cambie de puerta y gane? o ¿Cuál es la probabilidad de que mantenga la puerta y gane?\n",
    "\n",
    "Dibujemos el espacio muestral para representar esta idea de forma más visual:\n",
    "\n",
    "Este sería muestral antes de elegir una puerta\n",
    "\n",
    "$\n",
    "\\begin{vmatrix}P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Entonces digamos que elegimos la puerta 1, y el presentador abrió la puerta 3 ya que esta no tiene premio. El espacio muestral se nos restringiría a las situaciones donde la puerta 3 no tiene premios, quedando tal que\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{matrix}  \\\\\\longrightarrow 1/2 = 50\\% \\\\ \\longrightarrow 1/2 = 50\\% \\\\\\end{matrix}\n",
    "$\n",
    "\n",
    "Donde el número de estados posibles ya no es 3, sino 2, quedando la probabilidad de éxito de un medio.\\\n",
    "Entonces el razonamiento es que al tener 2 opciones donde solo 1 es de éxito y ambas tienen 50% de posibilidades de ser la correcta, el participante asume que da igual si mantiene la puerta o no, ya que en ambas tiene 50% de probabilidad de ganar. Este es el primer razonamiento que se podría hacer con la intuición natural de las probabilidades, pero la paradoja es que esto es **falso**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué cambian las probabilidades?\n",
    "\n",
    "Pero... ¿en realidad hay más probabilidades de ganar si cambio la puerta una vez que el presentador haya descartado una?\n",
    "\n",
    "La respuesta es sí! Porque resultan en situaciones distintas, al igual que en el ejemplo anterior, las probabilidades pueden verse modificadas cuando hay una cambio en la cantidad de información disponible a la hora de tomar una decisión, y este cambio de información fue el hecho de que el presentador haya abierto la puerta, modificando la probabilidad de éxito.\n",
    "\n",
    "Cambiemos el esquema mediante el cual ahora calcularemos nuestras nuevas probabilidades.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 0 \\\\ 0 \\\\ (🏆) \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 0 \\\\ (🏆) \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ (🏆) \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\hspace{1em}\n",
    "\\begin{matrix}   \\\\ 🏆\\rightarrow \\text{premio} \\\\ 🧔\\rightarrow \\text{participante} \\\\ 🎤\\rightarrow \\text{presentador} \\\\ \\end{matrix}\n",
    "$\n",
    "\n",
    "\n",
    "En este nuevo diagrama consideraremos dos columnas nuevas, donde representará el caso de si mantenemos la misma puerta que elegimos, o el caso en que cambiemos la puerta sabiendo la información adicional que nos dé el presentador.\n",
    "\n",
    "#### Situación 1\n",
    "\n",
    "Entonces supongamos que elegimos la puerta 1 y el presentador abriera la puerta 2, ya que la 3 tiene el premio, por lo tanto no la abriría.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🧔   \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤   \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ 🏆   \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\    \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "¿Que sucedería en esta situación?\n",
    "\n",
    "En esta situación, si me mantuviera en la puerta 1, que es la que elegimos al principio, no ganariamos el premio, pero si la cambiamos al a puerta 3, entonces si lo ganariamos. Quedando el diagrama tal que: \n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🧔 \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤 \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ 🏆 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ❌ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ✅ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Situación 2\n",
    "\n",
    "\n",
    "Sigamos usando el mismo razonamiento con el siguientes caso, donde abrimos la puerta 1, y el presentador tendrá que abrir la puerta 3, ya que en la puerta 2 se encuentra el premio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\  🧔  \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\  🏆  \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  🎤  \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\  ❌  \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\  ✅  \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Donde si me quedo con la puerta que elegí perdería, pero si la cambiara, ganaria.\n",
    "\n",
    "#### Situación 3\n",
    "\n",
    "Y en la ultima situacion, seria que abriera la puerta 1 que contiene el premio, y daria igual la puerta que abriera el presentador, ya que ni la puerta 2 y 3 tienen premio, siendo el único caso donde si mantengo la puerta ganaria.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🏆 \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤 \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ✅ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ❌ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Resolución\n",
    "\n",
    "Estas son las situaciones que tendríamos que tener en cuenta para saber ¿Cual es la probabilidad de ganar si me quedo con la misma puerta?\n",
    "\n",
    "Para saber esto veamos la matriz completa de todas las situaciones que vimos en el ejercicio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🧔 \\\\ 🧔 \\\\ 🏆 \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤 \\\\ 🏆 \\\\ 🎤 \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ 🏆 \\\\ 🎤 \\\\ 0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ❌ \\\\ ❌ \\\\ ✅ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ✅ \\\\ ✅ \\\\ ❌ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Si nos hubiéramos quedado con la misma puerta que elegimos al principio, solo en un caso hubiéramos tenido la probabilidad de ganar de los tres casos, quedando tal que:\n",
    "\n",
    "$\\displaystyle{P(🏆|Mantener)= \\frac{1}{3}}$\n",
    "\n",
    "Pero a diferencia de si hubiéramos cambiado de puerta luego de la información adicional dada por el presentador, tendríamos dos casos de eventos exitosos contra los tres que teníamos.\n",
    "\n",
    "$\\displaystyle{P(🏆|Cambiar)= \\frac{2}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Con estos dos ejercicios demostramos que el cálculo de probabilidades, no siempre es intuitivo y que hay tener cuidado al entender cual es el espacio muestral sobre cual estamos trabajando, dado que tengamos información adicional, o no, sobre cierta situación a la cual realizaremos el cálculo de probabilidades.\n",
    "\n",
    "Con estos dos ejercicios dimos el inicio para desarrollar nuestra intuición probabilística!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 3: Distribuciones de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es una distribución? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones discretas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando la distribución binomial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones continuas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo estimar una distribución?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 4: MLE (Maximum Likelihood Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es MLE? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de regrsión logística "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 5: Inferencia bayesiana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoremas de Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "642679db579c39e8c54388d8c67ee59d6b9479549eff357c7b1dae31a7261e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
