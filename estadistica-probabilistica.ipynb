{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matemáticas para Ciencias de Datos: Estadística Probabilistica\n",
    "\n",
    "En este articulo buscamos entender por que la probabilidad es tan importante en Ciencias de datos y el Machine Learning en general\n",
    "\n",
    "Para esto primero abordaremos el concepto de **probabilidad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 1: Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es la probabilidad?\n",
    "\n",
    "En que situaciones necesitamos usar la probabildiad? para eso iremos al concepto basico que nos induce a esto. Por ello nos haremos esta pregunta:\n",
    "\n",
    "**Que es la probabilidad?**\n",
    "\n",
    "**La probabilidad es la herramienta a la que recurrimos cuando hay incertdibumbre.**\n",
    "\n",
    "La incertidumbre surge a la hora de tomar decisiones cuando tenemos informacion incompleta. Los juegos de azar son el ejemplo perfecto, ya que no podemos predecir el resutlado en un juego de cartas o dados en un casino.\n",
    "\n",
    "Esto se debe a situaciones que tienen un grado de complejidad donde no es posible tener todas las variables suficiente, con todos los datos para predecir de que si lanzas los dados de cierta manera o juegas las cartas de cierta manera se terminara por dar un resultado.\n",
    "\n",
    "Podemos resumir lo anterior como **la incertidumbre es la toma de decisiones con informacion incompleta**.\n",
    "\n",
    ">\"El azar no es mas que la medida de nuestra ignorancia. \n",
    ">Los fenomenos fortuitos son, por definicion, aquellos cuyas leyes o causas simplemente ignoramos\"\n",
    ">\n",
    "> **Henri Poincaré**\n",
    "\n",
    "Por el hecho de que vivimos en una realidad donde la gran mayoria de nuestras decisiones las tomamos con informacion incompleta, los matematicos desarrollaron un esquema para cuantificar esta incertidumbre, dando asi el area de la Probabilidad en estadistica.\n",
    "\n",
    "**Probabilidad**\n",
    "\n",
    "En matematicos decimos que la probabilidad es el lenguaje y conjunto de herramientas matematicas que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Asi entendemos la propia palabra *probabilidad* como el area de investigacion, el concepto matematico puntual de la probabilidad tiene algunas sutilesas que conducen con frecuencia a confusiones.\n",
    "\n",
    "### Axiomas de la probabilidad\n",
    "\n",
    "Entender los elementos escenciales de la probabilidad\n",
    "\n",
    "Todo conjunto logico tiene que estar basado a un conjunto de axiomas, que significa que es un conjunto de setencias o afirmaciones, que no son derivables de algo mas fundamental, es decir que no requiere demostracion, por que lo asumimos como verdad.\n",
    "\n",
    "\n",
    "#### Sucesos\n",
    "\n",
    "Para comenzar definiremos los sucesos, ya que en cualquier libro de referencia, cualquier curso, o idioma donde estudies las matematicas de la probabilidad, encontraras que la definicion mas simple es que la probabilidad $(P)$, es la division de dos cantidades, numeros de sucesos exitodos sobre numero de sucesos totales.\n",
    "\n",
    "$\\displaystyle{P=\\underbrace{\\frac{N° \\text{sucesos exitosos}}{N° \\text{sucesos totales}}}_\\text{creencia del total}}$\n",
    "\n",
    "\n",
    "\n",
    "Ejemplo, cuando lanzas un dato, el resutlado son 6 posibiladades, cada una de esas posibilidades, es un suceso. \n",
    "Los sucesos totales son 6, pero cuando queremos saber cuales son las probabilidades de que el dado caiga en 2, como el 2 es un suceso de los seis, decimos que la probabilidad es de un sexto $({\\frac{1}{6}})$. \n",
    "\n",
    "Pero esto tiene una sutileza que nos conduce a dos escuelas de pensamientos en estadistica, la escuela Frecuentista y escuela Bayesiana.\n",
    "\n",
    "### Por que se divide el pensamiento estadistico?\n",
    "\n",
    "Cuando definimos que un sexto es la probabilidad de que un dado caiga en 2, aunque no parezca evidente, estamos asumiendo que todas las caras son igualmente probables. por lo tanto asumimos que todas las caras son igualmente probables. \n",
    "\n",
    "Lo mismo podemos definir con una moneda, donde tenemos dos posibles sucedos (cara o cruz), donde asumimos que la probabilidad de que caiga cara es de un medio $(\\frac{1}{2})$ y que caiga cruz tambien es de un medio.\n",
    "\n",
    "Pero que tan cierto es esto?\n",
    "\n",
    "Dependiendo de como interpretemos que es un suceso, o el numero de sucesos exitosos, podriamos hacer un ejercicio donde tiramos una moneda al aire 10 veces, y si la probabilidad es como la entendemos hasta ahora, de las 10 probabilidades, 5 deberian caer en cara y 5 en cruz.\n",
    "\n",
    "Haz el ejercicio y anota si realmente de las 10 veces te cayo 5 veces en cara o cruz. \n",
    "\n",
    "Probablemente no fue asi verdad, no?\n",
    "\n",
    "Aca es cuando diferenciamos las escuelas Frecuentistas y Bayesianas.\n",
    "\n",
    "#### Escuela Frecuentista\n",
    "\n",
    "Este pensamiento de probabilidad, nos explica que estos numeros que llamamos probabilidad (en esta ocacion puede ser la cara y la cruz), son numeros que solo se alcazan a la medida que haces infinitos lanzamientos de la moneda o dado, la proporcion del numero de lanzamientos exitosos y el numero de lanzamientos totales tiende a un medio, se acerca cada vez mas a 0.5. Como no hay forma de demostrar esto, por eso denominamos esto como un axioma.\n",
    "\n",
    "Las probabilidades sobre estos posibles sucesos que llamamos elementales, es por que son las ocurrencias mas basicas sobre un suceso probabilistico, donde una moneda solo tendria dos opciones, un dado seis opciones. Por esto debemos diferenciar sobre lo que es un suces elemental y un suceso\n",
    "\n",
    "**Suceso elemental:**\n",
    "\n",
    "Podemos entender a un suceso elemental como:\n",
    "> \"El resultado de lanzar un dado es 4\"\n",
    "\n",
    "Donde decimos que es elemental por que el resultado 4 solo se puede dar de una manera, que es que el daido caiga en 4 y nada mas.\n",
    "\n",
    "Suceso\n",
    "\n",
    "Un suceso en general se percibe como:\n",
    "> \"El suceso de lanzar un dado es par\"\n",
    "\n",
    "No es elemental porque es la union de varios sucesos elementales, donde el resultado puedo ser 2, 4 o 6.\n",
    "\n",
    "El uso de sucesos y sucesos elementales, se encuentran en el [espacio muestral](https://es.wikipedia.org/wiki/Espacio_muestral)  $(EM)$, **que es el conjunto de todos los posibles resultados de un evento aleatorio.** El dado tendria un espacio de seis, ya que tiene seis caras en la que puede caer, a cada uno de estos elementos del espacio muestral es lo que llamamos los sucesos elementales.\n",
    "\n",
    "En probabilidad entendequemos que todo evento aleatorio, viene escrito en un espacio muestral donde cada elemento son todas las posibles ocurrencias de ese evento aleatorio probabilistico, donde cada uno de los elementos le asignamos un numero que es una propiedad intrinseca. En el ejemplo de los dados le dariamos el elemento 1/6, ya que cada cara es igualmente probable y a esto lo asumimos como un axioma.\n",
    "\n",
    "<img src=\"./img/espacio muestral.PNG\" width=\"500\">\n",
    "\n",
    "Este tipo de probabilidad fundamental, sobre cada suceso elemental, de un espacio muestral, definimos a un sexto como la probabilidad de que caiga cada cara, a esto lo definimos como un axioma.\n",
    "\n",
    "En la vida real tendriamos que hacer infinitos intentos de esta situacion en particular, al ser un escenario abstracto, lo asumimos cierto dentro de un esquema axiomatica, es decir, la probabilidad hace parte de los axiomas y de esas propiedades intrinsecas de un problema aleatorio.\n",
    "\n",
    "La probabilidad que se le asigna a cada posible ocurrencia de un sistema aleatorio, posee varias propiedades que deben cumplirse para que el equema axiomatico tenga sentido:\n",
    "\n",
    "- $0 < P < 1$ Tienen que ser numeros que vayan del 0% al 100%, donde 0 es igual a 0% y 1 es igual a 100%.\n",
    "- $certeza \\rightarrow P=1$ Un elemento totalmente certero lo llamos con un 1.\n",
    "- $imposibilidad \\rightarrow p=0$ Un elemento imposiblemente certero lo llamos con un 0.\n",
    "- $disjuntos \\rightarrow P(A \\cup B)=P(A) + P(B)$ la probabilidad de dos elementos disjuntos sucedan, es la suma de las probabilidades de cada uno de estos.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "La posibilidad de que al arrojar un dado caiga en 2 y en 4 es la suma de la probabilidad de ambos sucesos, ya que no puede caer en 2 y en 4 al mismo tiempo\n",
    "\n",
    "Por lo que decimos que la probabilidad de que el dado caiga en 2 o en 4 es de dos sexto $(\\frac{2}{6})$, ya que son dos eventos posibles dentro de los seis eventos posibles.\n",
    "\n",
    "### Que es realmente la probabilidad?\n",
    "\n",
    "Para concluir debemos determinar que es realmente la probabilidad.\n",
    "\n",
    "Muchos dicen que es la creencia que tenemos sobre sucesos elementales. Ya que desde la perspectiva frecuentista, no tenemos forma de determinarlos realmente, asi que la probabilidad se incluye como un axioma en un conjunto de reglas que nos permite cuantificar la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad en Machine Learning\n",
    "\n",
    "En este módulo entenderemos como el Machine Learning y Ciencias de dato en general, como, el concepto o herramientas de probabilidad \n",
    "\n",
    "Recordemos que la probabilidad es un conjunto de herramientas y lenguaje matemático que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Pero... donde se encuentra la incertidumbre en el machine learning?\n",
    "\n",
    "La fuente de la incertidumbre se encuentra en: \n",
    "- Los datos.\n",
    "- Atributos del modelo.\n",
    "- Arquitectura del modelo.\n",
    "\n",
    "Recuerda que en la vida real, recolectar y hacer la medición de los datos es un proceso imperfecto, ya que todos los instrumentos de medición tienen un margen de error, que ya nos introduce parte de incertidumbre en los datos.\n",
    "\n",
    "En Machine learning hablamos que un modelo se alimenta de atributos, o variables predictoras, estas variables con frecuencia son subconjuntos reducidos del problema total y real, lo que hace que esta reducción de variables ya es otra capa de incertidumbre.\n",
    "\n",
    "En matemáticas un modelo se entiende como una representación simplificada de la realidad, y al ser una representación simplificada, ya induce otra capa más de incertidumbre.\n",
    "\n",
    "Estas tres son las principales fuentes de incertidumbre dentro del ML (Machine Learning), y por supuesto, estas fuentes de incertidumbre, son cuantificable con probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Clasificación\n",
    "\n",
    "Ejemplo, un clasificador de documento de texto, donde tenemos un conjunto de documentos de texto de distintas categorías, y nuestro modelo tiene que leer e identificar cual es el tema de conversación y ubicarlos en una categoría correspondiente de cada documento.\n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "Entonces, el modelo asignara cierta probabilidad a cada documento y así de determinara la clasificación de los documentos.\n",
    "\n",
    "A este modelo es lo que llamamos un clasificador probabilístico, y por definición del uso del propio modelo, ya damos uso a la probabilidad para identificar cual es la categoría más probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funcionamiento interno del modelo de Clasificador Probabilístico \n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "En nuestro caso, lo que hace el modelo es que tiene documentos, donde cada uno tiene etiquetas, la etiqueta sería la categoría o tema al que se refiere.\n",
    "\n",
    "#### Fase de Entrenamiento\n",
    "\n",
    "<img src=\"./img/entrenamiento.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "Los documentos tienen una función que extra los atributos, es decir, simplifica los elementos fundamentales del documento que me ayudaran a hacer la extracción de la categoría, a esto es lo que llamamos el **Extractor de Atributos**. \n",
    "\n",
    "Una vez realizada la extracción, el documento fue reducido a un conjunto de atributos (Vector), que se pasara como input al algoritmo de Machine Learning de clasificación. El cual sería un algoritmo de Machine Learning supervisado, porque le doy las etiquetas, donde el algoritmo leería los atributos y en base a esto, asignaría una etiqueta.\n",
    "\n",
    "Así es como entrenaríamos a un algoritmo de ML supervisado\n",
    "\n",
    "#### fase de Predicción\n",
    "\n",
    "Luego de la fase de entrenamiento, viene la fase de Predicción\n",
    "\n",
    "<img src=\"./img/prediccion.PNG\" width=\"500\">\n",
    "\n",
    "En el proceso donde el algoritmo aprendió a unir los atributos con las etiquetas correctas, ya podemos agarrar el modelo, entregarles documentos, en el cual usando el mismo proceso de extracción de atributos, para luego entrar en el modelo de clasificación y predecir la etiqueta.\n",
    "\n",
    "Entonces podríamos decir que tengo una tarea donde tengo que clasificar muchos documentos, pero como físicamente no se puedo por el tamaño y número de documentos, usaría mi algoritmo que está bien entrenado y el modelo me diría si el texto está hablando sobre política, deportes, etc\n",
    "\n",
    "> *La mayoría de modelos de clasificación funcionan con este esquema en general* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas las etapas del modelo probabilístico\n",
    "\n",
    "<img src=\"./img/etp modelos.PNG\" width=\"500\">\n",
    "\n",
    "Todas las etapas de un modelo, en ciertos aspectos involucra probabilidad.\n",
    "\n",
    "¿Pero como?\n",
    "\n",
    "#### Entrenamiento\n",
    "\n",
    "En la parte de entrenamiento, antes de pasar los documentos para extraer atributos e identificar la arquitectura, debemos escoger el modelo a usar\n",
    "\n",
    "- Diseño\n",
    "\n",
    "    El modelo a usar es lo que definimos por diseño, donde escogeremos si el modelo usaría probabilidad o no (No todos los modelos se apoyaran de la matemática probabilística, ya que no todos los modelos son probabilísticos)\n",
    "\n",
    "    En este caso usaremos de ejemplo el modelo de Naive Bayes, ya que es un modelo probabilístico, ya que el clasificador Naïve-Bayes aprende de los datos de entrenamiento y luego predice la clase de la instancia de prueba con la mayor probabilidad posterior.\n",
    "\n",
    "- Entrenamiento\n",
    "\n",
    "    Una vez elegido el diseño, tenemos que definir el entrenamiento.\n",
    "\n",
    "    El entrenamiento básicamente es que el modelo aprenda algo que sabrá mas adelante, que es el concepto de distribución de probabilidad.\n",
    "\n",
    "    Esto es una manera de saber que probabilidad asignarle a cada una de las posibles ocurrencias de los datos, donde nos encontramos con el esquema MLE (Maximum Likelihood Estimation)\n",
    "\n",
    "    **¿Qué es un parámetro de un modelo?** \n",
    "\n",
    "    En los modelos de aprendizaje automático, los parámetros son las variables que se estiman durante el proceso de entrenamiento con los conjuntos de datos. Por lo que sus valores no los indica manualmente el científico de datos, sino que son obtenidos.\n",
    "\n",
    "    **MLE**\n",
    "\n",
    "    En estadística, **la estimación de máxima verosimilitud** (MLE) es un método para estimar los parámetros de una distribución de probabilidad supuesta, dados algunos datos observados. Esto se logra maximizando una función de verosimilitud para que, bajo el modelo estadístico asumido, los datos observados sean los más probables.\n",
    "\n",
    "- Calibración\n",
    "\n",
    "    Luego llegaría la calibración, que es el ajuste del modelo a través de los hiperparametros, donde iremos calibrando el modelo para que el error del modelo sea cada vez más pequeño. \n",
    "\n",
    "    Los hiperparametros se encuentran por fuera del esquema de optimización, donde a veces se lo denomina como tuneo o calibración de hiperparametros, donde hay veces que se usan algoritmos de optimización bayesiana\n",
    "\n",
    "    **¿Qué es un hiper parámetro?**\n",
    "\n",
    "    Son valores que generalmente no puedo configurar con la optimización del modelo, por lo que suelen ser indicados por el científico de datos. El valor óptimo de un hiper parámetro no se puede conocer a priori para un problema dado. Por lo que se tiene que utilizar valores genéricos, reglas genéricas, los valores que han funcionado anteriormente en problemas similares o buscar la mejor opción mediante prueba y error. Siendo una buena opción buscar los hiper parámetros la validación cruzada.\n",
    "\n",
    "#### Predicción\n",
    "\n",
    "Luego del proceso de entrenamiento, viene el proceso de predicción, donde nos encontramos con la fase de interpretación del modelo\n",
    "\n",
    "- interpretación de la predicción\n",
    "\n",
    "    Independientemente de si el modelo es probabilístico o no, para la correcta interpretación  del modelo, la persona requiere de ciertos conceptos de probabilidad, ya que entender cómo funciona el cálculo de probabilidad del modelo, nos permite tener una interpretación correcta del mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 2: Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de probabilidad\n",
    "\n",
    "Profundizaremos sobre el concepto de probabilidad mismo, hablando de los distintos tipos de probabilidad\n",
    "\n",
    "Distintos tipos de situaciones tienen que cuantificar con conceptos adicionales sobre el concepto de probabilidad basico\n",
    "\n",
    "**Tipos de probabilidades**\n",
    "\n",
    "- Conjunta (Joint)\n",
    "\n",
    "- Marginal\n",
    "\n",
    "- Condicional $P(A|B)$\n",
    "\n",
    "Para explicar estos conceptos que suelen darse de manera muy abstracta, seran explicado con un juego de dos dados, estudiando el espacio muestral, donde la malla será la matriz por la que las filas y columnas representan el estado del primer dado y del segundo, teniendo un espacio muestral de 36 combinaciones\n",
    "\n",
    "<img src=\"./img/dados.PNG\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifiquemos las siguientes probabilidades y sus interpretaciones formulando la siguiente pregunta\n",
    "\n",
    "### Probabilidad Conjunta \n",
    "\n",
    "**Formula General:**\n",
    "\n",
    "$P(A\\cap B)$\n",
    "\n",
    "**¿Cual es la probabilidad de que ambos dados caigan en número par?**\n",
    "\n",
    "Esta pregunta se puede responder de forma sencilla, considerando, que el espacio muestral de los 2 dados y sus 36 posibilidades solo tenemos 9 sucesos exitosos que cumplan con el.\n",
    "\n",
    "<img src=\"./img/dosdadospar.PNG\" width='500'>\n",
    "\n",
    "Entonces decimos que los estados o sucesos exitosos son 9 posibilidades de 36, por la tanto la probabilidad quedaría como $\\frac{9}{36}$ y simplificado $\\frac{1}{4}$.\n",
    "\n",
    "- $\\displaystyle{P(par, par) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Esta probabilidad que corresponde a un suceso como tal, en realidad seria la unión de dos sucesos, es decir que el dado A haya caído en par y el dado B también haya caído en par, por lo tanto corresponde a dos sucesos separados, que es lo que llamamos una probabilidad conjunta (joint)\n",
    "\n",
    "- $\\displaystyle{P(\\underbrace{\\underbrace{par}_{A}, \\underbrace{par}_{B}}_{\\text{Conjunta (joint)}}) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Una probabilidad conjunta es una probabilidad de dos o más sucesos, que calculamos haciendo un conteo directo al espacio muestral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Condicional \n",
    "\n",
    "$P(A|B)$\n",
    "\n",
    "\n",
    "**¿Cual es la probabilidad es de que un dado caiga en par, sabiendo que el dado B ya cayó en par?**\n",
    "\n",
    "Como ves, esta pregunta es ligeramente distinta a la pregunta anterior, ya que supone una condición previa que restringe el uso enteró del espacio muestral.\n",
    " \n",
    "Ahora solo tenemos que considerar las situaciones donde ya sabemos que B es par\n",
    "\n",
    "<img src=\"./img/bpar.PNG\" width='400'>\n",
    "\n",
    "La parte de la pregunta que nos dice \"el dado B ya cayó en par\", lo que hace es restringir el espacio muestral, teniendo antes 36 posibilidades a tener ahora solo 18 \n",
    "posibilidades.\n",
    "\n",
    "Entonces ahora que reducimos el espacio muestral, decimos ?cual es la probabilidad de que a caiga en par, sabiendo que b ya es par?.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}}}$\n",
    "\n",
    "Como esto impone una condición previa a este tipo de probabilidades con la barrita vertical [(\"|\" o \"tal que\")](https://es.wikipedia.org/wiki/Notaci%C3%B3n_matem%C3%A1tica#Expresiones), la definimos como Probabilidad Condicional.\n",
    "\n",
    "Habiendo ya restringido el espacio muestral, volveremos a realizar un conteo pero solo teniendo en cuenta el espacio restringido\n",
    "\n",
    "<img src=\"./img/bparR.PNG\" width='400'>\n",
    "\n",
    "El número de sucesos exitosos no cambio, sino solo el número de sucesos posibles por lo que el resultado con el espacio muestral reducido quedará tal que\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}} = \\frac{9}{18}}$\n",
    "\n",
    "Así vemos que tenemos dos probabilidades distintas, para dos preguntas distintas. Pero entonces nos preguntamos...\n",
    "\n",
    "**¿Cómo están relacionadas estas probabilidades?**\n",
    "\n",
    "Resulta que podemos formular la pregunta de cuál es la probabilidad de que B caiga en par, esto seria una probabilidad tradicional, ya que no ponemos ninguna condición, donde disponemos del espacio muestral completo teniendo las 36 opciones disponibles, pero... ¿cuántos de ésos sucesos corresponden al estado par?\n",
    "\n",
    "<img src=\"./img/bebesito fiu fiu.png\" width='400'>\n",
    "\n",
    "Entonces de la misma manera 36 opciones, donde tenemos 3 columnas con 6 sucesos que cumplen la premisa de la pregunta, dándonos 18 sobre 36\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(B=par)}_{\\text{EM completo}} = \\frac{18}{36}}$\n",
    "\n",
    "Ahora vemos que tenemos 3 probabilidades que fueron los resultados de 3 preguntas diferentes, pero podemos decir que **la probabilidad conjunta del suceso A y B, es igual a la probabilidad condicional de A dado B, por, la probabilidad de B**\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)}_{\\text{conjunta}} = \\underbrace{P(A | B)}_{\\text{condicional}}  * \\underbrace{P(B)}_{\\text{prob de B}}}$\n",
    "\n",
    "Esto no es un caso particular del ejemplo dado, sino, que es una fórmula general, **la Regla del Producto**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)=P(A|B)*P(B)}_{\\text{Regla del producto}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Marginal\n",
    "\n",
    "Es cuando se obtiene una probabilidad sencilla a partir de una probabilidad conjunta. Es decir cuando se tiene las probabilidades conjuntas de 2 sucesos y se quiere saber solo la probabilidad de que suceda el primer suceso independiente de lo que pasa con el otro, así eso se define como **la suma de todas la probabilidades conjuntas sobre los demás estados que no está considerando A**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A) = \\Sigma p(A,B)}_{Marginal}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Por medio del juego de los dados logramos definir de forma natural tres tipos de probabilidades\n",
    "\n",
    "Primero definimos la **Probabilidad Conjunta** que como vimos, es una probabilidad que considera la ocurrencia de diferentes, pero simultáneos eventos aleatorios.\n",
    "\n",
    "Luego esta se relaciona con la **Probabilidad Condicional** por medio de la Regla del Producto. Es importante aclarar que la probabilidad condicional **NO IMPLICA CAUSALIDAD**, es decir, que la probabilidad de que suceda A dado que sucedio B, no quiere decir que B sea la causa de A. Puede que en situaciones particulares ocurra, pero son dos conceptos diferentes.\n",
    "\n",
    "Con esto terminamos por decir que la **Probabilidad Marginal**, se obtienen haciendo sumas sobre ciertas variables aleatorias o ciertos sucesos sobre ciertas variables aleatorias dentro de la probabilidad conjunta. Siempre que hagamos sumas de probabilidades conjuntas y dejemos libre una de las variables, decimos que estamos obteniendo la probabilidad marginal de dicho evento aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de cálculo de probabilidad\n",
    "\n",
    "### Correlación de eventos\n",
    "\n",
    "Con un par de ejemplos sencillos, buscaremos ganar más intuición sobre el uso de la probabilidad, como calcularla y cómo debemos interpretarlas. Aprenderemos cómo la correlación de eventos nos permite descubrir y aplicar asociaciones lógicas entre distintos eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Juego de los Dados\n",
    "\n",
    "Para este ejemplo, tendremos en cuenta 3 eventos aleatorios:\n",
    "\n",
    "- $A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "- $B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "- $C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "Podríamos preguntarnos sobre la probabilidades de cada uno de estos eventos, sin condicionarlos a la ocurrencia previa de otro evento.\n",
    "\n",
    "Veamos la diferencia entre la probabilidad condicionada entre uno u otros sucesos, y las probabilidades sin condicionar para ver qué conceptos surgen.\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "Dados nuestros tres sucesos, consideraremos nuestras probabilidades de una manera sencilla.\n",
    "\n",
    "Veamos en primer lugar una probabilidad tradicional.\n",
    "\n",
    "Dónde queremos saber cual es la probabilidad de que suceda A, sin ninguna condición adicional. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    " \n",
    "Al ser un dado, sabemos que las posibilidades son 6, y que caiga en 4 es solo una de ellas, por lo tanto decimos que la probabilidad de A, es un sexto:\n",
    "\n",
    "$\\displaystyle{ P(A)=\\frac{1}{6} \\rightarrow{16.6\\%}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlación Positiva\n",
    "\n",
    "Que sucede, si ahora nos preguntamos, ? cual es la probabilidad de que suceda A, sabiendo que ya ha sucedido B?\n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Gramaticalmente esto lo traduciríamos a la vida real como el hecho de que lance una vez el dado, y cayó en un número par, provocando que nuestro espacio muestral se haya reducido, así que el número de posibilidades ya no es 6, sino 3, y de esas 3, solo una posibilidad corresponde al evento exitoso. \n",
    "\n",
    "$\\displaystyle{P(A|B)=\\frac{1}{3} \\rightarrow 33.3\\%}$\n",
    "\n",
    "Por lo tanto decimos esta probabilidad condicional de que suceda A dado B, es mayor que la probabilidad tradicional de que suceda A, nos dice, que el hecho de que haya ocurrido B, aumenta la probabilidad de que ocurra A. Entonces es cuando decimos que los eventos A y B están **positivamente correlacionados**.\n",
    "\n",
    "Recordemos el concepto de Correlación de manera sencilla. La correlación es lo que nos dice como dos variables, eventos, sucesos o activos se relacionan el uno al otro. ([Profundizar conceptos de Correlacion. Tema 3, Capitulo VI](https://deepnote.com/@mazzaroli/Estadistica-Descriptiva-para-Ciencias-de-Datos-b8622ee2-5fb0-44f3-8791-96915665574e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlación Negativa\n",
    "\n",
    "Por otro lado también podemos preguntarnos sobre cuál es la probabilidad de que suceda A sabiendo que ya sucedió C. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "$P(A|C) = ?$\n",
    "\n",
    "Entonces, si ya sabemos que C sucedió, y el resultado es algún número impar, vemos que el espacio muestral se vio limitado a estas opciones: $\\{1,3,5\\}$, y resulta que A solo puede ser el número $\\{4\\}$.\n",
    "\n",
    "Como no hay una intersección entre el  $\\{1,3,5\\}$ y el elemento $\\{4\\}$, esto representa sucesos excluyentes, por lo tanto quedamos con un intersección o conjunto vacío.\n",
    "\n",
    "$\\{1,3,5\\} \\cap  \\{4\\} = \\varnothing$\n",
    "\n",
    "Por lo tanto decimos que la condición $C$ reduce el espacio muestral, diciéndonos que los sucesos posibles son 3, pero los sucesos exitosos son 0, dándonos una probabilidad de 0. Entonces decimos que la ocurrencia de $C$, redujo la ocurrencia de $A$, por lo tanto decimos que los eventos A y C están **negativamente correlacionados**\n",
    "\n",
    "Que la probabilidad nos de 0, osea que los elementos sean Excluyente, no quiere decir que los elementos sean independientes, sino, son altamente dependientes\n",
    "\n",
    "$Excluyente \\neq Independiente$\n",
    "\n",
    "**Conclusión del Juego de los dados**\n",
    "\n",
    "Con este sencillo ejercicio evidenciamos como cuando dos eventos pueden estar tanto positivamente y negativamente correlacionados. Y concluimos en:\n",
    "\n",
    "- Correlación Positiva es cuando la ocurrencia de un evento, **aumenta** la probabilidad de suceso de otro evento correlacionados\n",
    "\n",
    "- Correlación negativa es cuando la ocurrencia de un suceso **disminuye** la probabilidad de ocurrencia del otro.\n",
    "\n",
    "- Dos elementos excluyentes, no son independientes, por lo contrario, tienen correlación negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Juego de ruleta\n",
    "\n",
    "Para este ejemplo, usaremos el conocido juego de la ruleta que se pueden ver en muchos casinos, donde tendremos a dos jugadores, que cada uno apostará a cuatro números dentro de las ocho posibilidades dentro del rango del espacio muestral.\n",
    "\n",
    "<img src=\"./img/ruleta.png\" width=\"400\">\n",
    "\n",
    "El conjunto del $jugador\\,1$ lo llamaremos como conjunto $A$ y al del $jugador\\,2$ conjunto $B$, donde diferenciaremos los conjuntos de números que apostaron por el color rojo y azul.\n",
    "\n",
    "<img src=\"./img/ruleta color.png\" width=\"400\">\n",
    "\n",
    "Para facilitar el entendimiento del ejercicio, pasaremos a llamar los conjuntos de los jugadores a conjunto $A$ y $B$.\n",
    "\n",
    "$Jugador\\,1 \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 \\longrightarrow B = \\{5,6,7,8\\}$\n",
    "\n",
    "Aclarado esto, comenzamos el ejercicio preguntándonos:\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1?**\n",
    "\n",
    "En este caso, tanto los sucesos del $jugador\\,1$ y el $jugador\\,2$ son excluyentes, ya que sus apuestas son diferentes, por lo tanto no tienen un conjunto de intersecciones.\\\n",
    "Al analizar la probabilidad de que gane el $jugador\\,1$, está dada por las 8 casillas de la ruleta y de esas 8 posibilidades, solo 4 harán que gane el $jugador\\,1$.\n",
    "\n",
    "Quedando tal que:\n",
    "\n",
    "$P(A) = 4/8 = 1/2 = 50\\%$\n",
    "\n",
    "Pero... ¿Qué pasaría si ahora agregamos una condición?\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Vemos que la condición de restringir el espacio muestral completo, al conjunto B, redujo el número de eventos exitosos, teniendo como el número de eventos exitosos igual a 0, ya que al no existir un punto de intersección entre el conjunto A y B, no queda más que un conjunto vacío.\n",
    "\n",
    "$P(A|B) = \\frac{0}{4} = 0$\n",
    "\n",
    "Entonces evidenciamos un ejercicio de eventos excluyentes.\n",
    "\n",
    "____\n",
    "\n",
    "**¿Qué sucedería si presentamos una situación ligeramente diferente?**\n",
    "\n",
    "Donde el $Jugador\\,2$ cambie su apuesta al conjunto de números 4,5,6,7 y el $Jugador\\,1$ mantiene su conjunto del principio.\\\n",
    "Quedando los conjuntos tal que: \n",
    "\n",
    "$Jugador\\,1 = {1,2,3,4} \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 = {4,5,6,7} \\longrightarrow B = \\{4,5,6,7\\}$\n",
    "\n",
    "Recuerda que en general lo que elija el $Jugador\\,1$ y el $Jugador\\,2$, no tienen porque tener haber relación alguna entre sus apuestas, ya que cada uno está apostando a las posibilidades, donde cada uno eligió números a su propio criterio.\n",
    "\n",
    "En este caso logramos ver que si ocurre una intersección entre el conjunto del $Jugador\\,1$ y el nuevo conjunto del $Jugador\\,2$.\n",
    "\n",
    "<img src=\"./img/ruletaAyB.png\" width=\"500\">\n",
    "\n",
    "Entonces nos volvemos a preguntar...\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "Al igual que la vez anterior, **la condición B restringe el espacio muestral** a 4 de las 8 posibilidades, y la intersección entre el conjunto A y B solo ocurre en una posibilidad, por lo tanto la probabilidad de A dado B quedaría tal que:\n",
    "\n",
    "$P(A|B) = 1/4 = 25\\%$\n",
    "\n",
    "**¿Qué buscamos demostrar con este ejemplo?**\n",
    "\n",
    "Lo que queremos decir, es que gracias el conocimiento previo de saber que el $Jugador\\,2$ haya ganado, la probabilidad de que el $Jugador\\,1$ también ganará, es del 25%.\\\n",
    "A diferencia de antes, cuando las probabilidades de que el $Jugador\\,1$ gané, sabiendo que el $Jugador\\,2$ gano, eran del 0%.\n",
    "\n",
    "**Conclusiones del Juego de la Ruleta**\n",
    "\n",
    "- La ocurrencia del conocimiento previo de que el jugador 2 haya ganado, lo que provocó fue que se reduzca la probabilidad de que el jugador 1 haya ganado. Por lo tanto sabemos que la coincidencia de los eventos A y B representan eventos que se encuentran negativamente correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reto para practicar\n",
    "\n",
    "Sabemos que el jugador 1 mantiene los números que eligió al principio y jugador 2 cambio los suyos por el 2, 3, 6 y 7.\n",
    "\n",
    "**¿Cual es la probabilidad de que gane el jugador 1, sabiendo que el jugador 2 gano?**\n",
    "\n",
    "$jugador \\,1 = {1,2,3,4}$\\\n",
    "$jugador \\,2 = {2,3,6,7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos avanzados con probabilidad\n",
    "\n",
    "Continuaremos desarrollando ejemplos para \n",
    "\n",
    "### Paradoja ¿niño o niña?\n",
    "\n",
    "1. Una mujer tiene dos bebés donde el mayor es un varón.\n",
    "1. Una mujer tiene dos bebés donde uno de ellos es varón.\n",
    "\n",
    "Parecen parecidos pero no, en probabilidades cambia\n",
    "\n",
    "Tablero formulamos la siguiente pregunta\n",
    "\n",
    "Cual es la probabilidad de esta mujer tenga dos hijos varones.\n",
    "\n",
    "El fin del ejercicio es darse cuenta que la información de cada enunciado es diferente.\\\n",
    "Y para el cálculo de probabilidades de un ejerc q parece tan sencillo, primero deberemos calcular el espacio muestral, donde dibujaremos una matriz, donde en un eje se encontrarán los posibles géneros de un hijo, y en el otro eje los géneros del otro hijo.\n",
    "\n",
    "\n",
    "$\\underbrace{\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & MM  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}}_\\text{Espacio Muestral} \\hspace{3em} \\begin{matrix} F=Femenino \\\\ M=Masculino \\end{matrix}$\n",
    "\n",
    "Para dar un ejemplo, daremos que sin conocimiento previo nos preguntamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **¿Cual es la posibilidad de que una mujer tenga 2 hijos varones?**\n",
    "\n",
    "Tal cual lo presentamos sin ninguna condición, planteamos una probabilidad tradicional, y consideramos el espacio muestral completo, donde el número de eventos posibles es $4$, y el número de eventos exitosos es $1$.\n",
    "\n",
    "$\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & (MM)  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}$\n",
    "\n",
    "Y la probabilidad quedaría tal que:\n",
    "\n",
    "$\\displaystyle{P(MM) = \\frac{1}{4}=25\\%}$\n",
    "\n",
    "Por lo tanto, la probabilidad es solamente de $\\frac{1}{4}$ sin ninguna condición previa, donde esta probabilidad no representa ni al caso 1 ni 2 mencionados anteriormente, sino simplemente a una situación general donde no tenemos información previa al género de los hijos de dicha mujer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situación 1\n",
    "\n",
    "Pero qué sucedería si ahora imponemos la situación donde tenemos la información previa de que el mayor de los hijos es un varón. Entonces replantearíamos el ejercicio ahora de esta forma:\n",
    "\n",
    "**¿Cual es la probabilidad de que ambos hijos sean varones, sabiendo que el mayor es varón?**\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor Varón}) = ?$\n",
    "\n",
    "Con la información que tenemos podemos restringir el espacio muestral sabiendo que uno de los ejes (hijos) es el mayor, restringiendo el espacio muestral a solamente dos estados.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        FM & |MM|  \\\\\n",
    "        FF & |MF|  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Y de esta manera apreciamos que entre estos dos estados, solo uno satisface el enunciado. Quedando la probabilidad tal que:\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor M}) = \\frac{1}{2}=50\\%$\n",
    "\n",
    "Este resultado funciona bien con la situación 1, pero ¿Qué diferencia existe entre la situación 1 y 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situación 2\n",
    "\n",
    "Comparemos la sutileza gramatical entre la situación 1 y 2\n",
    "\n",
    "1. Una mujer tiene dos bebés donde <u>el mayor es un varón</u>.\n",
    "\n",
    "1. Una mujer tiene dos bebés donde <u>uno de ellos es varón</u>.\n",
    "\n",
    "La diferencia de decir entre el hijo mayor es varón, y uno de ellos es varón, implica que en realidad no sabemos cuál de ellos es varón.\\\n",
    "Aunque escape de la intuición, este pequeño cambio genera una diferencia en el espacio muestral, y lo demostraremos en la matriz para que se pueda apreciar el cambio del enunciado 2.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        [FM] & [MM]  \\\\\n",
    "        FF & [MF]  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "El hecho de decir que, uno de ellos es el varón, representan 3 posibles estados en el espacio muestral, porque en cada uno de los ejes, al menos uno de los hijos es varón.\n",
    "\n",
    "Cuando escribimos esto en la probabilidad, decimos, que la probabilidad de que ambos hijos sean varones, sabiendo que alguno de ellos es varón es de un estado exitoso sobre tres posibles estados:\n",
    "\n",
    "$\\displaystyle{P(MM \\, | \\, \\text{alguno M}) = \\frac{1}{3} = 33.\\hat{3}\\%}$\n",
    "\n",
    "Así podemos demostrar que las posibilidades de la situación 1 y 2 son diferentes, aunque parezcan igual y se debe a que la cantidad de información que contiene cada frase debido a esa sutileza gramatical es diferente y esto determina distintos resultados en probabilidad.\\\n",
    "Donde en la situación 1 la probabilidad de que los dos hijos sean varones es mayor, debido a la mayor cantidad de información dada en el enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de Monthy Hall\n",
    "\n",
    "<img src=\"https://m.media-amazon.com/images/M/MV5BNjUxNjMyZmUtYWE4Yi00Mzg2LWJkZmYtY2YyNjQ4ZmIyMGQwL2ltYWdlXkEyXkFqcGdeQXVyMTIxMDUyOTI@._V1_.jpg\" width=\"400\">\n",
    "\n",
    "En nuestra segunda paradoja trataremos el caso del programa de televisión *Let's make a deal*, dado por el conductor Monthy Hall, al que de se debe su nombre en probabilidad a esta paradoja, cómo, **El problema de Monthy Hall**  \n",
    "\n",
    "El ejercicio consistía en que el presentador le presentaba a un participante tres puertas, donde el participante tenía que elegir una entre las tres posibles puertas, donde detrás de dos puertas no había nada y solo en una había un premio.\n",
    "\n",
    "En una situación tradicional, el presentador le preguntaría al participante que elija una puerta, entonces nos preguntariamos\n",
    "\n",
    "**¿Cual es la posibilidad de que el participante elija la puerta correcta?**\n",
    "\n",
    "Siendo una probabilidad tradicional, dibujaremos el espacio muestral y veriamo todas las opciones, donde podremos ver que las tres opciones inicialmente, todas son igualmente probables, por lo tanto el participante piense que la probabilidad de elegir la puerta correcta sea de un tercio por la naturaleza de la situación.\n",
    "\n",
    "$\\displaystyle{\\begin{vmatrix} P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\\begin{matrix}  \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\ \\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\end{matrix}}$\n",
    "\n",
    "El truco del show era de que una vez que el participante eligiera una puerta, Monthy Hall abre una de las puertas (obviamente el presentador abriría una puerta sin recompensa, este era el punto de información adicional), luego de el presentador abriera la puerta sin recompensa, Monthy le preguntaría al participante, que ahora cuenta de información adicional (la puerta que abrió Monthy):\n",
    "\n",
    "Ahora que sabe que esta puerta no tenía recompensa, ¿mantiene la puerta que eligió, o prefiere cambiar de puerta?\n",
    "\n",
    "Entonces, la intuición a primera vista nos hace decir:\n",
    "\n",
    "¿Cual es la probabilidad de que cambie de puerta y gane? o ¿Cuál es la probabilidad de que mantenga la puerta y gane?\n",
    "\n",
    "Dibujemos el espacio muestral para representar esta idea de forma más visual:\n",
    "\n",
    "Este sería muestral antes de elegir una puerta\n",
    "\n",
    "$\n",
    "\\begin{vmatrix}P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Entonces digamos que elegimos la puerta 1, y el presentador abrió la puerta 3 ya que esta no tiene premio. El espacio muestral se nos restringiría a las situaciones donde la puerta 3 no tiene premios, quedando tal que\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{matrix}  \\\\\\longrightarrow 1/2 = 50\\% \\\\ \\longrightarrow 1/2 = 50\\% \\\\\\end{matrix}\n",
    "$\n",
    "\n",
    "Donde el número de estados posibles ya no es 3, sino 2, quedando la probabilidad de éxito de un medio.\\\n",
    "Entonces el razonamiento es que al tener 2 opciones donde solo 1 es de éxito y ambas tienen 50% de posibilidades de ser la correcta, el participante asume que da igual si mantiene la puerta o no, ya que en ambas tiene 50% de probabilidad de ganar. Este es el primer razonamiento que se podría hacer con la intuición natural de las probabilidades, pero la paradoja es que esto es **falso**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Por qué cambian las probabilidades?\n",
    "\n",
    "Pero... ¿en realidad hay más probabilidades de ganar si cambio la puerta una vez que el presentador haya descartado una?\n",
    "\n",
    "La respuesta es sí! Porque resultan en situaciones distintas, al igual que en el ejemplo anterior, las probabilidades pueden verse modificadas cuando hay una cambio en la cantidad de información disponible a la hora de tomar una decisión, y este cambio de información fue el hecho de que el presentador haya abierto la puerta, modificando la probabilidad de éxito.\n",
    "\n",
    "Cambiemos el esquema mediante el cual ahora calcularemos nuestras nuevas probabilidades.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 0 \\\\ 0 \\\\ (🏆) \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 0 \\\\ (🏆) \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ (🏆) \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\hspace{1em}\n",
    "\\begin{matrix}   \\\\ 🏆\\rightarrow \\text{premio} \\\\ 🧔\\rightarrow \\text{participante} \\\\ 🎤\\rightarrow \\text{presentador} \\\\ \\end{matrix}\n",
    "$\n",
    "\n",
    "\n",
    "En este nuevo diagrama consideraremos dos columnas nuevas, donde representará el caso de si mantenemos la misma puerta que elegimos, o el caso en que cambiemos la puerta sabiendo la información adicional que nos dé el presentador.\n",
    "\n",
    "#### Situación 1\n",
    "\n",
    "Entonces supongamos que elegimos la puerta 1 y el presentador abriera la puerta 2, ya que la 3 tiene el premio, por lo tanto no la abriría.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🧔   \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤   \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ 🏆   \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\    \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "¿Que sucedería en esta situación?\n",
    "\n",
    "En esta situación, si me mantuviera en la puerta 1, que es la que elegimos al principio, no ganariamos el premio, pero si la cambiamos al a puerta 3, entonces si lo ganariamos. Quedando el diagrama tal que: \n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🧔 \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤 \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ 🏆 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ❌ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ✅ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Situación 2\n",
    "\n",
    "\n",
    "Sigamos usando el mismo razonamiento con el siguientes caso, donde abrimos la puerta 1, y el presentador tendrá que abrir la puerta 3, ya que en la puerta 2 se encuentra el premio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\  🧔  \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\  🏆  \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  🎤  \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\  ❌  \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\  ✅  \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Donde si me quedo con la puerta que elegí perdería, pero si la cambiara, ganaria.\n",
    "\n",
    "#### Situación 3\n",
    "\n",
    "Y en la ultima situacion, seria que abriera la puerta 1 que contiene el premio, y daria igual la puerta que abriera el presentador, ya que ni la puerta 2 y 3 tienen premio, siendo el único caso donde si mantengo la puerta ganaria.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🏆 \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤 \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ✅ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ❌ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Resolución\n",
    "\n",
    "Estas son las situaciones que tendríamos que tener en cuenta para saber ¿Cual es la probabilidad de ganar si me quedo con la misma puerta?\n",
    "\n",
    "Para saber esto veamos la matriz completa de todas las situaciones que vimos en el ejercicio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 🧔 \\\\ 🧔 \\\\ 🏆 \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 🎤 \\\\ 🏆 \\\\ 🎤 \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ 🏆 \\\\ 🎤 \\\\ 0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ❌ \\\\ ❌ \\\\ ✅ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ✅ \\\\ ✅ \\\\ ❌ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Si nos hubiéramos quedado con la misma puerta que elegimos al principio, solo en un caso hubiéramos tenido la probabilidad de ganar de los tres casos, quedando tal que:\n",
    "\n",
    "$\\displaystyle{P(🏆|Mantener)= \\frac{1}{3}}$\n",
    "\n",
    "Pero a diferencia de si hubiéramos cambiado de puerta luego de la información adicional dada por el presentador, tendríamos dos casos de eventos exitosos contra los tres que teníamos.\n",
    "\n",
    "$\\displaystyle{P(🏆|Cambiar)= \\frac{2}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión\n",
    "\n",
    "Con estos dos ejercicios demostramos que el cálculo de probabilidades, no siempre es intuitivo y que hay tener cuidado al entender cual es el espacio muestral sobre cual estamos trabajando, dado que tengamos información adicional, o no, sobre cierta situación a la cual realizaremos el cálculo de probabilidades.\n",
    "\n",
    "Con estos dos ejercicios dimos el inicio para desarrollar nuestra intuición probabilística!\n",
    "\n",
    "[Video explicativo Monthy Hall - Javie Santaolla](https://www.youtube.com/watch?v=1BpTBzDQuRE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 3: Distribuciones de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es una distribución? \n",
    "\n",
    "**¿Qué es una distribución de probabilidad?**\n",
    "\n",
    "**Es una función**, en el sentido matemático del cálculo, **donde a cada uno de los posibles estados de una variable aleatoria dentro del espacio muestral**, se le asigna una probabilidad.\n",
    "\n",
    "Como ejemplo tenemos el ejercicio del dado que tiene un espacio muestral de 6 posibles estados, y cada uno de esos estados tiene una probabilidad de \\frac{1}{6},  en este caso esta distribución sería una función constante, donde a cada estado se le asigna un valor, siendo la misma, una función discreta.\n",
    "\n",
    "En general **mencionaremos a la $X$ mayúscula como una variable aleatoria**, donde **$P$, será la función**, que a cada una de las ocurrencias o valores posibles de esta variable aleatoria, se le asignará un número que denominaremos la probabilidad.\n",
    "\n",
    "\n",
    "$X \\, aleatoria \\longrightarrow \\underbrace{P(X = x)}_\\text{probabilidad de ocurrencia}$\n",
    "\n",
    "De esta manera comprendemos que **$P$ es función de la variable aleatoria**\n",
    "\n",
    "$P=f(X)$\n",
    "\n",
    "Una convención en probabilidad, es que, las **letras mayúsculas denotan las variables**, mientras que las **letras minúsculas denotar los posibles valores que estas variables aleatorias pueden tomar**.\n",
    "\n",
    "$X \\rightarrow \\text{variable aleatoria}$\\\n",
    "$x \\rightarrow \\text{valores posibles en el espacio muestral}$\n",
    "\n",
    "Al igual que sucede en el cálculo, las funciones poseen un Dominio.\n",
    "\n",
    "El dominio viene por **todos los valores posibles de la variable aleatoria por la cual la función puede ser calculada**, donde estos dominios podrán así dividirse en conjuntos discretos o continuos, **donde tendremos tanto funciones discretas o funciones continuas.**\n",
    "\n",
    "$\n",
    "Dom(X) = \n",
    "     \\begin{cases}\n",
    "        Discreto, &\\quad \\{1,2,3,4,5,6\\} \\\\\n",
    "        \\\\\n",
    "        Continuo,  &\\quad [0,\\infty] \\\\\n",
    "     \\end{cases}\n",
    "$\n",
    "\n",
    "[Articulo dedicado a Funciones Matematicas para Ciencias de Datos](https://deepnote.com/@mazzaroli/Introduccion-a-Funciones-Matematicas-para-Data-Science-e-Inteligencia-Artificial-f9a47b52-0308-4e95-a3d3-c3de3ef7b14f)\n",
    "\n",
    "Un ejemplo de una distribución discreta podría usarse de ejemplo el juego de los dados, porque los valores tienen un número finito de estados, donde tenemos a las 6 caras del dado, y la variable aleatoria sería la cara que me daría el dado como resultado. \n",
    "\n",
    "A diferencia de las variables aleatorias que pueden ser continua, por ejemplo, la temperatura, ya que puede considerarse como una variable aleatoria y es continua, porque no precisa necesariamente tener que ser un número entero, sino, que puede ser un valor decimal cualquiera dentro de un rango definido.\n",
    "\n",
    "Profundizaremos sobre los aspectos matemáticos de estas funciones particulares, que llamamos distribuciones de probabilidad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución de Probabilidad\n",
    "\n",
    "Coincidiremos a $X$ mayuscula como una variable aleatoria donde $P$ de $X$, será una \n",
    "función de distribución de probabilidad, o también conocida como [**densidad de probabilidad**](https://es.wikipedia.org/wiki/Funci%C3%B3n_de_densidad_de_probabilidad)\n",
    "\n",
    "$\\displaystyle{X \\rightarrow P(X) \\rightarrow \\text{densidad de probabilidad}}$\n",
    "\n",
    "Donde **$P(X)$ puede tener un carácter discreto o un carácter continuo**, que estarán determinados por los valores posibles de la variable aleatoria $X$\n",
    "\n",
    "$\n",
    "P(X) \n",
    "    \\begin{cases}\n",
    "    Discreto\\\\\n",
    "    \\\\\n",
    "    Continuo\\\\\n",
    "    \\end{cases}\n",
    "$\n",
    "\n",
    "Como toda función, se puede graficar, así que cuando una distribución de probabilidad es continua, podemos describirlo como una distribución gaussiana en un plano de ejes cartesianos, donde dado un punto $x$ ($x$ minúscula = ocurrencia de un valor específico dentro del conjunto de variables), la imagen, dada la función, es la probabilidad de que ocurra ese valor particular\n",
    "\n",
    "<img src='./img/dist normal.png' width='300'>\n",
    "\n",
    "Y como toda función en calculo, la podemos derivar o integrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integral de una distribución\n",
    "\n",
    "**¿Qué significa la integral de una distribución?**\n",
    "\n",
    "Al igual que podemos preguntarnos _¿Cuál es la probabilidad de que la variable tenga un valor en particular?_ que seria haciendolo con la función de densidad de probabilidad.\n",
    "\n",
    "$P(X=x)=?$\n",
    "\n",
    "También podemos preguntarnos \n",
    "\n",
    "**¿Cuál es la probabilidad de que mi variable aleatoria tenga valores menores o iguales que un valor específico dado?**\n",
    "\n",
    "$P(X\\leq x)=?$\n",
    "\n",
    "Para calcular esto, debemos recordar los conceptos de cálculo integral, donde serían todos los valores que se encuentre por detrás del valor umbral, y esto es lo que llamamos en cálculo, un área bajo la curva\n",
    "\n",
    "<img src='./img/area curva.png' width='300'>\n",
    "\n",
    "Así es como sabemos que este tipo de probabilidades ($P(X\\leq x)$) están dadas por una integral en función de la distribución.\\\n",
    "Donde decimos que la probabilidad de que mi variable aleatoria tome valores menores o iguales que un cierto valor específico, está dado por la integral de mi distribución de probabilidad $P$ de $X$, respecto a la variable de $X$, integrando sobre todos los posibles valores que sean menores o igual que $x$.\n",
    "\n",
    "$\\displaystyle{P(X\\leq x) = \\int\\limits_{X\\leq x}P(X)dX}$\n",
    "\n",
    "Esto es una integral, es el área debajo de la curva y también representa una probabilidad.\n",
    "\n",
    "En general decimos **cuando $x$ minúsculo no es un valor numérico**, sino, un valor cualquiera dado que p**uede considerarse como un parámetro, esto determinará** una nueva función que llamamos **la Distribución Acumulada** $C(X)$\n",
    "\n",
    "$\\displaystyle{P(X\\leq \\underbrace{x}_{parametro}) = \\int\\limits_{X\\leq x}P(X)dX}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Función de distribución acumulada\n",
    "\n",
    "Entonces decimos que **la distribución acumulada, representa la probabilidad de que mi variable aleatoria tome valores menores o iguales que esta $x$ dada, lo que llamamos una función de probabilidad acumulada.**\n",
    "\n",
    "$\\displaystyle{P(X\\leq \\underbrace{x}_{parametro}) = \\int\\limits_{X\\leq x}P(X)dX = C(x) \\longleftarrow Función \\, Probabilidad \\, Acumulada}$\n",
    "\n",
    "**La interpretación de la función de probabilidad acumulada, es la integral de la función de densidad de probabilidad.**\\\n",
    "**Y sirve para** responder el tipo de preguntas que surgen cuando no nos preguntamos por un valor en particular de la probabilidad, sino, **cuando nos referimos a un rango dentro de la probabilidad**, por ejemplo:\n",
    "\n",
    "**¿Cual es la probabilidad de que al tirar un dado el resultado sea un número menor o igual a x?**\n",
    "\n",
    "Por ejemplo, cuál es la probabilidad de que al tirar un dado el resultado sea un número menor o igual al 2, *donde este ejemplo específicamente se trata de una función discreta*.\n",
    "\n",
    "**La función de probabilidad acumulada también se utiliza para funciones discretas**, solo que en este caso, la gráfica en el plano cartesiano ya no se vería como una curva suave, sino, como un histograma.\\\n",
    "Donde cada una de sus caras tendrá una probabilidad, que sería la frecuencia con la que ocurriría cada uno de estos eventos.\n",
    "\n",
    "<img src='./img/histograma.png' width='300'>\n",
    "\n",
    "**Cuando queremos calcular la probabilidad acumulada de una función discreta**, porque queremos responder la misma pregunta sobre ¿Cuál es la probabilidad de que mi variable aleatoria tomará valores menores o iguales de cierto valor? **ya no se usarían integrales, sino, sumas discretas**, donde sumó todas las probabilidades en las que mi variable aleatoria tenga los valores menores o iguales al parámetro de referencia. \n",
    "\n",
    "$\\displaystyle{P(X\\leq x) = \\sum_{X\\leq{x}}P(X) \\longrightarrow Función \\, Probabilidad \\, Acumulada}$\n",
    "\n",
    "Esta también forma parte de la definición de **Probabilidad Acumulada**, pero es la función para los casos de **funciones discretas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reto\n",
    "\n",
    "Desarrolla una expresión matemática para el siguiente caso:\n",
    "\n",
    "¿Cual es la probabilidad de que mi variable aleatoria tome valores entre dos umbrales?\n",
    "\n",
    "$P(a \\leq X \\leq b)=?$\n",
    "\n",
    "Pista:\\\n",
    "Consideramos este caso como una <u>variable aleatoria continua</u>, donde tengo el umbral entre a y b\n",
    "\n",
    "<img src='./img/integral.png' width='300'>\n",
    "\n",
    "### Solución\n",
    "\n",
    "$\\displaystyle{P(a \\leq X \\leq b)\\hspace{1em}=\\hspace{1em} \\int\\limits^{b}_{a}P(X)dx\\hspace{1em}=\\hspace{1em}P(b)-P(a)\\hspace{1em}=\\hspace{1em}C(X)}$\n",
    "\n",
    "### Conclusión\n",
    "\n",
    "**La probabilidad** es un campo que **depende** mucho **de los elementos del cálculo**, porque esas funciones que nos permiten determinar probabilidades sobre los diferentes estados de una variable aleatoria, son específicamente las que definimos en el cálculo sobre un punto de vista matemático, **tales como sus propiedades matemáticas de derivacion e integracion que se aplican sobre funciones normales en cálculo, pueden ser aplicadas en probabilidad.**\\\n",
    "En el caso particular de la distribución de distribución acumulada, que es la integral de la función de la densidad de probabilidad.\n",
    "\n",
    "Pero no te asustes! porque estas son las bases para que entiendas los mecanismos detrás del cálculo de probabilidad, pero en la práctica, pasaremos al código con Python para desarrollar esto como lo haría todo un científico de datos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones discretas \n",
    "\n",
    "Profundizaremos en como trabajar con distribuciones discretas, tales como el lanzamiento de monedas y dados, donde para este tipo de ejercicios, surge de manera natural la **distribución de Bernoulli**.\n",
    "\n",
    "### Distribución de Bernoulli\n",
    "\n",
    "Una distribución de Bernoulli es una función que asigna a la variable binaria dos valores, cuando $X$ sea igual a 1 (éxito) ocurre con la probabilidad $p$, donde p valdría 0,5 dado un caso de probabilidad equilibrada, y cuando $X$ sea igual a 0 (fracaso) se representa con la probabilidad de $1 - p$, porque la suma de las probabilidades tiene que dar el 100%.\\\n",
    "Se dice que la variable aleatoria $X$, se distribuye como una Bernoulli de parámetro $p$ con $0 <p < 1$\n",
    "\n",
    "#### Fórmula de Bernoulli\n",
    "$\n",
    "P(X=1)=p\\\\\n",
    "P(X=0)=1-p\\\\\n",
    "0<p<1\n",
    "$\n",
    "\n",
    "Desde la definición de esta función, podemos empezar a considerar situaciones más complejas con base al ejercicio de lanzar monedas, pero... no te preguntas sobre ¿cómo podemos hacer más complejo lanzar una moneda?, si solo hay 2 posibilidades del 50%, la respuesta es lanzar una $n$ cantidad de monedas, 2, 3, 4 o las que yo quiera.\n",
    "\n",
    "Por lo tanto, decimos que cuando tenemos secuencias repetitivas de eventos binarios (eventos tipo Bernoulli), es cuando tenemos que hablar de la famosa **Distribución binomial**, entonces en este punto es cuando empezaremos a desarrollar sus pasos precedentes, hasta poder entender de forma natural y sencilla sobre como surgen de manera fundamental las distribuciones binomiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo Distribución Bernoulli\n",
    "\n",
    "##### Caso 1\n",
    "\n",
    "Podemos decir que tenemos tres monedas que lanzaremos 1 vez cada una o que lanzaremos la misma moneda tres veces, donde la probabilidad de que obtengamos cara y cruz en cada lanzamiento es igualmente probable en ambos casos. \n",
    "\n",
    "Entonces nos preguntamos:\n",
    "\n",
    "**¿Cuál es la probabilidad de 3 lanzamientos de una monedas, en 2 de esos 3 lanzamientos obtengamos cara?**\n",
    "\n",
    "Al graficar y contar las combinaciones, vemos que existen 8 posibles escenarios al lanzar las monedas:\n",
    "\n",
    "<img src='./img/moneda.png' width='350'>\n",
    "\n",
    "Así sabemos que trabajamos con un espacio muestral de 8 posibilidades, y de esas 8 solo en 3 casos obtendríamos 2 caras. \n",
    "\n",
    "<img src='./img/caras.png' width='350'>\n",
    "\n",
    "Por lo tanto, decimos que la probabilidad de lanzar 3 veces una moneda y obtener 2 caras es de:\n",
    "\n",
    "$\\displaystyle{P(2\\, Caras|3\\, Lanzamientos)=\\frac{3}{8}}$\n",
    "\n",
    "Asumimos en esta situación que la probabilidad de obtener cara o cruz, es igualmente probable en cada lanzamiento, porque esta es la hipótesis con la que hemos trabajado desde el principio del artículo, donde decimos que hay probabilidades fundamentales que son axiomáticas y, por lo tanto, asumimos que son igualmente probable.\\\n",
    "Pero en caso de la distribución de Bernoulli, cuando esto no sucede, definimos el número $p$ minúscula, que asigna la probabilidad de uno u otro suceso.\n",
    "\n",
    "*En la vida real este parámetro se ajusta acorde los datos que obtengamos en práctica de X experimento.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Caso 2\n",
    "\n",
    "Si complicamos el caso de la distribución binomial, donde ya no nos preguntándonos por 3 lanzamientos de monedas, sino, por $n$ lanzamientos, donde $n$ podría ser un número muy grande, y de esos $n$ lanzamientos, podemos tener $k$ caras, que es la variable donde definiremos cuantas caras queremos tener según el número $n$ de lanzamientos.\n",
    " \n",
    "$\\displaystyle{P(K=Caras\\;|\\;n=Lanzamientos)=?}$\n",
    "\n",
    "En este punto vemos que la formula se complica, ya que mientras más lanzamientos haya, el espacio muestral $(EM)$ crece de manera mayor que la exponencial.\n",
    "\n",
    "[Calcular espacio muestral para una n cantidad de probabilidades](https://es.wikipedia.org/wiki/Espacio_muestral#Procesos_estoc%C3%A1sticos_finitos_y_diagramas_de_%C3%A1rbol)\n",
    "\n",
    "Entonces en este punto nos preguntamos:\n",
    "\n",
    "**¿Existe alguna fórmula general para contar todos estos posibles estados y sobre ellos hacer el conteo de probabilidades?**\n",
    "\n",
    "La respuesta es claro que si, de esto es lo que se trata específicamente <u>la función de distribución binomial.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción a la distribución binomial\n",
    "\n",
    "Volviendo a nuestro problema de los 3 lanzamientos de una moneda, usaremos la letra $k$ para definir el número de caras o sucesos exitosos, que queremos obtener a partir de los $n$ lanzamientos.\n",
    "\n",
    "Veamos como sería la distribución binomial de este problema, donde ya sabemos que es binomial, pero...\n",
    "\n",
    "**¿Qué quiere decir que una distribución sea binomial exactamente?**\n",
    "\n",
    "Gráficamente sabemos que cuando una [distribución es discreta](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_probabilidad#Distribuciones_de_variable_discreta), la gráfica tendrá forma de un [diagrama de barras o histograma](https://es.wikipedia.org/wiki/Histograma), donde cada barra representa la [frecuencia relativa](https://es.wikipedia.org/wiki/Frecuencia_estad%C3%ADstica#Frecuencia_relativa) de un evento posible en el eje X.\n",
    "\n",
    "Entonces decimos que los eventos posibles son el resultado que podemos obtener de cada lanzamiento: **0 caras, 1 cara, 2 caras y como máximo 3 caras**.\\\n",
    "Estas son las 4 posibilidades sobre las que podemos calcular las frecuencias relativas.\n",
    "\n",
    "<img src='./img/barras.png' width='300'>\n",
    "\n",
    "De todos los eventos, sabemos que tenemos 8 posibilidades, que sería nuestro espacio muestral.\n",
    "\n",
    "<img src='./img/monedabinomial.png' width='300'>\n",
    "\n",
    "\n",
    "Entonces... **¿Cuántas opciones del EM resultan en 0 caras, en 1 cara, 2 caras y 3 cars?**\n",
    "\n",
    "Como vemos en el gráfico del espacio muestral, solo en un caso tenemos 0 caras, en 3 casos tenemos 1 y 2 caras, y en solo un caso tenemos 3 caras.\\\n",
    "Quedando la probabilidad quedaría tal que:\n",
    "\n",
    "Donde:\\\n",
    "$\\displaystyle{P(k= cara ,\\; n= lanzamientos) = \\frac{k}{EM}}$\n",
    "\n",
    "$\n",
    "\\displaystyle{P(0,3) = \\frac{1}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(1,3) = \\frac{3}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(2,3) = \\frac{3}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(3,3) = \\frac{1}{8}}\n",
    "$\n",
    "\n",
    "\n",
    "<img src='./img/monedabinomialposibilidades.png' width='800'>\n",
    "\n",
    "De esta forma podemos reflejar el concepto de como se vería la distribución binomial para este caso en particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinatorio o Coeficiente binomial\n",
    "\n",
    "Volviendo a la pregunta inicial.\n",
    "\n",
    "**¿Existe alguna fórmula general para contar todos estos posibles estados y sobre ellos hacer el conteo de probabilidades?**\n",
    "\n",
    "¡Y como ya mencionamos antes, si disponemos una fórmula general! \n",
    "\n",
    "En matemáticas contamos con un elemento que son los [coeficientes binomiales, **números combinatorios** o combinaciones](https://es.wikipedia.org/wiki/Coeficiente_binomial) son números estudiados en [matemáticas combinatoria](https://es.wikipedia.org/wiki/Combinatoria) que corresponden al número de formas en que se puede extraer subconjuntos a partir de un conjunto dado.\\\n",
    "**El número combinatorio $\\binom{n}{k}$ es el número de subconjuntos $k$ elementos que satisfacen algun requisito de un conjunto con $n$ elementos, y el subconjunto $k$ tiene que ser menor que el conjunto $n$.**\n",
    "\n",
    "#### **Fórmula del Combinatorio:**\n",
    "\n",
    "$\\displaystyle C_{n}^{k} = \\binom {n}{k}=\\frac {n!}{k!\\cdot (n-k)!}$\n",
    "\n",
    "donde:\\\n",
    "$\n",
    "n = \\text{número de intentos} \\\\\n",
    "k = \\text{número de aciertos} \\\\\n",
    "r \\leq n \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo Combinatorio o Coeficiente binomial\n",
    "\n",
    "Ahora que sabemos que existe una manera de contar de forma general todos los posibles estados dentro de un espacio muestral, pasaremos con un ejemplo para ver como nos ayuda a conocer la probabilidad de éxito donde:\n",
    "\n",
    "**Queremos obtener la probabilidad de obtener $\\pmb{k}$ veces cara, dado $\\pmb{n}$ lanzamientos.**\n",
    "\n",
    "donde:\\\n",
    "$n = 3$\\\n",
    "$k = 1$\n",
    "\n",
    "Donde la probabilidad quedaría tal que:\n",
    "\n",
    "$P(1,3)=?$\n",
    "\n",
    "Usando el Combinatorio pasaremos a contar los posibles estados de éxito de obtener 1 cara dado 3 lanzamientos de una moneda quedando tal que:\n",
    "\n",
    "$\\displaystyle\n",
    "P(k,n) \\rightarrow C^{n}_{k}\n",
    "$\n",
    "\n",
    "Donde sabemos que $n$ es el número de lanzamientos que son 3 y $k$ sería el número de éxitos dado $n$ que es 1:\n",
    "\n",
    "${\\displaystyle P(1,3) \\longrightarrow C^{3}_{1} = {\\binom {3}{1}} = {\\frac {3!}{1!\\cdot (3-1)!}} = {\\frac {1*2*3}{1* 1*2}} = {\\frac {\\cancel{1}*\\cancel{2}*3}{\\cancel{1}*\\cancel{2}}} = 3}$\n",
    "\n",
    "Así es como sabemos las posibles maneras de obtener este resultado, que es 3.\n",
    "\n",
    "Por último décimos que la probabilidad está dada por el resultado del combinatorio entre el espacio muestral total, que es 8, ya que son todos los estados posibles de lanzar 3 veces una moneda.\n",
    "\n",
    "${\\displaystyle P(k,n) = \\frac{C}{EM} \\longrightarrow P(3,1) = \\frac{3}{8}}$\n",
    "\n",
    "Entonces vemos que a través de la fórmula combinatoria somos capaces de contar los estados dado dicho evento y lo podemos demostrar, comparando el resultado que obtuvimos con el gráfico de la distribución binomial que realizamos anteriormente, donde la barra que reflejaba la probabilidad de obtener 1 cara de 3 lanzamientos de una moneda era de $\\frac{3}{8}$.\n",
    "\n",
    "Así a través del símbolo combinatorio que nos permite contar los estados posibles, podemos desarrollar el cálculo de conteo de probabilidades, de esta manera dando paso a la introducción de la fórmula general de Distribución Binomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribución Binomial\n",
    "\n",
    "Definimos a la distribución binomial o distribución binómica como una distribución de probabilidad discreta que cuenta el número de éxitos en una secuencia de ${\\displaystyle n}$ ensayos de Bernoulli independientes entre sí, con una probabilidad fija ${\\displaystyle p}$ de ocurrencia de éxito entre los ensayos.\n",
    "\n",
    "Decimos que la probabilidad de un suceso partícula, es igual al número de estados que conducen a ese suceso, multiplicado por la probabilidad de cada estado individual:\n",
    "\n",
    "$p \\rightarrow suceso \\rightarrow  p *  estados \\, suceso $\n",
    "\n",
    "Usando el ejemplo de las monedas:\n",
    "\n",
    "Donde sabemos que el número 3 son los estados exitosos que obtuvimos a partir del combinatorio $C^n_k$ y la probabilidad de individual de cada uno de los estados es de $\\frac{1}{8}$.\n",
    "\n",
    "Quedándonos el resultado tal que:\n",
    "\n",
    "${\\displaystyle  p =\\frac{1}{8} * 3 = \\frac{3}{8}}$\n",
    "\n",
    "Estas probabilidades estarían dadas por la fórmula general que encontramos en la literatura como la Distribución Binomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desarrollo fórmula Distribución Binomial \n",
    "\n",
    "Cuando tengamos una probabilidad que dados de $n$ intentos, y queramos obtener $k$ resultados, el número de estados exitosos es igual a $n$ combinado $k$.\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k}}$\n",
    "\n",
    "Esto lo que quiere decir es que de una $n$ cantidad de estados, solo habrá una cantidad $k$ de estados que satisfagan los resultados deseados y cada estado $k$ tendrá una probabilidad $p$\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "De lanzar una $n$ cantidad de monedas, solo habrá una $k$ cantidad que caiga en cara, donde cada una de esas $k$ monedas tendrá una probabilidad $p$.\n",
    "\n",
    "$\\displaystyle{\\overbrace{\\underbrace{coin}_k ,\\underbrace{coin}_k ,\\underbrace{coin}_{\\underbrace{k}_p},\\cdots ,coin ,coin ,coin,coin}^{n}}$\n",
    "\n",
    "Asumimos que p para el caso ideal tendría una probabilidad de 1/2, pero puede que esto no sea así, denotamos la letra $p$ por si las probabilidades no se encuentran balanceadas y multiplicamos la probabilidad de cada uno de estos eventos, que sería la probabilidad e la primera moneda, por la probabilidad de la segunda, la tercera y así considerando a todas las $k$, que sería equivalente a elevar la probabilidad $p$ a la $k$.\n",
    "\n",
    "$\n",
    "p(k_1) \\hspace{0.5em} * \\hspace{0.5em}\n",
    "p(k_2) \\hspace{0.5em} * \\hspace{0.5em}\n",
    "\\dots \\hspace{0.5em} * \\hspace{0.5em}\n",
    "p(k_n) \\hspace{0.5em} = \\hspace{0.5em}\n",
    "p^k\n",
    "$\n",
    "\n",
    "Quedando la formula general tal que:\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k} p^{k} }$\n",
    "\n",
    "Si la probabilidad de que el evento individual éxito es p, decimos que la probabilidad del evento fallido es $q=1-p$ tal cual vimos en la distribución de Bernoulli.\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k} p^{k} q}$\n",
    "\n",
    "De misma manera debemos descubrir la probabilidad de cada evento no exitoso, lo cual resolvemos multiplicando la probabilidad de cada uno de estos e igualmente sería equivalente a elevar $q$ por el número de todos los eventos no exitosos.\n",
    "\n",
    "Para saber cuantos eventos fallidos quedaron, simplemente tenemos que restarle a la totalidad de eventos $n$ realizados, la cantidad de eventos exitosos $k$. \n",
    "\n",
    "$\\displaystyle{\\overbrace{\\underbrace{coin ,coin ,coin }_{k},\\underbrace{\\cdots ,coin ,coin ,coin,coin}_{n-k}}^{n}}$\n",
    "\n",
    "Por lo tanto, la probabilidad de fracaso quedaría elevado a la n-k \n",
    "\n",
    "Quedándonos la formula tal que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fórmula de Distribución Binomial\n",
    "\n",
    "${\\displaystyle P(X) = {\\binom {n}{k}p^{k}q^{n-k}} = {\\frac {n!}{k!\\cdot (n-k)!}\\,p^{k}q^{n-k}} }$\n",
    "\n",
    "Y así es como damos a la fórmula de la Distribución Binomial\n",
    "\n",
    "donde:\\\n",
    "$n = \\text{número de intentos}$\\\n",
    "$k = \\text{número de aciertos}$\\\n",
    "$p = \\text{probabilidad de éxito en un intento}$\\\n",
    "$q = (1-p) \\hspace{0.5em} \\text{probabilidad de fracaso en un intento}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusión\n",
    "\n",
    "Así es como definimos a la distribución binomial, como, una distribución o función de densidad de probabilidad, donde podemos calcular de una secuencia de eventos de tipo Bernoulli cuantos éxitos puedo tener de variables binarias.\n",
    "\n",
    "- $\\displaystyle{P(k\\; caras\\;|\\;n\\; lanzamientos)}$\n",
    "\n",
    "- $\\displaystyle{P(k;n,p) = \\binom{n}{k}p^k(1-p)^{n-k}}$\n",
    "\n",
    "Esta no es la única distribución que podemos trabajar con variables aleatorias binarias, ya que existen varias.\\\n",
    "Donde también existen casos de variables aleatorias discretas no binarias, como por ejemplo la distribución multinomial, que es la generalización natural de la binomial.\n",
    "\n",
    "Formula general de Distribución multinomial\n",
    "\n",
    "$\\displaystyle{P(X_1,\\cdots,X_n) = \\frac{n!}{k_1!,\\dots,k_n!}P_1^{k_1},\\dots,P_n^{k_n} }$\n",
    "\n",
    "No profundizaremos en la distribución multinomial, porque lo importante es entender que existen otras distribuciones para variables discretas, con nombres interesantes que podrás impactar y asustar a tus amigos con simplemente nombrarlas.\n",
    "\n",
    "Otras distribuciones\n",
    "\n",
    "- [Poisson](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_Poisson)\n",
    "- [Geométrica](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_geom%C3%A9trica)\n",
    "- [Hipergeométrica](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_hipergeom%C3%A9trica)\n",
    "- [Binomial negativa](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_binomial_negativa)\n",
    "- [t de Student]()\n",
    " \n",
    "Entonces nos surge la duda de ¿Cómo sabremos cuando usar cada distribución habiendo tantas?, la verdad es que existen ciertas experiencias, investigaciones y experimentos aleatorios donde cada una de estas distribuciones se aplican de manera óptima.\n",
    "\n",
    "En el siguiente capítulo veremos que hay casos donde tenemos un conjunto de datos particular y no sabemos al comienzo su distribución, aprenderemos que existen técnicas para ajustar la mejor distribución de probabilidad al conjunto de datos que tengamos.\n",
    "\n",
    "¡Ya que en la vida real no sabemos exactamente las distribuciones en probabilidad y en conjuntos de datos, sino que tendremos que aprenderlas y tendremos ayuda de algoritmos que aprenden la distribución a partir de los datos, dando así el inicio al Machine Learning probabilístico!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando la distribución binomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import binomial\n",
    "from scipy.stats import binom\n",
    "import scipy.stats\n",
    "from math import factorial\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\displaystyle{P(k,n;p)=\\binom{n}{k}p^k(1-p)^{n-k}=\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}}\n",
    "$\n",
    "\n",
    "### Funcion de la distribucion binomial con Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def my_binomial(k,n,p):\n",
    "    return factorial(n)/(factorial(k)*factorial(n-k))*pow(p,k)*pow(1-p,n-k)\n",
    "\n",
    "my_binomial(2,3,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodo de Scipy funcion binomial\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html\n",
    "\n",
    "<table class=\"table\">\n",
    "<tbody>\n",
    "<tr class=\"row-odd\"><td><p><strong>rvs(n, p, loc=0, size=1, random_state=None)</strong></p></td>\n",
    "<td><p>Random variates.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>pmf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Probability mass function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>logpmf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Log of the probability mass function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>cdf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Cumulative distribution function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>logcdf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Log of the cumulative distribution function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>sf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Survival function  (also defined as <code class=\"docutils literal notranslate\"><span class=\"pre\">1</span> <span class=\"pre\">-</span> <span class=\"pre\">cdf</span></code>, but <em class=\"xref py py-obj\">sf</em> is sometimes more accurate).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>logsf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Log of the survival function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>ppf(q, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Percent point function (inverse of <code class=\"docutils literal notranslate\"><span class=\"pre\">cdf</span></code> — percentiles).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>isf(q, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Inverse survival function (inverse of <code class=\"docutils literal notranslate\"><span class=\"pre\">sf</span></code>).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>stats(n, p, loc=0, moments=’mv’)</strong></p></td>\n",
    "<td><p>Mean(‘m’), variance(‘v’), skew(‘s’), and/or kurtosis(‘k’).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>entropy(n, p, loc=0)</strong></p></td>\n",
    "<td><p>(Differential) entropy of the RV.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>expect(func, args=(n, p), loc=0, lb=None, ub=None, conditional=False)</strong></p></td>\n",
    "<td><p>Expected value of a function (of one argument) with respect to the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>median(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Median of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>mean(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Mean of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>var(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Variance of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>std(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Standard deviation of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>interval(alpha, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Endpoints of the range that contains fraction alpha [0, 1] of the distribution</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scipy.pmf Probability Mass Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.stats.binom(numero de intentos, probabilidad).pmf(numero de exitos)\n",
    "dist = binom(3, 0.5) \n",
    "\n",
    "# pmf = probability mass function = funcion de densidad de probabilidad\n",
    "pmf = dist.pmf(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion de distribucion acumulada con Python\n",
    "\n",
    "$\n",
    "\\displaystyle{P(k \\leq 2, n = 3; p = \\frac{1}{2})=\\sum^{2}_{k=0}\\left[\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\right]}=\\frac{7}{8}\n",
    "$\n",
    "\n",
    "*Puedes intentar validar el resultado de este ejercicio en papel antes de pasar al codigo* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scipy Cumulative Distribution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scipy.stats.binom(numero de intentos = 3 , probabilidad de eventos = 0.5).cdf(casos exitoso = 2)\n",
    "\n",
    "# Cumulative distribution function. = funcion de distribucion acumulada\n",
    "dist.cdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilidades Individuales: [0.125 0.375 0.375]\n",
      "     Probabilidades Sumadas: 0.875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probabilidades_individuales = scipy.stats.binom(3,0.5).pmf(range(0,3))\n",
    "probabilidades_sumadas = round(np.sum(probabilidades_individuales),3)\n",
    "\n",
    "print(f\"\"\"\n",
    "Probabilidades Individuales: {probabilidades_individuales}\n",
    "     Probabilidades Sumadas: {round(probabilidades_sumadas,3)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{probabilidades_sumadas}\n",
    "{dist.cdf(2)}\n",
    "{7/8}\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulaciones de secuencias con generadores aleatorios\n",
    "\n",
    "* Los generadores aleatorios tienen como propósito simular muestras de datos que resultarían de muestreos en la vida real de procesos aleatorios como lanzar una moneda o un dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulacion con 100 lanzamientos de moneda equilibrada\n",
    "# (ejecuta esta celda varias veces para observar la variacion de los resultados)\n",
    "p=0.5\n",
    "n=3\n",
    "binomial(n,p) #numpy.random.binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist(num_trials):\n",
    "    values = [0,1,2,3]\n",
    "    arr = []\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        arr.append(binomial(3,0.5))\n",
    "\n",
    "    distribucion_simulada = np.unique(arr, return_counts=True)[1]/len(arr)\n",
    "    distribucion_teorica = [binom(3,0.5).pmf(k) for k in values]\n",
    "\n",
    "    plt.bar(values, distribucion_simulada, color = 'green')\n",
    "    plt.bar(values, distribucion_teorica, alpha=0.5,color='violet')\n",
    "\n",
    "    plt.title('{} experimentos'.format(num_trials))\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(20)\n",
    "plot_hist(200)\n",
    "plot_hist(20000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Cómo estimar una distribución?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 4: MLE (Maximum Likelihood Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¿Qué es MLE? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicación de regrsión logística "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 5: Inferencia bayesiana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoremas de Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "642679db579c39e8c54388d8c67ee59d6b9479549eff357c7b1dae31a7261e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
