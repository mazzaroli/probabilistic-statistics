{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matem√°ticas para Ciencias de Datos: Estad√≠stica Probabilistica\n",
    "\n",
    "En este articulo buscamos entender por que la probabilidad es tan importante en Ciencias de datos y el Machine Learning en general\n",
    "\n",
    "Para esto primero abordaremos el concepto de **probabilidad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 1: Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es la probabilidad?\n",
    "\n",
    "En que situaciones necesitamos usar la probabildiad? para eso iremos al concepto basico que nos induce a esto. Por ello nos haremos esta pregunta:\n",
    "\n",
    "**Que es la probabilidad?**\n",
    "\n",
    "**La probabilidad es la herramienta a la que recurrimos cuando hay incertdibumbre.**\n",
    "\n",
    "La incertidumbre surge a la hora de tomar decisiones cuando tenemos informacion incompleta. Los juegos de azar son el ejemplo perfecto, ya que no podemos predecir el resutlado en un juego de cartas o dados en un casino.\n",
    "\n",
    "Esto se debe a situaciones que tienen un grado de complejidad donde no es posible tener todas las variables suficiente, con todos los datos para predecir de que si lanzas los dados de cierta manera o juegas las cartas de cierta manera se terminara por dar un resultado.\n",
    "\n",
    "Podemos resumir lo anterior como **la incertidumbre es la toma de decisiones con informacion incompleta**.\n",
    "\n",
    ">\"El azar no es mas que la medida de nuestra ignorancia. \n",
    ">Los fenomenos fortuitos son, por definicion, aquellos cuyas leyes o causas simplemente ignoramos\"\n",
    ">\n",
    "> **Henri Poincar√©**\n",
    "\n",
    "Por el hecho de que vivimos en una realidad donde la gran mayoria de nuestras decisiones las tomamos con informacion incompleta, los matematicos desarrollaron un esquema para cuantificar esta incertidumbre, dando asi el area de la Probabilidad en estadistica.\n",
    "\n",
    "**Probabilidad**\n",
    "\n",
    "En matematicos decimos que la probabilidad es el lenguaje y conjunto de herramientas matematicas que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Asi entendemos la propia palabra *probabilidad* como el area de investigacion, el concepto matematico puntual de la probabilidad tiene algunas sutilesas que conducen con frecuencia a confusiones.\n",
    "\n",
    "### Axiomas de la probabilidad\n",
    "\n",
    "Entender los elementos escenciales de la probabilidad\n",
    "\n",
    "Todo conjunto logico tiene que estar basado a un conjunto de axiomas, que significa que es un conjunto de setencias o afirmaciones, que no son derivables de algo mas fundamental, es decir que no requiere demostracion, por que lo asumimos como verdad.\n",
    "\n",
    "\n",
    "#### Sucesos\n",
    "\n",
    "Para comenzar definiremos los sucesos, ya que en cualquier libro de referencia, cualquier curso, o idioma donde estudies las matematicas de la probabilidad, encontraras que la definicion mas simple es que la probabilidad $(P)$, es la division de dos cantidades, numeros de sucesos exitodos sobre numero de sucesos totales.\n",
    "\n",
    "$\\displaystyle{P=\\underbrace{\\frac{N¬∞ \\text{sucesos exitosos}}{N¬∞ \\text{sucesos totales}}}_\\text{creencia del total}}$\n",
    "\n",
    "\n",
    "\n",
    "Ejemplo, cuando lanzas un dato, el resutlado son 6 posibiladades, cada una de esas posibilidades, es un suceso. \n",
    "Los sucesos totales son 6, pero cuando queremos saber cuales son las probabilidades de que el dado caiga en 2, como el 2 es un suceso de los seis, decimos que la probabilidad es de un sexto $({\\frac{1}{6}})$. \n",
    "\n",
    "Pero esto tiene una sutileza que nos conduce a dos escuelas de pensamientos en estadistica, la escuela Frecuentista y escuela Bayesiana.\n",
    "\n",
    "### Por que se divide el pensamiento estadistico?\n",
    "\n",
    "Cuando definimos que un sexto es la probabilidad de que un dado caiga en 2, aunque no parezca evidente, estamos asumiendo que todas las caras son igualmente probables. por lo tanto asumimos que todas las caras son igualmente probables. \n",
    "\n",
    "Lo mismo podemos definir con una moneda, donde tenemos dos posibles sucedos (cara o cruz), donde asumimos que la probabilidad de que caiga cara es de un medio $(\\frac{1}{2})$ y que caiga cruz tambien es de un medio.\n",
    "\n",
    "Pero que tan cierto es esto?\n",
    "\n",
    "Dependiendo de como interpretemos que es un suceso, o el numero de sucesos exitosos, podriamos hacer un ejercicio donde tiramos una moneda al aire 10 veces, y si la probabilidad es como la entendemos hasta ahora, de las 10 probabilidades, 5 deberian caer en cara y 5 en cruz.\n",
    "\n",
    "Haz el ejercicio y anota si realmente de las 10 veces te cayo 5 veces en cara o cruz. \n",
    "\n",
    "Probablemente no fue asi verdad, no?\n",
    "\n",
    "Aca es cuando diferenciamos las escuelas Frecuentistas y Bayesianas.\n",
    "\n",
    "#### Escuela Frecuentista\n",
    "\n",
    "Este pensamiento de probabilidad, nos explica que estos numeros que llamamos probabilidad (en esta ocacion puede ser la cara y la cruz), son numeros que solo se alcazan a la medida que haces infinitos lanzamientos de la moneda o dado, la proporcion del numero de lanzamientos exitosos y el numero de lanzamientos totales tiende a un medio, se acerca cada vez mas a 0.5. Como no hay forma de demostrar esto, por eso denominamos esto como un axioma.\n",
    "\n",
    "Las probabilidades sobre estos posibles sucesos que llamamos elementales, es por que son las ocurrencias mas basicas sobre un suceso probabilistico, donde una moneda solo tendria dos opciones, un dado seis opciones. Por esto debemos diferenciar sobre lo que es un suces elemental y un suceso\n",
    "\n",
    "**Suceso elemental:**\n",
    "\n",
    "Podemos entender a un suceso elemental como:\n",
    "> \"El resultado de lanzar un dado es 4\"\n",
    "\n",
    "Donde decimos que es elemental por que el resultado 4 solo se puede dar de una manera, que es que el daido caiga en 4 y nada mas.\n",
    "\n",
    "Suceso\n",
    "\n",
    "Un suceso en general se percibe como:\n",
    "> \"El suceso de lanzar un dado es par\"\n",
    "\n",
    "No es elemental porque es la union de varios sucesos elementales, donde el resultado puedo ser 2, 4 o 6.\n",
    "\n",
    "El uso de sucesos y sucesos elementales, se encuentran en el [espacio muestral](https://es.wikipedia.org/wiki/Espacio_muestral)  $(EM)$, **que es el conjunto de todos los posibles resultados de un evento aleatorio.** El dado tendria un espacio de seis, ya que tiene seis caras en la que puede caer, a cada uno de estos elementos del espacio muestral es lo que llamamos los sucesos elementales.\n",
    "\n",
    "En probabilidad entendequemos que todo evento aleatorio, viene escrito en un espacio muestral donde cada elemento son todas las posibles ocurrencias de ese evento aleatorio probabilistico, donde cada uno de los elementos le asignamos un numero que es una propiedad intrinseca. En el ejemplo de los dados le dariamos el elemento 1/6, ya que cada cara es igualmente probable y a esto lo asumimos como un axioma.\n",
    "\n",
    "<img src=\"./img/espacio muestral.PNG\" width=\"500\">\n",
    "\n",
    "Este tipo de probabilidad fundamental, sobre cada suceso elemental, de un espacio muestral, definimos a un sexto como la probabilidad de que caiga cada cara, a esto lo definimos como un axioma.\n",
    "\n",
    "En la vida real tendriamos que hacer infinitos intentos de esta situacion en particular, al ser un escenario abstracto, lo asumimos cierto dentro de un esquema axiomatica, es decir, la probabilidad hace parte de los axiomas y de esas propiedades intrinsecas de un problema aleatorio.\n",
    "\n",
    "La probabilidad que se le asigna a cada posible ocurrencia de un sistema aleatorio, posee varias propiedades que deben cumplirse para que el equema axiomatico tenga sentido:\n",
    "\n",
    "- $0 < P < 1$ Tienen que ser numeros que vayan del 0% al 100%, donde 0 es igual a 0% y 1 es igual a 100%.\n",
    "- $certeza \\rightarrow P=1$ Un elemento totalmente certero lo llamos con un 1.\n",
    "- $imposibilidad \\rightarrow p=0$ Un elemento imposiblemente certero lo llamos con un 0.\n",
    "- $disjuntos \\rightarrow P(A \\cup B)=P(A) + P(B)$ la probabilidad de dos elementos disjuntos sucedan, es la suma de las probabilidades de cada uno de estos.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "La posibilidad de que al arrojar un dado caiga en 2 y en 4 es la suma de la probabilidad de ambos sucesos, ya que no puede caer en 2 y en 4 al mismo tiempo\n",
    "\n",
    "Por lo que decimos que la probabilidad de que el dado caiga en 2 o en 4 es de dos sexto $(\\frac{2}{6})$, ya que son dos eventos posibles dentro de los seis eventos posibles.\n",
    "\n",
    "### Que es realmente la probabilidad?\n",
    "\n",
    "Para concluir debemos determinar que es realmente la probabilidad.\n",
    "\n",
    "Muchos dicen que es la creencia que tenemos sobre sucesos elementales. Ya que desde la perspectiva frecuentista, no tenemos forma de determinarlos realmente, asi que la probabilidad se incluye como un axioma en un conjunto de reglas que nos permite cuantificar la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad en Machine Learning\n",
    "\n",
    "En este m√≥dulo entenderemos como el Machine Learning y Ciencias de dato en general, como, el concepto o herramientas de probabilidad \n",
    "\n",
    "Recordemos que la probabilidad es un conjunto de herramientas y lenguaje matem√°tico que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Pero... donde se encuentra la incertidumbre en el machine learning?\n",
    "\n",
    "La fuente de la incertidumbre se encuentra en: \n",
    "- Los datos.\n",
    "- Atributos del modelo.\n",
    "- Arquitectura del modelo.\n",
    "\n",
    "Recuerda que en la vida real, recolectar y hacer la medici√≥n de los datos es un proceso imperfecto, ya que todos los instrumentos de medici√≥n tienen un margen de error, que ya nos introduce parte de incertidumbre en los datos.\n",
    "\n",
    "En Machine learning hablamos que un modelo se alimenta de atributos, o variables predictoras, estas variables con frecuencia son subconjuntos reducidos del problema total y real, lo que hace que esta reducci√≥n de variables ya es otra capa de incertidumbre.\n",
    "\n",
    "En matem√°ticas un modelo se entiende como una representaci√≥n simplificada de la realidad, y al ser una representaci√≥n simplificada, ya induce otra capa m√°s de incertidumbre.\n",
    "\n",
    "Estas tres son las principales fuentes de incertidumbre dentro del ML (Machine Learning), y por supuesto, estas fuentes de incertidumbre, son cuantificable con probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Clasificaci√≥n\n",
    "\n",
    "Ejemplo, un clasificador de documento de texto, donde tenemos un conjunto de documentos de texto de distintas categor√≠as, y nuestro modelo tiene que leer e identificar cual es el tema de conversaci√≥n y ubicarlos en una categor√≠a correspondiente de cada documento.\n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "Entonces, el modelo asignara cierta probabilidad a cada documento y as√≠ de determinara la clasificaci√≥n de los documentos.\n",
    "\n",
    "A este modelo es lo que llamamos un clasificador probabil√≠stico, y por definici√≥n del uso del propio modelo, ya damos uso a la probabilidad para identificar cual es la categor√≠a m√°s probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funcionamiento interno del modelo de Clasificador Probabil√≠stico \n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "En nuestro caso, lo que hace el modelo es que tiene documentos, donde cada uno tiene etiquetas, la etiqueta ser√≠a la categor√≠a o tema al que se refiere.\n",
    "\n",
    "#### Fase de Entrenamiento\n",
    "\n",
    "<img src=\"./img/entrenamiento.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "Los documentos tienen una funci√≥n que extra los atributos, es decir, simplifica los elementos fundamentales del documento que me ayudaran a hacer la extracci√≥n de la categor√≠a, a esto es lo que llamamos el **Extractor de Atributos**. \n",
    "\n",
    "Una vez realizada la extracci√≥n, el documento fue reducido a un conjunto de atributos (Vector), que se pasara como input al algoritmo de Machine Learning de clasificaci√≥n. El cual ser√≠a un algoritmo de Machine Learning supervisado, porque le doy las etiquetas, donde el algoritmo leer√≠a los atributos y en base a esto, asignar√≠a una etiqueta.\n",
    "\n",
    "As√≠ es como entrenar√≠amos a un algoritmo de ML supervisado\n",
    "\n",
    "#### fase de Predicci√≥n\n",
    "\n",
    "Luego de la fase de entrenamiento, viene la fase de Predicci√≥n\n",
    "\n",
    "<img src=\"./img/prediccion.PNG\" width=\"500\">\n",
    "\n",
    "En el proceso donde el algoritmo aprendi√≥ a unir los atributos con las etiquetas correctas, ya podemos agarrar el modelo, entregarles documentos, en el cual usando el mismo proceso de extracci√≥n de atributos, para luego entrar en el modelo de clasificaci√≥n y predecir la etiqueta.\n",
    "\n",
    "Entonces podr√≠amos decir que tengo una tarea donde tengo que clasificar muchos documentos, pero como f√≠sicamente no se puedo por el tama√±o y n√∫mero de documentos, usar√≠a mi algoritmo que est√° bien entrenado y el modelo me dir√≠a si el texto est√° hablando sobre pol√≠tica, deportes, etc\n",
    "\n",
    "> *La mayor√≠a de modelos de clasificaci√≥n funcionan con este esquema en general* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas las etapas del modelo probabil√≠stico\n",
    "\n",
    "<img src=\"./img/etp modelos.PNG\" width=\"500\">\n",
    "\n",
    "Todas las etapas de un modelo, en ciertos aspectos involucra probabilidad.\n",
    "\n",
    "¬øPero como?\n",
    "\n",
    "#### Entrenamiento\n",
    "\n",
    "En la parte de entrenamiento, antes de pasar los documentos para extraer atributos e identificar la arquitectura, debemos escoger el modelo a usar\n",
    "\n",
    "- Dise√±o\n",
    "\n",
    "    El modelo a usar es lo que definimos por dise√±o, donde escogeremos si el modelo usar√≠a probabilidad o no (No todos los modelos se apoyaran de la matem√°tica probabil√≠stica, ya que no todos los modelos son probabil√≠sticos)\n",
    "\n",
    "    En este caso usaremos de ejemplo el modelo de Naive Bayes, ya que es un modelo probabil√≠stico, ya que el clasificador Na√Øve-Bayes aprende de los datos de entrenamiento y luego predice la clase de la instancia de prueba con la mayor probabilidad posterior.\n",
    "\n",
    "- Entrenamiento\n",
    "\n",
    "    Una vez elegido el dise√±o, tenemos que definir el entrenamiento.\n",
    "\n",
    "    El entrenamiento b√°sicamente es que el modelo aprenda algo que sabr√° mas adelante, que es el concepto de distribuci√≥n de probabilidad.\n",
    "\n",
    "    Esto es una manera de saber que probabilidad asignarle a cada una de las posibles ocurrencias de los datos, donde nos encontramos con el esquema MLE (Maximum Likelihood Estimation)\n",
    "\n",
    "    **¬øQu√© es un par√°metro de un modelo?** \n",
    "\n",
    "    En los modelos de aprendizaje autom√°tico, los par√°metros son las variables que se estiman durante el proceso de entrenamiento con los conjuntos de datos. Por lo que sus valores no los indica manualmente el cient√≠fico de datos, sino que son obtenidos.\n",
    "\n",
    "    **MLE**\n",
    "\n",
    "    En estad√≠stica, **la estimaci√≥n de m√°xima verosimilitud** (MLE) es un m√©todo para estimar los par√°metros de una distribuci√≥n de probabilidad supuesta, dados algunos datos observados. Esto se logra maximizando una funci√≥n de verosimilitud para que, bajo el modelo estad√≠stico asumido, los datos observados sean los m√°s probables.\n",
    "\n",
    "- Calibraci√≥n\n",
    "\n",
    "    Luego llegar√≠a la calibraci√≥n, que es el ajuste del modelo a trav√©s de los hiperparametros, donde iremos calibrando el modelo para que el error del modelo sea cada vez m√°s peque√±o. \n",
    "\n",
    "    Los hiperparametros se encuentran por fuera del esquema de optimizaci√≥n, donde a veces se lo denomina como tuneo o calibraci√≥n de hiperparametros, donde hay veces que se usan algoritmos de optimizaci√≥n bayesiana\n",
    "\n",
    "    **¬øQu√© es un hiper par√°metro?**\n",
    "\n",
    "    Son valores que generalmente no puedo configurar con la optimizaci√≥n del modelo, por lo que suelen ser indicados por el cient√≠fico de datos. El valor √≥ptimo de un hiper par√°metro no se puede conocer a priori para un problema dado. Por lo que se tiene que utilizar valores gen√©ricos, reglas gen√©ricas, los valores que han funcionado anteriormente en problemas similares o buscar la mejor opci√≥n mediante prueba y error. Siendo una buena opci√≥n buscar los hiper par√°metros la validaci√≥n cruzada.\n",
    "\n",
    "#### Predicci√≥n\n",
    "\n",
    "Luego del proceso de entrenamiento, viene el proceso de predicci√≥n, donde nos encontramos con la fase de interpretaci√≥n del modelo\n",
    "\n",
    "- interpretaci√≥n de la predicci√≥n\n",
    "\n",
    "    Independientemente de si el modelo es probabil√≠stico o no, para la correcta interpretaci√≥n  del modelo, la persona requiere de ciertos conceptos de probabilidad, ya que entender c√≥mo funciona el c√°lculo de probabilidad del modelo, nos permite tener una interpretaci√≥n correcta del mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 2: Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de probabilidad\n",
    "\n",
    "Profundizaremos sobre el concepto de probabilidad mismo, hablando de los distintos tipos de probabilidad\n",
    "\n",
    "Distintos tipos de situaciones tienen que cuantificar con conceptos adicionales sobre el concepto de probabilidad basico\n",
    "\n",
    "**Tipos de probabilidades**\n",
    "\n",
    "- Conjunta (Joint)\n",
    "\n",
    "- Marginal\n",
    "\n",
    "- Condicional $P(A|B)$\n",
    "\n",
    "Para explicar estos conceptos que suelen darse de manera muy abstracta, seran explicado con un juego de dos dados, estudiando el espacio muestral, donde la malla ser√° la matriz por la que las filas y columnas representan el estado del primer dado y del segundo, teniendo un espacio muestral de 36 combinaciones\n",
    "\n",
    "<img src=\"./img/dados.PNG\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifiquemos las siguientes probabilidades y sus interpretaciones formulando la siguiente pregunta\n",
    "\n",
    "### Probabilidad Conjunta \n",
    "\n",
    "**Formula General:**\n",
    "\n",
    "$P(A\\cap B)$\n",
    "\n",
    "**¬øCual es la probabilidad de que ambos dados caigan en n√∫mero par?**\n",
    "\n",
    "Esta pregunta se puede responder de forma sencilla, considerando, que el espacio muestral de los 2 dados y sus 36 posibilidades solo tenemos 9 sucesos exitosos que cumplan con el.\n",
    "\n",
    "<img src=\"./img/dosdadospar.PNG\" width='500'>\n",
    "\n",
    "Entonces decimos que los estados o sucesos exitosos son 9 posibilidades de 36, por la tanto la probabilidad quedar√≠a como $\\frac{9}{36}$ y simplificado $\\frac{1}{4}$.\n",
    "\n",
    "- $\\displaystyle{P(par, par) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Esta probabilidad que corresponde a un suceso como tal, en realidad seria la uni√≥n de dos sucesos, es decir que el dado A haya ca√≠do en par y el dado B tambi√©n haya ca√≠do en par, por lo tanto corresponde a dos sucesos separados, que es lo que llamamos una probabilidad conjunta (joint)\n",
    "\n",
    "- $\\displaystyle{P(\\underbrace{\\underbrace{par}_{A}, \\underbrace{par}_{B}}_{\\text{Conjunta (joint)}}) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Una probabilidad conjunta es una probabilidad de dos o m√°s sucesos, que calculamos haciendo un conteo directo al espacio muestral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Condicional \n",
    "\n",
    "$P(A|B)$\n",
    "\n",
    "\n",
    "**¬øCual es la probabilidad es de que un dado caiga en par, sabiendo que el dado B ya cay√≥ en par?**\n",
    "\n",
    "Como ves, esta pregunta es ligeramente distinta a la pregunta anterior, ya que supone una condici√≥n previa que restringe el uso enter√≥ del espacio muestral.\n",
    " \n",
    "Ahora solo tenemos que considerar las situaciones donde ya sabemos que B es par\n",
    "\n",
    "<img src=\"./img/bpar.PNG\" width='400'>\n",
    "\n",
    "La parte de la pregunta que nos dice \"el dado B ya cay√≥ en par\", lo que hace es restringir el espacio muestral, teniendo antes 36 posibilidades a tener ahora solo 18 \n",
    "posibilidades.\n",
    "\n",
    "Entonces ahora que reducimos el espacio muestral, decimos ?cual es la probabilidad de que a caiga en par, sabiendo que b ya es par?.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}}}$\n",
    "\n",
    "Como esto impone una condici√≥n previa a este tipo de probabilidades con la barrita vertical [(\"|\" o \"tal que\")](https://es.wikipedia.org/wiki/Notaci%C3%B3n_matem%C3%A1tica#Expresiones), la definimos como Probabilidad Condicional.\n",
    "\n",
    "Habiendo ya restringido el espacio muestral, volveremos a realizar un conteo pero solo teniendo en cuenta el espacio restringido\n",
    "\n",
    "<img src=\"./img/bparR.PNG\" width='400'>\n",
    "\n",
    "El n√∫mero de sucesos exitosos no cambio, sino solo el n√∫mero de sucesos posibles por lo que el resultado con el espacio muestral reducido quedar√° tal que\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}} = \\frac{9}{18}}$\n",
    "\n",
    "As√≠ vemos que tenemos dos probabilidades distintas, para dos preguntas distintas. Pero entonces nos preguntamos...\n",
    "\n",
    "**¬øC√≥mo est√°n relacionadas estas probabilidades?**\n",
    "\n",
    "Resulta que podemos formular la pregunta de cu√°l es la probabilidad de que B caiga en par, esto seria una probabilidad tradicional, ya que no ponemos ninguna condici√≥n, donde disponemos del espacio muestral completo teniendo las 36 opciones disponibles, pero... ¬øcu√°ntos de √©sos sucesos corresponden al estado par?\n",
    "\n",
    "<img src=\"./img/bebesito fiu fiu.png\" width='400'>\n",
    "\n",
    "Entonces de la misma manera 36 opciones, donde tenemos 3 columnas con 6 sucesos que cumplen la premisa de la pregunta, d√°ndonos 18 sobre 36\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(B=par)}_{\\text{EM completo}} = \\frac{18}{36}}$\n",
    "\n",
    "Ahora vemos que tenemos 3 probabilidades que fueron los resultados de 3 preguntas diferentes, pero podemos decir que **la probabilidad conjunta del suceso A y B, es igual a la probabilidad condicional de A dado B, por, la probabilidad de B**\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)}_{\\text{conjunta}} = \\underbrace{P(A | B)}_{\\text{condicional}}  * \\underbrace{P(B)}_{\\text{prob de B}}}$\n",
    "\n",
    "Esto no es un caso particular del ejemplo dado, sino, que es una f√≥rmula general, **la Regla del Producto**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)=P(A|B)*P(B)}_{\\text{Regla del producto}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Marginal\n",
    "\n",
    "Es cuando se obtiene una probabilidad sencilla a partir de una probabilidad conjunta. Es decir cuando se tiene las probabilidades conjuntas de 2 sucesos y se quiere saber solo la probabilidad de que suceda el primer suceso independiente de lo que pasa con el otro, as√≠ eso se define como **la suma de todas la probabilidades conjuntas sobre los dem√°s estados que no est√° considerando A**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A) = \\Sigma p(A,B)}_{Marginal}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Por medio del juego de los dados logramos definir de forma natural tres tipos de probabilidades\n",
    "\n",
    "Primero definimos la **Probabilidad Conjunta** que como vimos, es una probabilidad que considera la ocurrencia de diferentes, pero simult√°neos eventos aleatorios.\n",
    "\n",
    "Luego esta se relaciona con la **Probabilidad Condicional** por medio de la Regla del Producto. Es importante aclarar que la probabilidad condicional **NO IMPLICA CAUSALIDAD**, es decir, que la probabilidad de que suceda A dado que sucedio B, no quiere decir que B sea la causa de A. Puede que en situaciones particulares ocurra, pero son dos conceptos diferentes.\n",
    "\n",
    "Con esto terminamos por decir que la **Probabilidad Marginal**, se obtienen haciendo sumas sobre ciertas variables aleatorias o ciertos sucesos sobre ciertas variables aleatorias dentro de la probabilidad conjunta. Siempre que hagamos sumas de probabilidades conjuntas y dejemos libre una de las variables, decimos que estamos obteniendo la probabilidad marginal de dicho evento aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de c√°lculo de probabilidad\n",
    "\n",
    "### Correlaci√≥n de eventos\n",
    "\n",
    "Con un par de ejemplos sencillos, buscaremos ganar m√°s intuici√≥n sobre el uso de la probabilidad, como calcularla y c√≥mo debemos interpretarlas. Aprenderemos c√≥mo la correlaci√≥n de eventos nos permite descubrir y aplicar asociaciones l√≥gicas entre distintos eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Juego de los Dados\n",
    "\n",
    "Para este ejemplo, tendremos en cuenta 3 eventos aleatorios:\n",
    "\n",
    "- $A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "- $B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "- $C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "Podr√≠amos preguntarnos sobre la probabilidades de cada uno de estos eventos, sin condicionarlos a la ocurrencia previa de otro evento.\n",
    "\n",
    "Veamos la diferencia entre la probabilidad condicionada entre uno u otros sucesos, y las probabilidades sin condicionar para ver qu√© conceptos surgen.\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "Dados nuestros tres sucesos, consideraremos nuestras probabilidades de una manera sencilla.\n",
    "\n",
    "Veamos en primer lugar una probabilidad tradicional.\n",
    "\n",
    "D√≥nde queremos saber cual es la probabilidad de que suceda A, sin ninguna condici√≥n adicional. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    " \n",
    "Al ser un dado, sabemos que las posibilidades son 6, y que caiga en 4 es solo una de ellas, por lo tanto decimos que la probabilidad de A, es un sexto:\n",
    "\n",
    "$\\displaystyle{ P(A)=\\frac{1}{6} \\rightarrow{16.6\\%}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlaci√≥n Positiva\n",
    "\n",
    "Que sucede, si ahora nos preguntamos, ? cual es la probabilidad de que suceda A, sabiendo que ya ha sucedido B?\n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Gramaticalmente esto lo traducir√≠amos a la vida real como el hecho de que lance una vez el dado, y cay√≥ en un n√∫mero par, provocando que nuestro espacio muestral se haya reducido, as√≠ que el n√∫mero de posibilidades ya no es 6, sino 3, y de esas 3, solo una posibilidad corresponde al evento exitoso. \n",
    "\n",
    "$\\displaystyle{P(A|B)=\\frac{1}{3} \\rightarrow 33.3\\%}$\n",
    "\n",
    "Por lo tanto decimos esta probabilidad condicional de que suceda A dado B, es mayor que la probabilidad tradicional de que suceda A, nos dice, que el hecho de que haya ocurrido B, aumenta la probabilidad de que ocurra A. Entonces es cuando decimos que los eventos A y B est√°n **positivamente correlacionados**.\n",
    "\n",
    "Recordemos el concepto de Correlaci√≥n de manera sencilla. La correlaci√≥n es lo que nos dice como dos variables, eventos, sucesos o activos se relacionan el uno al otro. ([Profundizar conceptos de Correlacion. Tema 3, Capitulo VI](https://deepnote.com/@mazzaroli/Estadistica-Descriptiva-para-Ciencias-de-Datos-b8622ee2-5fb0-44f3-8791-96915665574e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlaci√≥n Negativa\n",
    "\n",
    "Por otro lado tambi√©n podemos preguntarnos sobre cu√°l es la probabilidad de que suceda A sabiendo que ya sucedi√≥ C. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "$P(A|C) = ?$\n",
    "\n",
    "Entonces, si ya sabemos que C sucedi√≥, y el resultado es alg√∫n n√∫mero impar, vemos que el espacio muestral se vio limitado a estas opciones: $\\{1,3,5\\}$, y resulta que A solo puede ser el n√∫mero $\\{4\\}$.\n",
    "\n",
    "Como no hay una intersecci√≥n entre el  $\\{1,3,5\\}$ y el elemento $\\{4\\}$, esto representa sucesos excluyentes, por lo tanto quedamos con un intersecci√≥n o conjunto vac√≠o.\n",
    "\n",
    "$\\{1,3,5\\} \\cap  \\{4\\} = \\varnothing$\n",
    "\n",
    "Por lo tanto decimos que la condici√≥n $C$ reduce el espacio muestral, dici√©ndonos que los sucesos posibles son 3, pero los sucesos exitosos son 0, d√°ndonos una probabilidad de 0. Entonces decimos que la ocurrencia de $C$, redujo la ocurrencia de $A$, por lo tanto decimos que los eventos A y C est√°n **negativamente correlacionados**\n",
    "\n",
    "Que la probabilidad nos de 0, osea que los elementos sean Excluyente, no quiere decir que los elementos sean independientes, sino, son altamente dependientes\n",
    "\n",
    "$Excluyente \\neq Independiente$\n",
    "\n",
    "**Conclusi√≥n del Juego de los dados**\n",
    "\n",
    "Con este sencillo ejercicio evidenciamos como cuando dos eventos pueden estar tanto positivamente y negativamente correlacionados. Y concluimos en:\n",
    "\n",
    "- Correlaci√≥n Positiva es cuando la ocurrencia de un evento, **aumenta** la probabilidad de suceso de otro evento correlacionados\n",
    "\n",
    "- Correlaci√≥n negativa es cuando la ocurrencia de un suceso **disminuye** la probabilidad de ocurrencia del otro.\n",
    "\n",
    "- Dos elementos excluyentes, no son independientes, por lo contrario, tienen correlaci√≥n negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Juego de ruleta\n",
    "\n",
    "Para este ejemplo, usaremos el conocido juego de la ruleta que se pueden ver en muchos casinos, donde tendremos a dos jugadores, que cada uno apostar√° a cuatro n√∫meros dentro de las ocho posibilidades dentro del rango del espacio muestral.\n",
    "\n",
    "<img src=\"./img/ruleta.png\" width=\"400\">\n",
    "\n",
    "El conjunto del $jugador\\,1$ lo llamaremos como conjunto $A$ y al del $jugador\\,2$ conjunto $B$, donde diferenciaremos los conjuntos de n√∫meros que apostaron por el color rojo y azul.\n",
    "\n",
    "<img src=\"./img/ruleta color.png\" width=\"400\">\n",
    "\n",
    "Para facilitar el entendimiento del ejercicio, pasaremos a llamar los conjuntos de los jugadores a conjunto $A$ y $B$.\n",
    "\n",
    "$Jugador\\,1 \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 \\longrightarrow B = \\{5,6,7,8\\}$\n",
    "\n",
    "Aclarado esto, comenzamos el ejercicio pregunt√°ndonos:\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1?**\n",
    "\n",
    "En este caso, tanto los sucesos del $jugador\\,1$ y el $jugador\\,2$ son excluyentes, ya que sus apuestas son diferentes, por lo tanto no tienen un conjunto de intersecciones.\\\n",
    "Al analizar la probabilidad de que gane el $jugador\\,1$, est√° dada por las 8 casillas de la ruleta y de esas 8 posibilidades, solo 4 har√°n que gane el $jugador\\,1$.\n",
    "\n",
    "Quedando tal que:\n",
    "\n",
    "$P(A) = 4/8 = 1/2 = 50\\%$\n",
    "\n",
    "Pero... ¬øQu√© pasar√≠a si ahora agregamos una condici√≥n?\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Vemos que la condici√≥n de restringir el espacio muestral completo, al conjunto B, redujo el n√∫mero de eventos exitosos, teniendo como el n√∫mero de eventos exitosos igual a 0, ya que al no existir un punto de intersecci√≥n entre el conjunto A y B, no queda m√°s que un conjunto vac√≠o.\n",
    "\n",
    "$P(A|B) = \\frac{0}{4} = 0$\n",
    "\n",
    "Entonces evidenciamos un ejercicio de eventos excluyentes.\n",
    "\n",
    "____\n",
    "\n",
    "**¬øQu√© suceder√≠a si presentamos una situaci√≥n ligeramente diferente?**\n",
    "\n",
    "Donde el $Jugador\\,2$ cambie su apuesta al conjunto de n√∫meros 4,5,6,7 y el $Jugador\\,1$ mantiene su conjunto del principio.\\\n",
    "Quedando los conjuntos tal que: \n",
    "\n",
    "$Jugador\\,1 = {1,2,3,4} \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 = {4,5,6,7} \\longrightarrow B = \\{4,5,6,7\\}$\n",
    "\n",
    "Recuerda que en general lo que elija el $Jugador\\,1$ y el $Jugador\\,2$, no tienen porque tener haber relaci√≥n alguna entre sus apuestas, ya que cada uno est√° apostando a las posibilidades, donde cada uno eligi√≥ n√∫meros a su propio criterio.\n",
    "\n",
    "En este caso logramos ver que si ocurre una intersecci√≥n entre el conjunto del $Jugador\\,1$ y el nuevo conjunto del $Jugador\\,2$.\n",
    "\n",
    "<img src=\"./img/ruletaAyB.png\" width=\"500\">\n",
    "\n",
    "Entonces nos volvemos a preguntar...\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "Al igual que la vez anterior, **la condici√≥n B restringe el espacio muestral** a 4 de las 8 posibilidades, y la intersecci√≥n entre el conjunto A y B solo ocurre en una posibilidad, por lo tanto la probabilidad de A dado B quedar√≠a tal que:\n",
    "\n",
    "$P(A|B) = 1/4 = 25\\%$\n",
    "\n",
    "**¬øQu√© buscamos demostrar con este ejemplo?**\n",
    "\n",
    "Lo que queremos decir, es que gracias el conocimiento previo de saber que el $Jugador\\,2$ haya ganado, la probabilidad de que el $Jugador\\,1$ tambi√©n ganar√°, es del 25%.\\\n",
    "A diferencia de antes, cuando las probabilidades de que el $Jugador\\,1$ gan√©, sabiendo que el $Jugador\\,2$ gano, eran del 0%.\n",
    "\n",
    "**Conclusiones del Juego de la Ruleta**\n",
    "\n",
    "- La ocurrencia del conocimiento previo de que el jugador 2 haya ganado, lo que provoc√≥ fue que se reduzca la probabilidad de que el jugador 1 haya ganado. Por lo tanto sabemos que la coincidencia de los eventos A y B representan eventos que se encuentran negativamente correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reto para practicar\n",
    "\n",
    "Sabemos que el jugador 1 mantiene los n√∫meros que eligi√≥ al principio y jugador 2 cambio los suyos por el 2, 3, 6 y 7.\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el jugador 2 gano?**\n",
    "\n",
    "$jugador \\,1 = {1,2,3,4}$\\\n",
    "$jugador \\,2 = {2,3,6,7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos avanzados con probabilidad\n",
    "\n",
    "Continuaremos desarrollando ejemplos para \n",
    "\n",
    "### Paradoja ¬øni√±o o ni√±a?\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde el mayor es un var√≥n.\n",
    "1. Una mujer tiene dos beb√©s donde uno de ellos es var√≥n.\n",
    "\n",
    "Parecen parecidos pero no, en probabilidades cambia\n",
    "\n",
    "Tablero formulamos la siguiente pregunta\n",
    "\n",
    "Cual es la probabilidad de esta mujer tenga dos hijos varones.\n",
    "\n",
    "El fin del ejercicio es darse cuenta que la informaci√≥n de cada enunciado es diferente.\\\n",
    "Y para el c√°lculo de probabilidades de un ejerc q parece tan sencillo, primero deberemos calcular el espacio muestral, donde dibujaremos una matriz, donde en un eje se encontrar√°n los posibles g√©neros de un hijo, y en el otro eje los g√©neros del otro hijo.\n",
    "\n",
    "\n",
    "$\\underbrace{\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & MM  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}}_\\text{Espacio Muestral} \\hspace{3em} \\begin{matrix} F=Femenino \\\\ M=Masculino \\end{matrix}$\n",
    "\n",
    "Para dar un ejemplo, daremos que sin conocimiento previo nos preguntamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **¬øCual es la posibilidad de que una mujer tenga 2 hijos varones?**\n",
    "\n",
    "Tal cual lo presentamos sin ninguna condici√≥n, planteamos una probabilidad tradicional, y consideramos el espacio muestral completo, donde el n√∫mero de eventos posibles es $4$, y el n√∫mero de eventos exitosos es $1$.\n",
    "\n",
    "$\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & (MM)  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}$\n",
    "\n",
    "Y la probabilidad quedar√≠a tal que:\n",
    "\n",
    "$\\displaystyle{P(MM) = \\frac{1}{4}=25\\%}$\n",
    "\n",
    "Por lo tanto, la probabilidad es solamente de $\\frac{1}{4}$ sin ninguna condici√≥n previa, donde esta probabilidad no representa ni al caso 1 ni 2 mencionados anteriormente, sino simplemente a una situaci√≥n general donde no tenemos informaci√≥n previa al g√©nero de los hijos de dicha mujer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situaci√≥n 1\n",
    "\n",
    "Pero qu√© suceder√≠a si ahora imponemos la situaci√≥n donde tenemos la informaci√≥n previa de que el mayor de los hijos es un var√≥n. Entonces replantear√≠amos el ejercicio ahora de esta forma:\n",
    "\n",
    "**¬øCual es la probabilidad de que ambos hijos sean varones, sabiendo que el mayor es var√≥n?**\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor Var√≥n}) = ?$\n",
    "\n",
    "Con la informaci√≥n que tenemos podemos restringir el espacio muestral sabiendo que uno de los ejes (hijos) es el mayor, restringiendo el espacio muestral a solamente dos estados.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        FM & |MM|  \\\\\n",
    "        FF & |MF|  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Y de esta manera apreciamos que entre estos dos estados, solo uno satisface el enunciado. Quedando la probabilidad tal que:\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor M}) = \\frac{1}{2}=50\\%$\n",
    "\n",
    "Este resultado funciona bien con la situaci√≥n 1, pero ¬øQu√© diferencia existe entre la situaci√≥n 1 y 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situaci√≥n 2\n",
    "\n",
    "Comparemos la sutileza gramatical entre la situaci√≥n 1 y 2\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde <u>el mayor es un var√≥n</u>.\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde <u>uno de ellos es var√≥n</u>.\n",
    "\n",
    "La diferencia de decir entre el hijo mayor es var√≥n, y uno de ellos es var√≥n, implica que en realidad no sabemos cu√°l de ellos es var√≥n.\\\n",
    "Aunque escape de la intuici√≥n, este peque√±o cambio genera una diferencia en el espacio muestral, y lo demostraremos en la matriz para que se pueda apreciar el cambio del enunciado 2.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        [FM] & [MM]  \\\\\n",
    "        FF & [MF]  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "El hecho de decir que, uno de ellos es el var√≥n, representan 3 posibles estados en el espacio muestral, porque en cada uno de los ejes, al menos uno de los hijos es var√≥n.\n",
    "\n",
    "Cuando escribimos esto en la probabilidad, decimos, que la probabilidad de que ambos hijos sean varones, sabiendo que alguno de ellos es var√≥n es de un estado exitoso sobre tres posibles estados:\n",
    "\n",
    "$\\displaystyle{P(MM \\, | \\, \\text{alguno M}) = \\frac{1}{3} = 33.\\hat{3}\\%}$\n",
    "\n",
    "As√≠ podemos demostrar que las posibilidades de la situaci√≥n 1 y 2 son diferentes, aunque parezcan igual y se debe a que la cantidad de informaci√≥n que contiene cada frase debido a esa sutileza gramatical es diferente y esto determina distintos resultados en probabilidad.\\\n",
    "Donde en la situaci√≥n 1 la probabilidad de que los dos hijos sean varones es mayor, debido a la mayor cantidad de informaci√≥n dada en el enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de Monthy Hall\n",
    "\n",
    "<img src=\"https://m.media-amazon.com/images/M/MV5BNjUxNjMyZmUtYWE4Yi00Mzg2LWJkZmYtY2YyNjQ4ZmIyMGQwL2ltYWdlXkEyXkFqcGdeQXVyMTIxMDUyOTI@._V1_.jpg\" width=\"400\">\n",
    "\n",
    "En nuestra segunda paradoja trataremos el caso del programa de televisi√≥n *Let's make a deal*, dado por el conductor Monthy Hall, al que de se debe su nombre en probabilidad a esta paradoja, c√≥mo, **El problema de Monthy Hall**  \n",
    "\n",
    "El ejercicio consist√≠a en que el presentador le presentaba a un participante tres puertas, donde el participante ten√≠a que elegir una entre las tres posibles puertas, donde detr√°s de dos puertas no hab√≠a nada y solo en una hab√≠a un premio.\n",
    "\n",
    "En una situaci√≥n tradicional, el presentador le preguntar√≠a al participante que elija una puerta, entonces nos preguntariamos\n",
    "\n",
    "**¬øCual es la posibilidad de que el participante elija la puerta correcta?**\n",
    "\n",
    "Siendo una probabilidad tradicional, dibujaremos el espacio muestral y veriamo todas las opciones, donde podremos ver que las tres opciones inicialmente, todas son igualmente probables, por lo tanto el participante piense que la probabilidad de elegir la puerta correcta sea de un tercio por la naturaleza de la situaci√≥n.\n",
    "\n",
    "$\\displaystyle{\\begin{vmatrix} P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\\begin{matrix}  \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\ \\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\end{matrix}}$\n",
    "\n",
    "El truco del show era de que una vez que el participante eligiera una puerta, Monthy Hall abre una de las puertas (obviamente el presentador abrir√≠a una puerta sin recompensa, este era el punto de informaci√≥n adicional), luego de el presentador abriera la puerta sin recompensa, Monthy le preguntar√≠a al participante, que ahora cuenta de informaci√≥n adicional (la puerta que abri√≥ Monthy):\n",
    "\n",
    "Ahora que sabe que esta puerta no ten√≠a recompensa, ¬ømantiene la puerta que eligi√≥, o prefiere cambiar de puerta?\n",
    "\n",
    "Entonces, la intuici√≥n a primera vista nos hace decir:\n",
    "\n",
    "¬øCual es la probabilidad de que cambie de puerta y gane? o ¬øCu√°l es la probabilidad de que mantenga la puerta y gane?\n",
    "\n",
    "Dibujemos el espacio muestral para representar esta idea de forma m√°s visual:\n",
    "\n",
    "Este ser√≠a muestral antes de elegir una puerta\n",
    "\n",
    "$\n",
    "\\begin{vmatrix}P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Entonces digamos que elegimos la puerta 1, y el presentador abri√≥ la puerta 3 ya que esta no tiene premio. El espacio muestral se nos restringir√≠a a las situaciones donde la puerta 3 no tiene premios, quedando tal que\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{matrix}  \\\\\\longrightarrow 1/2 = 50\\% \\\\ \\longrightarrow 1/2 = 50\\% \\\\\\end{matrix}\n",
    "$\n",
    "\n",
    "Donde el n√∫mero de estados posibles ya no es 3, sino 2, quedando la probabilidad de √©xito de un medio.\\\n",
    "Entonces el razonamiento es que al tener 2 opciones donde solo 1 es de √©xito y ambas tienen 50% de posibilidades de ser la correcta, el participante asume que da igual si mantiene la puerta o no, ya que en ambas tiene 50% de probabilidad de ganar. Este es el primer razonamiento que se podr√≠a hacer con la intuici√≥n natural de las probabilidades, pero la paradoja es que esto es **falso**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øPor qu√© cambian las probabilidades?\n",
    "\n",
    "Pero... ¬øen realidad hay m√°s probabilidades de ganar si cambio la puerta una vez que el presentador haya descartado una?\n",
    "\n",
    "La respuesta es s√≠! Porque resultan en situaciones distintas, al igual que en el ejemplo anterior, las probabilidades pueden verse modificadas cuando hay una cambio en la cantidad de informaci√≥n disponible a la hora de tomar una decisi√≥n, y este cambio de informaci√≥n fue el hecho de que el presentador haya abierto la puerta, modificando la probabilidad de √©xito.\n",
    "\n",
    "Cambiemos el esquema mediante el cual ahora calcularemos nuestras nuevas probabilidades.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 0 \\\\ 0 \\\\ (üèÜ) \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 0 \\\\ (üèÜ) \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ (üèÜ) \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\hspace{1em}\n",
    "\\begin{matrix}   \\\\ üèÜ\\rightarrow \\text{premio} \\\\ üßî\\rightarrow \\text{participante} \\\\ üé§\\rightarrow \\text{presentador} \\\\ \\end{matrix}\n",
    "$\n",
    "\n",
    "\n",
    "En este nuevo diagrama consideraremos dos columnas nuevas, donde representar√° el caso de si mantenemos la misma puerta que elegimos, o el caso en que cambiemos la puerta sabiendo la informaci√≥n adicional que nos d√© el presentador.\n",
    "\n",
    "#### Situaci√≥n 1\n",
    "\n",
    "Entonces supongamos que elegimos la puerta 1 y el presentador abriera la puerta 2, ya que la 3 tiene el premio, por lo tanto no la abrir√≠a.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî   \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§   \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ   \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\    \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "¬øQue suceder√≠a en esta situaci√≥n?\n",
    "\n",
    "En esta situaci√≥n, si me mantuviera en la puerta 1, que es la que elegimos al principio, no ganariamos el premio, pero si la cambiamos al a puerta 3, entonces si lo ganariamos. Quedando el diagrama tal que: \n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚ùå \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚úÖ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Situaci√≥n 2\n",
    "\n",
    "\n",
    "Sigamos usando el mismo razonamiento con el siguientes caso, donde abrimos la puerta 1, y el presentador tendr√° que abrir la puerta 3, ya que en la puerta 2 se encuentra el premio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\  üßî  \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\  üèÜ  \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  üé§  \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\  ‚ùå  \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\  ‚úÖ  \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Donde si me quedo con la puerta que eleg√≠ perder√≠a, pero si la cambiara, ganaria.\n",
    "\n",
    "#### Situaci√≥n 3\n",
    "\n",
    "Y en la ultima situacion, seria que abriera la puerta 1 que contiene el premio, y daria igual la puerta que abriera el presentador, ya que ni la puerta 2 y 3 tienen premio, siendo el √∫nico caso donde si mantengo la puerta ganaria.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚úÖ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚ùå \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Resoluci√≥n\n",
    "\n",
    "Estas son las situaciones que tendr√≠amos que tener en cuenta para saber ¬øCual es la probabilidad de ganar si me quedo con la misma puerta?\n",
    "\n",
    "Para saber esto veamos la matriz completa de todas las situaciones que vimos en el ejercicio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî \\\\ üßî \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\\\ üèÜ \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ \\\\ üé§ \\\\ 0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚ùå \\\\ ‚ùå \\\\ ‚úÖ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚úÖ \\\\ ‚úÖ \\\\ ‚ùå \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Si nos hubi√©ramos quedado con la misma puerta que elegimos al principio, solo en un caso hubi√©ramos tenido la probabilidad de ganar de los tres casos, quedando tal que:\n",
    "\n",
    "$\\displaystyle{P(üèÜ|Mantener)= \\frac{1}{3}}$\n",
    "\n",
    "Pero a diferencia de si hubi√©ramos cambiado de puerta luego de la informaci√≥n adicional dada por el presentador, tendr√≠amos dos casos de eventos exitosos contra los tres que ten√≠amos.\n",
    "\n",
    "$\\displaystyle{P(üèÜ|Cambiar)= \\frac{2}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Con estos dos ejercicios demostramos que el c√°lculo de probabilidades, no siempre es intuitivo y que hay tener cuidado al entender cual es el espacio muestral sobre cual estamos trabajando, dado que tengamos informaci√≥n adicional, o no, sobre cierta situaci√≥n a la cual realizaremos el c√°lculo de probabilidades.\n",
    "\n",
    "Con estos dos ejercicios dimos el inicio para desarrollar nuestra intuici√≥n probabil√≠stica!\n",
    "\n",
    "[Video explicativo Monthy Hall - Javie Santaolla](https://www.youtube.com/watch?v=1BpTBzDQuRE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 3: Distribuciones de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es una distribuci√≥n? \n",
    "\n",
    "**¬øQu√© es una distribuci√≥n de probabilidad?**\n",
    "\n",
    "**Es una funci√≥n**, en el sentido matem√°tico del c√°lculo, **donde a cada uno de los posibles estados de una variable aleatoria dentro del espacio muestral**, se le asigna una probabilidad.\n",
    "\n",
    "Como ejemplo tenemos el ejercicio del dado que tiene un espacio muestral de 6 posibles estados, y cada uno de esos estados tiene una probabilidad de \\frac{1}{6},  en este caso esta distribuci√≥n ser√≠a una funci√≥n constante, donde a cada estado se le asigna un valor, siendo la misma, una funci√≥n discreta.\n",
    "\n",
    "En general **mencionaremos a la $X$ may√∫scula como una variable aleatoria**, donde **$P$, ser√° la funci√≥n**, que a cada una de las ocurrencias o valores posibles de esta variable aleatoria, se le asignar√° un n√∫mero que denominaremos la probabilidad.\n",
    "\n",
    "\n",
    "$X \\, aleatoria \\longrightarrow \\underbrace{P(X = x)}_\\text{probabilidad de ocurrencia}$\n",
    "\n",
    "De esta manera comprendemos que **$P$ es funci√≥n de la variable aleatoria**\n",
    "\n",
    "$P=f(X)$\n",
    "\n",
    "Una convenci√≥n en probabilidad, es que, las **letras may√∫sculas denotan las variables**, mientras que las **letras min√∫sculas denotar los posibles valores que estas variables aleatorias pueden tomar**.\n",
    "\n",
    "$X \\rightarrow \\text{variable aleatoria}$\\\n",
    "$x \\rightarrow \\text{valores posibles en el espacio muestral}$\n",
    "\n",
    "Al igual que sucede en el c√°lculo, las funciones poseen un Dominio.\n",
    "\n",
    "El dominio viene por **todos los valores posibles de la variable aleatoria por la cual la funci√≥n puede ser calculada**, donde estos dominios podr√°n as√≠ dividirse en conjuntos discretos o continuos, **donde tendremos tanto funciones discretas o funciones continuas.**\n",
    "\n",
    "$\n",
    "Dom(X) = \n",
    "     \\begin{cases}\n",
    "        Discreto, &\\quad \\{1,2,3,4,5,6\\} \\\\\n",
    "        \\\\\n",
    "        Continuo,  &\\quad [0,\\infty] \\\\\n",
    "     \\end{cases}\n",
    "$\n",
    "\n",
    "[Articulo dedicado a Funciones Matematicas para Ciencias de Datos](https://deepnote.com/@mazzaroli/Introduccion-a-Funciones-Matematicas-para-Data-Science-e-Inteligencia-Artificial-f9a47b52-0308-4e95-a3d3-c3de3ef7b14f)\n",
    "\n",
    "Un ejemplo de una distribuci√≥n discreta podr√≠a usarse de ejemplo el juego de los dados, porque los valores tienen un n√∫mero finito de estados, donde tenemos a las 6 caras del dado, y la variable aleatoria ser√≠a la cara que me dar√≠a el dado como resultado. \n",
    "\n",
    "A diferencia de las variables aleatorias que pueden ser continua, por ejemplo, la temperatura, ya que puede considerarse como una variable aleatoria y es continua, porque no precisa necesariamente tener que ser un n√∫mero entero, sino, que puede ser un valor decimal cualquiera dentro de un rango definido.\n",
    "\n",
    "Profundizaremos sobre los aspectos matem√°ticos de estas funciones particulares, que llamamos distribuciones de probabilidad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuci√≥n de Probabilidad\n",
    "\n",
    "Coincidiremos a $X$ mayuscula como una variable aleatoria donde $P$ de $X$, ser√° una \n",
    "funci√≥n de distribuci√≥n de probabilidad, o tambi√©n conocida como [**densidad de probabilidad**](https://es.wikipedia.org/wiki/Funci%C3%B3n_de_densidad_de_probabilidad)\n",
    "\n",
    "$\\displaystyle{X \\rightarrow P(X) \\rightarrow \\text{densidad de probabilidad}}$\n",
    "\n",
    "Donde **$P(X)$ puede tener un car√°cter discreto o un car√°cter continuo**, que estar√°n determinados por los valores posibles de la variable aleatoria $X$\n",
    "\n",
    "$\n",
    "P(X) \n",
    "    \\begin{cases}\n",
    "    Discreto\\\\\n",
    "    \\\\\n",
    "    Continuo\\\\\n",
    "    \\end{cases}\n",
    "$\n",
    "\n",
    "Como toda funci√≥n, se puede graficar, as√≠ que cuando una distribuci√≥n de probabilidad es continua, podemos describirlo como una distribuci√≥n gaussiana en un plano de ejes cartesianos, donde dado un punto $x$ ($x$ min√∫scula = ocurrencia de un valor espec√≠fico dentro del conjunto de variables), la imagen, dada la funci√≥n, es la probabilidad de que ocurra ese valor particular\n",
    "\n",
    "<img src='./img/dist normal.png' width='300'>\n",
    "\n",
    "Y como toda funci√≥n en calculo, la podemos derivar o integrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integral de una distribuci√≥n\n",
    "\n",
    "**¬øQu√© significa la integral de una distribuci√≥n?**\n",
    "\n",
    "Al igual que podemos preguntarnos _¬øCu√°l es la probabilidad de que la variable tenga un valor en particular?_ que seria haciendolo con la funci√≥n de densidad de probabilidad.\n",
    "\n",
    "$P(X=x)=?$\n",
    "\n",
    "Tambi√©n podemos preguntarnos \n",
    "\n",
    "**¬øCu√°l es la probabilidad de que mi variable aleatoria tenga valores menores o iguales que un valor espec√≠fico dado?**\n",
    "\n",
    "$P(X\\leq x)=?$\n",
    "\n",
    "Para calcular esto, debemos recordar los conceptos de c√°lculo integral, donde ser√≠an todos los valores que se encuentre por detr√°s del valor umbral, y esto es lo que llamamos en c√°lculo, un √°rea bajo la curva\n",
    "\n",
    "<img src='./img/area curva.png' width='300'>\n",
    "\n",
    "As√≠ es como sabemos que este tipo de probabilidades ($P(X\\leq x)$) est√°n dadas por una integral en funci√≥n de la distribuci√≥n.\\\n",
    "Donde decimos que la probabilidad de que mi variable aleatoria tome valores menores o iguales que un cierto valor espec√≠fico, est√° dado por la integral de mi distribuci√≥n de probabilidad $P$ de $X$, respecto a la variable de $X$, integrando sobre todos los posibles valores que sean menores o igual que $x$.\n",
    "\n",
    "$\\displaystyle{P(X\\leq x) = \\int\\limits_{X\\leq x}P(X)dX}$\n",
    "\n",
    "Esto es una integral, es el √°rea debajo de la curva y tambi√©n representa una probabilidad.\n",
    "\n",
    "En general decimos **cuando $x$ min√∫sculo no es un valor num√©rico**, sino, un valor cualquiera dado que p**uede considerarse como un par√°metro, esto determinar√°** una nueva funci√≥n que llamamos **la Distribuci√≥n Acumulada** $C(X)$\n",
    "\n",
    "$\\displaystyle{P(X\\leq \\underbrace{x}_{parametro}) = \\int\\limits_{X\\leq x}P(X)dX}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funci√≥n de distribuci√≥n acumulada\n",
    "\n",
    "Entonces decimos que **la distribuci√≥n acumulada, representa la probabilidad de que mi variable aleatoria tome valores menores o iguales que esta $x$ dada, lo que llamamos una funci√≥n de probabilidad acumulada.**\n",
    "\n",
    "$\\displaystyle{P(X\\leq \\underbrace{x}_{parametro}) = \\int\\limits_{X\\leq x}P(X)dX = C(x) \\longleftarrow Funci√≥n \\, Probabilidad \\, Acumulada}$\n",
    "\n",
    "**La interpretaci√≥n de la funci√≥n de probabilidad acumulada, es la integral de la funci√≥n de densidad de probabilidad.**\\\n",
    "**Y sirve para** responder el tipo de preguntas que surgen cuando no nos preguntamos por un valor en particular de la probabilidad, sino, **cuando nos referimos a un rango dentro de la probabilidad**, por ejemplo:\n",
    "\n",
    "**¬øCual es la probabilidad de que al tirar un dado el resultado sea un n√∫mero menor o igual a x?**\n",
    "\n",
    "Por ejemplo, cu√°l es la probabilidad de que al tirar un dado el resultado sea un n√∫mero menor o igual al 2, *donde este ejemplo espec√≠ficamente se trata de una funci√≥n discreta*.\n",
    "\n",
    "**La funci√≥n de probabilidad acumulada tambi√©n se utiliza para funciones discretas**, solo que en este caso, la gr√°fica en el plano cartesiano ya no se ver√≠a como una curva suave, sino, como un histograma.\\\n",
    "Donde cada una de sus caras tendr√° una probabilidad, que ser√≠a la frecuencia con la que ocurrir√≠a cada uno de estos eventos.\n",
    "\n",
    "<img src='./img/histograma.png' width='300'>\n",
    "\n",
    "**Cuando queremos calcular la probabilidad acumulada de una funci√≥n discreta**, porque queremos responder la misma pregunta sobre ¬øCu√°l es la probabilidad de que mi variable aleatoria tomar√° valores menores o iguales de cierto valor? **ya no se usar√≠an integrales, sino, sumas discretas**, donde sum√≥ todas las probabilidades en las que mi variable aleatoria tenga los valores menores o iguales al par√°metro de referencia. \n",
    "\n",
    "$\\displaystyle{P(X\\leq x) = \\sum_{X\\leq{x}}P(X) \\longrightarrow Funci√≥n \\, Probabilidad \\, Acumulada}$\n",
    "\n",
    "Esta tambi√©n forma parte de la definici√≥n de **Probabilidad Acumulada**, pero es la funci√≥n para los casos de **funciones discretas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reto\n",
    "\n",
    "Desarrolla una expresi√≥n matem√°tica para el siguiente caso:\n",
    "\n",
    "¬øCual es la probabilidad de que mi variable aleatoria tome valores entre dos umbrales?\n",
    "\n",
    "$P(a \\leq X \\leq b)=?$\n",
    "\n",
    "Pista:\\\n",
    "Consideramos este caso como una <u>variable aleatoria continua</u>, donde tengo el umbral entre a y b\n",
    "\n",
    "<img src='./img/integral.png' width='300'>\n",
    "\n",
    "### Soluci√≥n\n",
    "\n",
    "$\\displaystyle{P(a \\leq X \\leq b)\\hspace{1em}=\\hspace{1em} \\int\\limits^{b}_{a}P(X)dx\\hspace{1em}=\\hspace{1em}P(b)-P(a)\\hspace{1em}=\\hspace{1em}C(X)}$\n",
    "\n",
    "### Conclusi√≥n\n",
    "\n",
    "**La probabilidad** es un campo que **depende** mucho **de los elementos del c√°lculo**, porque esas funciones que nos permiten determinar probabilidades sobre los diferentes estados de una variable aleatoria, son espec√≠ficamente las que definimos en el c√°lculo sobre un punto de vista matem√°tico, **tales como sus propiedades matem√°ticas de derivacion e integracion que se aplican sobre funciones normales en c√°lculo, pueden ser aplicadas en probabilidad.**\\\n",
    "En el caso particular de la distribuci√≥n de distribuci√≥n acumulada, que es la integral de la funci√≥n de la densidad de probabilidad.\n",
    "\n",
    "Pero no te asustes! porque estas son las bases para que entiendas los mecanismos detr√°s del c√°lculo de probabilidad, pero en la pr√°ctica, pasaremos al c√≥digo con Python para desarrollar esto como lo har√≠a todo un cient√≠fico de datos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones discretas \n",
    "\n",
    "Profundizaremos en como trabajar con distribuciones discretas, tales como el lanzamiento de monedas y dados, donde para este tipo de ejercicios, surge de manera natural la **distribuci√≥n de Bernoulli**.\n",
    "\n",
    "### Distribuci√≥n de Bernoulli\n",
    "\n",
    "Una distribuci√≥n de Bernoulli es una funci√≥n que asigna a la variable binaria dos valores, cuando $X$ sea igual a 1 (√©xito) ocurre con la probabilidad $p$, donde p valdr√≠a 0,5 dado un caso de probabilidad equilibrada, y cuando $X$ sea igual a 0 (fracaso) se representa con la probabilidad de $1 - p$, porque la suma de las probabilidades tiene que dar el 100%.\\\n",
    "Se dice que la variable aleatoria $X$, se distribuye como una Bernoulli de par√°metro $p$ con $0 <p < 1$\n",
    "\n",
    "#### F√≥rmula de Bernoulli\n",
    "$\n",
    "P(X=1)=p\\\\\n",
    "P(X=0)=1-p\\\\\n",
    "0<p<1\n",
    "$\n",
    "\n",
    "Desde la definici√≥n de esta funci√≥n, podemos empezar a considerar situaciones m√°s complejas con base al ejercicio de lanzar monedas, pero... no te preguntas sobre ¬øc√≥mo podemos hacer m√°s complejo lanzar una moneda?, si solo hay 2 posibilidades del 50%, la respuesta es lanzar una $n$ cantidad de monedas, 2, 3, 4 o las que yo quiera.\n",
    "\n",
    "Por lo tanto, decimos que cuando tenemos secuencias repetitivas de eventos binarios (eventos tipo Bernoulli), es cuando tenemos que hablar de la famosa **Distribuci√≥n binomial**, entonces en este punto es cuando empezaremos a desarrollar sus pasos precedentes, hasta poder entender de forma natural y sencilla sobre como surgen de manera fundamental las distribuciones binomiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo Distribuci√≥n Bernoulli\n",
    "\n",
    "##### Caso 1\n",
    "\n",
    "Podemos decir que tenemos tres monedas que lanzaremos 1 vez cada una o que lanzaremos la misma moneda tres veces, donde la probabilidad de que obtengamos cara y cruz en cada lanzamiento es igualmente probable en ambos casos. \n",
    "\n",
    "Entonces nos preguntamos:\n",
    "\n",
    "**¬øCu√°l es la probabilidad de 3 lanzamientos de una monedas, en 2 de esos 3 lanzamientos obtengamos cara?**\n",
    "\n",
    "Al graficar y contar las combinaciones, vemos que existen 8 posibles escenarios al lanzar las monedas:\n",
    "\n",
    "<img src='./img/moneda.png' width='350'>\n",
    "\n",
    "As√≠ sabemos que trabajamos con un espacio muestral de 8 posibilidades, y de esas 8 solo en 3 casos obtendr√≠amos 2 caras. \n",
    "\n",
    "<img src='./img/caras.png' width='350'>\n",
    "\n",
    "Por lo tanto, decimos que la probabilidad de lanzar 3 veces una moneda y obtener 2 caras es de:\n",
    "\n",
    "$\\displaystyle{P(2\\, Caras|3\\, Lanzamientos)=\\frac{3}{8}}$\n",
    "\n",
    "Asumimos en esta situaci√≥n que la probabilidad de obtener cara o cruz, es igualmente probable en cada lanzamiento, porque esta es la hip√≥tesis con la que hemos trabajado desde el principio del art√≠culo, donde decimos que hay probabilidades fundamentales que son axiom√°ticas y, por lo tanto, asumimos que son igualmente probable.\\\n",
    "Pero en caso de la distribuci√≥n de Bernoulli, cuando esto no sucede, definimos el n√∫mero $p$ min√∫scula, que asigna la probabilidad de uno u otro suceso.\n",
    "\n",
    "*En la vida real este par√°metro se ajusta acorde los datos que obtengamos en pr√°ctica de X experimento.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Caso 2\n",
    "\n",
    "Si complicamos el caso de la distribuci√≥n binomial, donde ya no nos pregunt√°ndonos por 3 lanzamientos de monedas, sino, por $n$ lanzamientos, donde $n$ podr√≠a ser un n√∫mero muy grande, y de esos $n$ lanzamientos, podemos tener $k$ caras, que es la variable donde definiremos cuantas caras queremos tener seg√∫n el n√∫mero $n$ de lanzamientos.\n",
    " \n",
    "$\\displaystyle{P(K=Caras\\;|\\;n=Lanzamientos)=?}$\n",
    "\n",
    "En este punto vemos que la formula se complica, ya que mientras m√°s lanzamientos haya, el espacio muestral $(EM)$ crece de manera mayor que la exponencial.\n",
    "\n",
    "[Calcular espacio muestral para una n cantidad de probabilidades](https://es.wikipedia.org/wiki/Espacio_muestral#Procesos_estoc%C3%A1sticos_finitos_y_diagramas_de_%C3%A1rbol)\n",
    "\n",
    "Entonces en este punto nos preguntamos:\n",
    "\n",
    "**¬øExiste alguna f√≥rmula general para contar todos estos posibles estados y sobre ellos hacer el conteo de probabilidades?**\n",
    "\n",
    "La respuesta es claro que si, de esto es lo que se trata espec√≠ficamente <u>la funci√≥n de distribuci√≥n binomial.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducci√≥n a la distribuci√≥n binomial\n",
    "\n",
    "Volviendo a nuestro problema de los 3 lanzamientos de una moneda, usaremos la letra $k$ para definir el n√∫mero de caras o sucesos exitosos, que queremos obtener a partir de los $n$ lanzamientos.\n",
    "\n",
    "Veamos como ser√≠a la distribuci√≥n binomial de este problema, donde ya sabemos que es binomial, pero...\n",
    "\n",
    "**¬øQu√© quiere decir que una distribuci√≥n sea binomial exactamente?**\n",
    "\n",
    "Gr√°ficamente sabemos que cuando una [distribuci√≥n es discreta](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_probabilidad#Distribuciones_de_variable_discreta), la gr√°fica tendr√° forma de un [diagrama de barras o histograma](https://es.wikipedia.org/wiki/Histograma), donde cada barra representa la [frecuencia relativa](https://es.wikipedia.org/wiki/Frecuencia_estad%C3%ADstica#Frecuencia_relativa) de un evento posible en el eje X.\n",
    "\n",
    "Entonces decimos que los eventos posibles son el resultado que podemos obtener de cada lanzamiento: **0 caras, 1 cara, 2 caras y como m√°ximo 3 caras**.\\\n",
    "Estas son las 4 posibilidades sobre las que podemos calcular las frecuencias relativas.\n",
    "\n",
    "<img src='./img/barras.png' width='300'>\n",
    "\n",
    "De todos los eventos, sabemos que tenemos 8 posibilidades, que ser√≠a nuestro espacio muestral.\n",
    "\n",
    "<img src='./img/monedabinomial.png' width='300'>\n",
    "\n",
    "\n",
    "Entonces... **¬øCu√°ntas opciones del EM resultan en 0 caras, en 1 cara, 2 caras y 3 cars?**\n",
    "\n",
    "Como vemos en el gr√°fico del espacio muestral, solo en un caso tenemos 0 caras, en 3 casos tenemos 1 y 2 caras, y en solo un caso tenemos 3 caras.\\\n",
    "Quedando la probabilidad quedar√≠a tal que:\n",
    "\n",
    "Donde:\\\n",
    "$\\displaystyle{P(k= cara ,\\; n= lanzamientos) = \\frac{k}{EM}}$\n",
    "\n",
    "$\n",
    "\\displaystyle{P(0,3) = \\frac{1}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(1,3) = \\frac{3}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(2,3) = \\frac{3}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(3,3) = \\frac{1}{8}}\n",
    "$\n",
    "\n",
    "\n",
    "<img src='./img/monedabinomialposibilidades.png' width='800'>\n",
    "\n",
    "De esta forma podemos reflejar el concepto de como se ver√≠a la distribuci√≥n binomial para este caso en particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinatorio o Coeficiente binomial\n",
    "\n",
    "Volviendo a la pregunta inicial.\n",
    "\n",
    "**¬øExiste alguna f√≥rmula general para contar todos estos posibles estados y sobre ellos hacer el conteo de probabilidades?**\n",
    "\n",
    "¬°Y como ya mencionamos antes, si disponemos una f√≥rmula general! \n",
    "\n",
    "En matem√°ticas contamos con un elemento que son los [coeficientes binomiales, **n√∫meros combinatorios** o combinaciones](https://es.wikipedia.org/wiki/Coeficiente_binomial) son n√∫meros estudiados en [matem√°ticas combinatoria](https://es.wikipedia.org/wiki/Combinatoria) que corresponden al n√∫mero de formas en que se puede extraer subconjuntos a partir de un conjunto dado.\\\n",
    "**El n√∫mero combinatorio $\\binom{n}{k}$ es el n√∫mero de subconjuntos $k$ elementos que satisfacen algun requisito de un conjunto con $n$ elementos, y el subconjunto $k$ tiene que ser menor que el conjunto $n$.**\n",
    "\n",
    "#### **F√≥rmula del Combinatorio:**\n",
    "\n",
    "$\\displaystyle C_{n}^{k} = \\binom {n}{k}=\\frac {n!}{k!\\cdot (n-k)!}$\n",
    "\n",
    "donde:\\\n",
    "$\n",
    "n = \\text{n√∫mero de intentos} \\\\\n",
    "k = \\text{n√∫mero de aciertos} \\\\\n",
    "r \\leq n \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo Combinatorio o Coeficiente binomial\n",
    "\n",
    "Ahora que sabemos que existe una manera de contar de forma general todos los posibles estados dentro de un espacio muestral, pasaremos con un ejemplo para ver como nos ayuda a conocer la probabilidad de √©xito donde:\n",
    "\n",
    "**Queremos obtener la probabilidad de obtener $\\pmb{k}$ veces cara, dado $\\pmb{n}$ lanzamientos.**\n",
    "\n",
    "donde:\\\n",
    "$n = 3$\\\n",
    "$k = 1$\n",
    "\n",
    "Donde la probabilidad quedar√≠a tal que:\n",
    "\n",
    "$P(1,3)=?$\n",
    "\n",
    "Usando el Combinatorio pasaremos a contar los posibles estados de √©xito de obtener 1 cara dado 3 lanzamientos de una moneda quedando tal que:\n",
    "\n",
    "$\\displaystyle\n",
    "P(k,n) \\rightarrow C^{n}_{k}\n",
    "$\n",
    "\n",
    "Donde sabemos que $n$ es el n√∫mero de lanzamientos que son 3 y $k$ ser√≠a el n√∫mero de √©xitos dado $n$ que es 1:\n",
    "\n",
    "${\\displaystyle P(1,3) \\longrightarrow C^{3}_{1} = {\\binom {3}{1}} = {\\frac {3!}{1!\\cdot (3-1)!}} = {\\frac {1*2*3}{1* 1*2}} = {\\frac {\\cancel{1}*\\cancel{2}*3}{\\cancel{1}*\\cancel{2}}} = 3}$\n",
    "\n",
    "As√≠ es como sabemos las posibles maneras de obtener este resultado, que es 3.\n",
    "\n",
    "Por √∫ltimo d√©cimos que la probabilidad est√° dada por el resultado del combinatorio entre el espacio muestral total, que es 8, ya que son todos los estados posibles de lanzar 3 veces una moneda.\n",
    "\n",
    "${\\displaystyle P(k,n) = \\frac{C}{EM} \\longrightarrow P(3,1) = \\frac{3}{8}}$\n",
    "\n",
    "Entonces vemos que a trav√©s de la f√≥rmula combinatoria somos capaces de contar los estados dado dicho evento y lo podemos demostrar, comparando el resultado que obtuvimos con el gr√°fico de la distribuci√≥n binomial que realizamos anteriormente, donde la barra que reflejaba la probabilidad de obtener 1 cara de 3 lanzamientos de una moneda era de $\\frac{3}{8}$.\n",
    "\n",
    "As√≠ a trav√©s del s√≠mbolo combinatorio que nos permite contar los estados posibles, podemos desarrollar el c√°lculo de conteo de probabilidades, de esta manera dando paso a la introducci√≥n de la f√≥rmula general de Distribuci√≥n Binomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuci√≥n Binomial\n",
    "\n",
    "Definimos a la distribuci√≥n binomial o distribuci√≥n bin√≥mica como una distribuci√≥n de probabilidad discreta que cuenta el n√∫mero de √©xitos en una secuencia de ${\\displaystyle n}$ ensayos de Bernoulli independientes entre s√≠, con una probabilidad fija ${\\displaystyle p}$ de ocurrencia de √©xito entre los ensayos.\n",
    "\n",
    "Decimos que la probabilidad de un suceso part√≠cula, es igual al n√∫mero de estados que conducen a ese suceso, multiplicado por la probabilidad de cada estado individual:\n",
    "\n",
    "$p \\rightarrow suceso \\rightarrow  p *  estados \\, suceso $\n",
    "\n",
    "Usando el ejemplo de las monedas:\n",
    "\n",
    "Donde sabemos que el n√∫mero 3 son los estados exitosos que obtuvimos a partir del combinatorio $C^n_k$ y la probabilidad de individual de cada uno de los estados es de $\\frac{1}{8}$.\n",
    "\n",
    "Qued√°ndonos el resultado tal que:\n",
    "\n",
    "${\\displaystyle  p =\\frac{1}{8} * 3 = \\frac{3}{8}}$\n",
    "\n",
    "Estas probabilidades estar√≠an dadas por la f√≥rmula general que encontramos en la literatura como la Distribuci√≥n Binomial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desarrollo f√≥rmula Distribuci√≥n Binomial \n",
    "\n",
    "Cuando tengamos una probabilidad que dados de $n$ intentos, y queramos obtener $k$ resultados, el n√∫mero de estados exitosos es igual a $n$ combinado $k$.\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k}}$\n",
    "\n",
    "Esto lo que quiere decir es que de una $n$ cantidad de estados, solo habr√° una cantidad $k$ de estados que satisfagan los resultados deseados y cada estado $k$ tendr√° una probabilidad $p$\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "De lanzar una $n$ cantidad de monedas, solo habr√° una $k$ cantidad que caiga en cara, donde cada una de esas $k$ monedas tendr√° una probabilidad $p$.\n",
    "\n",
    "$\\displaystyle{\\overbrace{\\underbrace{coin}_k ,\\underbrace{coin}_k ,\\underbrace{coin}_{\\underbrace{k}_p},\\cdots ,coin ,coin ,coin,coin}^{n}}$\n",
    "\n",
    "Asumimos que p para el caso ideal tendr√≠a una probabilidad de 1/2, pero puede que esto no sea as√≠, denotamos la letra $p$ por si las probabilidades no se encuentran balanceadas y multiplicamos la probabilidad de cada uno de estos eventos, que ser√≠a la probabilidad e la primera moneda, por la probabilidad de la segunda, la tercera y as√≠ considerando a todas las $k$, que ser√≠a equivalente a elevar la probabilidad $p$ a la $k$.\n",
    "\n",
    "$\n",
    "p(k_1) \\hspace{0.5em} * \\hspace{0.5em}\n",
    "p(k_2) \\hspace{0.5em} * \\hspace{0.5em}\n",
    "\\dots \\hspace{0.5em} * \\hspace{0.5em}\n",
    "p(k_n) \\hspace{0.5em} = \\hspace{0.5em}\n",
    "p^k\n",
    "$\n",
    "\n",
    "Quedando la formula general tal que:\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k} p^{k} }$\n",
    "\n",
    "Si la probabilidad de que el evento individual √©xito es p, decimos que la probabilidad del evento fallido es $q=1-p$ tal cual vimos en la distribuci√≥n de Bernoulli.\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k} p^{k} q}$\n",
    "\n",
    "De misma manera debemos descubrir la probabilidad de cada evento no exitoso, lo cual resolvemos multiplicando la probabilidad de cada uno de estos e igualmente ser√≠a equivalente a elevar $q$ por el n√∫mero de todos los eventos no exitosos.\n",
    "\n",
    "Para saber cuantos eventos fallidos quedaron, simplemente tenemos que restarle a la totalidad de eventos $n$ realizados, la cantidad de eventos exitosos $k$. \n",
    "\n",
    "$\\displaystyle{\\overbrace{\\underbrace{coin ,coin ,coin }_{k},\\underbrace{\\cdots ,coin ,coin ,coin,coin}_{n-k}}^{n}}$\n",
    "\n",
    "Por lo tanto, la probabilidad de fracaso quedar√≠a elevado a la n-k \n",
    "\n",
    "Qued√°ndonos la formula tal que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F√≥rmula de Distribuci√≥n Binomial\n",
    "\n",
    "${\\displaystyle P(X) = {\\binom {n}{k}p^{k}q^{n-k}} = {\\frac {n!}{k!\\cdot (n-k)!}\\,p^{k}q^{n-k}} }$\n",
    "\n",
    "Y as√≠ es como damos a la f√≥rmula de la Distribuci√≥n Binomial\n",
    "\n",
    "donde:\\\n",
    "$n = \\text{n√∫mero de intentos}$\\\n",
    "$k = \\text{n√∫mero de aciertos}$\\\n",
    "$p = \\text{probabilidad de √©xito en un intento}$\\\n",
    "$q = (1-p) \\hspace{0.5em} \\text{probabilidad de fracaso en un intento}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusi√≥n\n",
    "\n",
    "As√≠ es como definimos a la distribuci√≥n binomial, como, una distribuci√≥n o funci√≥n de densidad de probabilidad, donde podemos calcular de una secuencia de eventos de tipo Bernoulli cuantos √©xitos puedo tener de variables binarias.\n",
    "\n",
    "- $\\displaystyle{P(k\\; caras\\;|\\;n\\; lanzamientos)}$\n",
    "\n",
    "- $\\displaystyle{P(k;n,p) = \\binom{n}{k}p^k(1-p)^{n-k}}$\n",
    "\n",
    "Esta no es la √∫nica distribuci√≥n que podemos trabajar con variables aleatorias binarias, ya que existen varias.\\\n",
    "Donde tambi√©n existen casos de variables aleatorias discretas no binarias, como por ejemplo la distribuci√≥n multinomial, que es la generalizaci√≥n natural de la binomial.\n",
    "\n",
    "Formula general de Distribuci√≥n multinomial\n",
    "\n",
    "$\\displaystyle{P(X_1,\\cdots,X_n) = \\frac{n!}{k_1!,\\dots,k_n!}P_1^{k_1},\\dots,P_n^{k_n} }$\n",
    "\n",
    "No profundizaremos en la distribuci√≥n multinomial, porque lo importante es entender que existen otras distribuciones para variables discretas, con nombres interesantes que podr√°s impactar y asustar a tus amigos con simplemente nombrarlas.\n",
    "\n",
    "Otras distribuciones\n",
    "\n",
    "- [Poisson](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_Poisson)\n",
    "- [Geom√©trica](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_geom%C3%A9trica)\n",
    "- [Hipergeom√©trica](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_hipergeom%C3%A9trica)\n",
    "- [Binomial negativa](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_binomial_negativa)\n",
    "- [t de Student]()\n",
    " \n",
    "Entonces nos surge la duda de ¬øC√≥mo sabremos cuando usar cada distribuci√≥n habiendo tantas?, la verdad es que existen ciertas experiencias, investigaciones y experimentos aleatorios donde cada una de estas distribuciones se aplican de manera √≥ptima.\n",
    "\n",
    "En el siguiente cap√≠tulo veremos que hay casos donde tenemos un conjunto de datos particular y no sabemos al comienzo su distribuci√≥n, aprenderemos que existen t√©cnicas para ajustar la mejor distribuci√≥n de probabilidad al conjunto de datos que tengamos.\n",
    "\n",
    "¬°Ya que en la vida real no sabemos exactamente las distribuciones en probabilidad y en conjuntos de datos, sino que tendremos que aprenderlas y tendremos ayuda de algoritmos que aprenden la distribuci√≥n a partir de los datos, dando as√≠ el inicio al Machine Learning probabil√≠stico!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando la distribuci√≥n binomial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import binomial\n",
    "from scipy.stats import binom\n",
    "import scipy.stats\n",
    "from math import factorial\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\displaystyle{P(k,n;p)=\\binom{n}{k}p^k(1-p)^{n-k}=\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}}\n",
    "$\n",
    "\n",
    "### Funcion de la distribucion binomial con Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.375"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def my_binomial(k,n,p):\n",
    "    return factorial(n)/(factorial(k)*factorial(n-k))*pow(p,k)*pow(1-p,n-k)\n",
    "\n",
    "my_binomial(2,3,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metodo de Scipy funcion binomial\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html\n",
    "\n",
    "<table class=\"table\">\n",
    "<tbody>\n",
    "<tr class=\"row-odd\"><td><p><strong>rvs(n, p, loc=0, size=1, random_state=None)</strong></p></td>\n",
    "<td><p>Random variates.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>pmf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Probability mass function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>logpmf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Log of the probability mass function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>cdf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Cumulative distribution function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>logcdf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Log of the cumulative distribution function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>sf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Survival function  (also defined as <code class=\"docutils literal notranslate\"><span class=\"pre\">1</span> <span class=\"pre\">-</span> <span class=\"pre\">cdf</span></code>, but <em class=\"xref py py-obj\">sf</em> is sometimes more accurate).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>logsf(k, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Log of the survival function.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>ppf(q, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Percent point function (inverse of <code class=\"docutils literal notranslate\"><span class=\"pre\">cdf</span></code> ‚Äî percentiles).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>isf(q, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Inverse survival function (inverse of <code class=\"docutils literal notranslate\"><span class=\"pre\">sf</span></code>).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>stats(n, p, loc=0, moments=‚Äômv‚Äô)</strong></p></td>\n",
    "<td><p>Mean(‚Äòm‚Äô), variance(‚Äòv‚Äô), skew(‚Äòs‚Äô), and/or kurtosis(‚Äòk‚Äô).</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>entropy(n, p, loc=0)</strong></p></td>\n",
    "<td><p>(Differential) entropy of the RV.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>expect(func, args=(n, p), loc=0, lb=None, ub=None, conditional=False)</strong></p></td>\n",
    "<td><p>Expected value of a function (of one argument) with respect to the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>median(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Median of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>mean(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Mean of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>var(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Variance of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-even\"><td><p><strong>std(n, p, loc=0)</strong></p></td>\n",
    "<td><p>Standard deviation of the distribution.</p></td>\n",
    "</tr>\n",
    "<tr class=\"row-odd\"><td><p><strong>interval(alpha, n, p, loc=0)</strong></p></td>\n",
    "<td><p>Endpoints of the range that contains fraction alpha [0, 1] of the distribution</p></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### scipy.pmf Probability Mass Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.stats.binom(numero de intentos, probabilidad).pmf(numero de exitos)\n",
    "dist = binom(3, 0.5) \n",
    "\n",
    "# pmf = probability mass function = funcion de densidad de probabilidad\n",
    "pmf = dist.pmf(2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funcion de distribucion acumulada con Python\n",
    "\n",
    "$\n",
    "\\displaystyle{P(k \\leq 2, n = 3; p = \\frac{1}{2})=\\sum^{2}_{k=0}\\left[\\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}\\right]}=\\frac{7}{8}\n",
    "$\n",
    "\n",
    "*Puedes intentar validar el resultado de este ejercicio en papel antes de pasar al codigo* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scipy Cumulative Distribution Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scipy.stats.binom(numero de intentos = 3 , probabilidad de eventos = 0.5).cdf(casos exitoso = 2)\n",
    "\n",
    "# Cumulative distribution function. = funcion de distribucion acumulada\n",
    "dist.cdf(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Probabilidades Individuales: [0.125 0.375 0.375]\n",
      "     Probabilidades Sumadas: 0.875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "probabilidades_individuales = scipy.stats.binom(3,0.5).pmf(range(0,3))\n",
    "probabilidades_sumadas = round(np.sum(probabilidades_individuales),3)\n",
    "\n",
    "print(f\"\"\"\n",
    "Probabilidades Individuales: {probabilidades_individuales}\n",
    "     Probabilidades Sumadas: {round(probabilidades_sumadas,3)}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.875\n",
      "0.875\n",
      "0.875\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "{probabilidades_sumadas}\n",
    "{dist.cdf(2)}\n",
    "{7/8}\n",
    "  \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulaciones de secuencias con generadores aleatorios\n",
    "\n",
    "* Los generadores aleatorios tienen como prop√≥sito simular muestras de datos que resultar√≠an de muestreos en la vida real de procesos aleatorios como lanzar una moneda o un dado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simulacion con 100 lanzamientos de moneda equilibrada\n",
    "# (ejecuta esta celda varias veces para observar la variacion de los resultados)\n",
    "p=0.5\n",
    "n=3\n",
    "binomial(n,p) #numpy.random.binomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist(num_trials):\n",
    "    values = [0,1,2,3]\n",
    "    arr = []\n",
    "\n",
    "    for _ in range(num_trials):\n",
    "        arr.append(binomial(3,0.5))\n",
    "\n",
    "    distribucion_simulada = np.unique(arr, return_counts=True)[1]/len(arr)\n",
    "    distribucion_teorica = [binom(3,0.5).pmf(k) for k in values]\n",
    "\n",
    "    plt.bar(values, distribucion_simulada, color = 'green')\n",
    "    plt.bar(values, distribucion_teorica, alpha=0.5,color='violet')\n",
    "\n",
    "    plt.title('{} experimentos'.format(num_trials))\n",
    "    plt.show()\n",
    "\n",
    "plot_hist(20)\n",
    "plot_hist(200)\n",
    "plot_hist(20000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones continuas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øC√≥mo estimar una distribuci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 4: MLE (Maximum Likelihood Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es MLE? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaci√≥n de regrsi√≥n log√≠stica "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 5: Inferencia bayesiana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoremas de Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "642679db579c39e8c54388d8c67ee59d6b9479549eff357c7b1dae31a7261e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
