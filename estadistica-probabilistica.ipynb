{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matem√°ticas para Ciencias de Datos: Estad√≠stica Probabilistica\n",
    "\n",
    "En este articulo buscamos entender por que la probabilidad es tan importante en Ciencias de datos y el Machine Learning en general\n",
    "\n",
    "Para esto primero abordaremos el concepto de **probabilidad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 1: Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es la probabilidad?\n",
    "\n",
    "En que situaciones necesitamos usar la probabildiad? para eso iremos al concepto basico que nos induce a esto. Por ello nos haremos esta pregunta:\n",
    "\n",
    "**Que es la probabilidad?**\n",
    "\n",
    "**La probabilidad es la herramienta a la que recurrimos cuando hay incertdibumbre.**\n",
    "\n",
    "La incertidumbre surge a la hora de tomar decisiones cuando tenemos informacion incompleta. Los juegos de azar son el ejemplo perfecto, ya que no podemos predecir el resutlado en un juego de cartas o dados en un casino.\n",
    "\n",
    "Esto se debe a situaciones que tienen un grado de complejidad donde no es posible tener todas las variables suficiente, con todos los datos para predecir de que si lanzas los dados de cierta manera o juegas las cartas de cierta manera se terminara por dar un resultado.\n",
    "\n",
    "Podemos resumir lo anterior como **la incertidumbre es la toma de decisiones con informacion incompleta**.\n",
    "\n",
    ">\"El azar no es mas que la medida de nuestra ignorancia. \n",
    ">Los fenomenos fortuitos son, por definicion, aquellos cuyas leyes o causas simplemente ignoramos\"\n",
    ">\n",
    "> **Henri Poincar√©**\n",
    "\n",
    "Por el hecho de que vivimos en una realidad donde la gran mayoria de nuestras decisiones las tomamos con informacion incompleta, los matematicos desarrollaron un esquema para cuantificar esta incertidumbre, dando asi el area de la Probabilidad en estadistica.\n",
    "\n",
    "**Probabilidad**\n",
    "\n",
    "En matematicos decimos que la probabilidad es el lenguaje y conjunto de herramientas matematicas que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Asi entendemos la propia palabra *probabilidad* como el area de investigacion, el concepto matematico puntual de la probabilidad tiene algunas sutilesas que conducen con frecuencia a confusiones.\n",
    "\n",
    "### Axiomas de la probabilidad\n",
    "\n",
    "Entender los elementos escenciales de la probabilidad\n",
    "\n",
    "Todo conjunto logico tiene que estar basado a un conjunto de axiomas, que significa que es un conjunto de setencias o afirmaciones, que no son derivables de algo mas fundamental, es decir que no requiere demostracion, por que lo asumimos como verdad.\n",
    "\n",
    "\n",
    "#### Sucesos\n",
    "\n",
    "Para comenzar definiremos los sucesos, ya que en cualquier libro de referencia, cualquier curso, o idioma donde estudies las matematicas de la probabilidad, encontraras que la definicion mas simple es que la probabilidad $(P)$, es la division de dos cantidades, numeros de sucesos exitodos sobre numero de sucesos totales.\n",
    "\n",
    "$\\displaystyle{P=\\underbrace{\\frac{N¬∞ \\text{sucesos exitosos}}{N¬∞ \\text{sucesos totales}}}_\\text{creencia del total}}$\n",
    "\n",
    "\n",
    "\n",
    "Ejemplo, cuando lanzas un dato, el resutlado son 6 posibiladades, cada una de esas posibilidades, es un suceso. \n",
    "Los sucesos totales son 6, pero cuando queremos saber cuales son las probabilidades de que el dado caiga en 2, como el 2 es un suceso de los seis, decimos que la probabilidad es de un sexto $({\\frac{1}{6}})$. \n",
    "\n",
    "Pero esto tiene una sutileza que nos conduce a dos escuelas de pensamientos en estadistica, la escuela Frecuentista y escuela Bayesiana.\n",
    "\n",
    "### Por que se divide el pensamiento estadistico?\n",
    "\n",
    "Cuando definimos que un sexto es la probabilidad de que un dado caiga en 2, aunque no parezca evidente, estamos asumiendo que todas las caras son igualmente probables. por lo tanto asumimos que todas las caras son igualmente probables. \n",
    "\n",
    "Lo mismo podemos definir con una moneda, donde tenemos dos posibles sucedos (cara o cruz), donde asumimos que la probabilidad de que caiga cara es de un medio $(\\frac{1}{2})$ y que caiga cruz tambien es de un medio.\n",
    "\n",
    "Pero que tan cierto es esto?\n",
    "\n",
    "Dependiendo de como interpretemos que es un suceso, o el numero de sucesos exitosos, podriamos hacer un ejercicio donde tiramos una moneda al aire 10 veces, y si la probabilidad es como la entendemos hasta ahora, de las 10 probabilidades, 5 deberian caer en cara y 5 en cruz.\n",
    "\n",
    "Haz el ejercicio y anota si realmente de las 10 veces te cayo 5 veces en cara o cruz. \n",
    "\n",
    "Probablemente no fue asi verdad, no?\n",
    "\n",
    "Aca es cuando diferenciamos las escuelas Frecuentistas y Bayesianas.\n",
    "\n",
    "#### Escuela Frecuentista\n",
    "\n",
    "Este pensamiento de probabilidad, nos explica que estos numeros que llamamos probabilidad (en esta ocacion puede ser la cara y la cruz), son numeros que solo se alcazan a la medida que haces infinitos lanzamientos de la moneda o dado, la proporcion del numero de lanzamientos exitosos y el numero de lanzamientos totales tiende a un medio, se acerca cada vez mas a 0.5. Como no hay forma de demostrar esto, por eso denominamos esto como un axioma.\n",
    "\n",
    "Las probabilidades sobre estos posibles sucesos que llamamos elementales, es por que son las ocurrencias mas basicas sobre un suceso probabilistico, donde una moneda solo tendria dos opciones, un dado seis opciones. Por esto debemos diferenciar sobre lo que es un suces elemental y un suceso\n",
    "\n",
    "**Suceso elemental:**\n",
    "\n",
    "Podemos entender a un suceso elemental como:\n",
    "> \"El resultado de lanzar un dado es 4\"\n",
    "\n",
    "Donde decimos que es elemental por que el resultado 4 solo se puede dar de una manera, que es que el daido caiga en 4 y nada mas.\n",
    "\n",
    "Suceso\n",
    "\n",
    "Un suceso en general se percibe como:\n",
    "> \"El suceso de lanzar un dado es par\"\n",
    "\n",
    "No es elemental porque es la union de varios sucesos elementales, donde el resultado puedo ser 2, 4 o 6.\n",
    "\n",
    "El uso de sucesos y sucesos elementales, se encuentran en el espacio muestral, que es el conjunto de todos los posibles resultados de un evento aleatorio. El dado tendria un espacio de seis, ya que tiene seis caras en la que puede caer, a cada uno de estos elementos del espacio muestral es lo que llamamos los sucesos elementales.\n",
    "\n",
    "En probabilidad entendequemos que todo evento aleatorio, viene escrito en un espacio muestral donde cada elemento son todas las posibles ocurrencias de ese evento aleatorio probabilistico, donde cada uno de los elementos le asignamos un numero que es una propiedad intrinseca. En el ejemplo de los dados le dariamos el elemento 1/6, ya que cada cara es igualmente probable y a esto lo asumimos como un axioma.\n",
    "\n",
    "<img src=\"./img/espacio muestral.PNG\" width=\"500\">\n",
    "\n",
    "Este tipo de probabilidad fundamental, sobre cada suceso elemental, de un espacio muestral, definimos a un sexto como la probabilidad de que caiga cada cara, a esto lo definimos como un axioma.\n",
    "\n",
    "En la vida real tendriamos que hacer infinitos intentos de esta situacion en particular, al ser un escenario abstracto, lo asumimos cierto dentro de un esquema axiomatica, es decir, la probabilidad hace parte de los axiomas y de esas propiedades intrinsecas de un problema aleatorio.\n",
    "\n",
    "La probabilidad que se le asigna a cada posible ocurrencia de un sistema aleatorio, posee varias propiedades que deben cumplirse para que el equema axiomatico tenga sentido:\n",
    "\n",
    "- $0 < P < 1$ Tienen que ser numeros que vayan del 0% al 100%, donde 0 es igual a 0% y 1 es igual a 100%.\n",
    "- $certeza \\rightarrow P=1$ Un elemento totalmente certero lo llamos con un 1.\n",
    "- $imposibilidad \\rightarrow p=0$ Un elemento imposiblemente certero lo llamos con un 0.\n",
    "- $disjuntos \\rightarrow P(A \\cup B)=P(A) + P(B)$ la probabilidad de dos elementos disjuntos sucedan, es la suma de las probabilidades de cada uno de estos.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "La posibilidad de que al arrojar un dado caiga en 2 y en 4 es la suma de la probabilidad de ambos sucesos, ya que no puede caer en 2 y en 4 al mismo tiempo\n",
    "\n",
    "Por lo que decimos que la probabilidad de que el dado caiga en 2 o en 4 es de dos sexto $(\\frac{2}{6})$, ya que son dos eventos posibles dentro de los seis eventos posibles.\n",
    "\n",
    "### Que es realmente la probabilidad?\n",
    "\n",
    "Para concluir debemos determinar que es realmente la probabilidad.\n",
    "\n",
    "Muchos dicen que es la creencia que tenemos sobre sucesos elementales. Ya que desde la perspectiva frecuentista, no tenemos forma de determinarlos realmente, asi que la probabilidad se incluye como un axioma en un conjunto de reglas que nos permite cuantificar la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad en Machine Learning\n",
    "\n",
    "En este m√≥dulo entenderemos como el Machine Learning y Ciencias de dato en general, como, el concepto o herramientas de probabilidad \n",
    "\n",
    "Recordemos que la probabilidad es un conjunto de herramientas y lenguaje matem√°tico que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Pero... donde se encuentra la incertidumbre en el machine learning?\n",
    "\n",
    "La fuente de la incertidumbre se encuentra en: \n",
    "- Los datos.\n",
    "- Atributos del modelo.\n",
    "- Arquitectura del modelo.\n",
    "\n",
    "Recuerda que en la vida real, recolectar y hacer la medici√≥n de los datos es un proceso imperfecto, ya que todos los instrumentos de medici√≥n tienen un margen de error, que ya nos introduce parte de incertidumbre en los datos.\n",
    "\n",
    "En Machine learning hablamos que un modelo se alimenta de atributos, o variables predictoras, estas variables con frecuencia son subconjuntos reducidos del problema total y real, lo que hace que esta reducci√≥n de variables ya es otra capa de incertidumbre.\n",
    "\n",
    "En matem√°ticas un modelo se entiende como una representaci√≥n simplificada de la realidad, y al ser una representaci√≥n simplificada, ya induce otra capa m√°s de incertidumbre.\n",
    "\n",
    "Estas tres son las principales fuentes de incertidumbre dentro del ML (Machine Learning), y por supuesto, estas fuentes de incertidumbre, son cuantificable con probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Clasificaci√≥n\n",
    "\n",
    "Ejemplo, un clasificador de documento de texto, donde tenemos un conjunto de documentos de texto de distintas categor√≠as, y nuestro modelo tiene que leer e identificar cual es el tema de conversaci√≥n y ubicarlos en una categor√≠a correspondiente de cada documento.\n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "Entonces, el modelo asignara cierta probabilidad a cada documento y as√≠ de determinara la clasificaci√≥n de los documentos.\n",
    "\n",
    "A este modelo es lo que llamamos un clasificador probabil√≠stico, y por definici√≥n del uso del propio modelo, ya damos uso a la probabilidad para identificar cual es la categor√≠a m√°s probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funcionamiento interno del modelo de Clasificador Probabil√≠stico \n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "En nuestro caso, lo que hace el modelo es que tiene documentos, donde cada uno tiene etiquetas, la etiqueta ser√≠a la categor√≠a o tema al que se refiere.\n",
    "\n",
    "#### Fase de Entrenamiento\n",
    "\n",
    "<img src=\"./img/entrenamiento.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "Los documentos tienen una funci√≥n que extra los atributos, es decir, simplifica los elementos fundamentales del documento que me ayudaran a hacer la extracci√≥n de la categor√≠a, a esto es lo que llamamos el **Extractor de Atributos**. \n",
    "\n",
    "Una vez realizada la extracci√≥n, el documento fue reducido a un conjunto de atributos (Vector), que se pasara como input al algoritmo de Machine Learning de clasificaci√≥n. El cual ser√≠a un algoritmo de Machine Learning supervisado, porque le doy las etiquetas, donde el algoritmo leer√≠a los atributos y en base a esto, asignar√≠a una etiqueta.\n",
    "\n",
    "As√≠ es como entrenar√≠amos a un algoritmo de ML supervisado\n",
    "\n",
    "#### fase de Predicci√≥n\n",
    "\n",
    "Luego de la fase de entrenamiento, viene la fase de Predicci√≥n\n",
    "\n",
    "<img src=\"./img/prediccion.PNG\" width=\"500\">\n",
    "\n",
    "En el proceso donde el algoritmo aprendi√≥ a unir los atributos con las etiquetas correctas, ya podemos agarrar el modelo, entregarles documentos, en el cual usando el mismo proceso de extracci√≥n de atributos, para luego entrar en el modelo de clasificaci√≥n y predecir la etiqueta.\n",
    "\n",
    "Entonces podr√≠amos decir que tengo una tarea donde tengo que clasificar muchos documentos, pero como f√≠sicamente no se puedo por el tama√±o y n√∫mero de documentos, usar√≠a mi algoritmo que est√° bien entrenado y el modelo me dir√≠a si el texto est√° hablando sobre pol√≠tica, deportes, etc\n",
    "\n",
    "> *La mayor√≠a de modelos de clasificaci√≥n funcionan con este esquema en general* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas las etapas del modelo probabil√≠stico\n",
    "\n",
    "<img src=\"./img/etp modelos.PNG\" width=\"500\">\n",
    "\n",
    "Todas las etapas de un modelo, en ciertos aspectos involucra probabilidad.\n",
    "\n",
    "¬øPero como?\n",
    "\n",
    "#### Entrenamiento\n",
    "\n",
    "En la parte de entrenamiento, antes de pasar los documentos para extraer atributos e identificar la arquitectura, debemos escoger el modelo a usar\n",
    "\n",
    "- Dise√±o\n",
    "\n",
    "    El modelo a usar es lo que definimos por dise√±o, donde escogeremos si el modelo usar√≠a probabilidad o no (No todos los modelos se apoyaran de la matem√°tica probabil√≠stica, ya que no todos los modelos son probabil√≠sticos)\n",
    "\n",
    "    En este caso usaremos de ejemplo el modelo de Naive Bayes, ya que es un modelo probabil√≠stico, ya que el clasificador Na√Øve-Bayes aprende de los datos de entrenamiento y luego predice la clase de la instancia de prueba con la mayor probabilidad posterior.\n",
    "\n",
    "- Entrenamiento\n",
    "\n",
    "    Una vez elegido el dise√±o, tenemos que definir el entrenamiento.\n",
    "\n",
    "    El entrenamiento b√°sicamente es que el modelo aprenda algo que sabr√° mas adelante, que es el concepto de distribuci√≥n de probabilidad.\n",
    "\n",
    "    Esto es una manera de saber que probabilidad asignarle a cada una de las posibles ocurrencias de los datos, donde nos encontramos con el esquema MLE (Maximum Likelihood Estimation)\n",
    "\n",
    "    **¬øQu√© es un par√°metro de un modelo?** \n",
    "\n",
    "    En los modelos de aprendizaje autom√°tico, los par√°metros son las variables que se estiman durante el proceso de entrenamiento con los conjuntos de datos. Por lo que sus valores no los indica manualmente el cient√≠fico de datos, sino que son obtenidos.\n",
    "\n",
    "    **MLE**\n",
    "\n",
    "    En estad√≠stica, **la estimaci√≥n de m√°xima verosimilitud** (MLE) es un m√©todo para estimar los par√°metros de una distribuci√≥n de probabilidad supuesta, dados algunos datos observados. Esto se logra maximizando una funci√≥n de verosimilitud para que, bajo el modelo estad√≠stico asumido, los datos observados sean los m√°s probables.\n",
    "\n",
    "- Calibraci√≥n\n",
    "\n",
    "    Luego llegar√≠a la calibraci√≥n, que es el ajuste del modelo a trav√©s de los hiperparametros, donde iremos calibrando el modelo para que el error del modelo sea cada vez m√°s peque√±o. \n",
    "\n",
    "    Los hiperparametros se encuentran por fuera del esquema de optimizaci√≥n, donde a veces se lo denomina como tuneo o calibraci√≥n de hiperparametros, donde hay veces que se usan algoritmos de optimizaci√≥n bayesiana\n",
    "\n",
    "    **¬øQu√© es un hiper par√°metro?**\n",
    "\n",
    "    Son valores que generalmente no puedo configurar con la optimizaci√≥n del modelo, por lo que suelen ser indicados por el cient√≠fico de datos. El valor √≥ptimo de un hiper par√°metro no se puede conocer a priori para un problema dado. Por lo que se tiene que utilizar valores gen√©ricos, reglas gen√©ricas, los valores que han funcionado anteriormente en problemas similares o buscar la mejor opci√≥n mediante prueba y error. Siendo una buena opci√≥n buscar los hiper par√°metros la validaci√≥n cruzada.\n",
    "\n",
    "#### Predicci√≥n\n",
    "\n",
    "Luego del proceso de entrenamiento, viene el proceso de predicci√≥n, donde nos encontramos con la fase de interpretaci√≥n del modelo\n",
    "\n",
    "- interpretaci√≥n de la predicci√≥n\n",
    "\n",
    "    Independientemente de si el modelo es probabil√≠stico o no, para la correcta interpretaci√≥n  del modelo, la persona requiere de ciertos conceptos de probabilidad, ya que entender c√≥mo funciona el c√°lculo de probabilidad del modelo, nos permite tener una interpretaci√≥n correcta del mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 2: Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de probabilidad\n",
    "\n",
    "Profundizaremos sobre el concepto de probabilidad mismo, hablando de los distintos tipos de probabilidad\n",
    "\n",
    "Distintos tipos de situaciones tienen que cuantificar con conceptos adicionales sobre el concepto de probabilidad basico\n",
    "\n",
    "**Tipos de probabilidades**\n",
    "\n",
    "- Conjunta (Joint)\n",
    "\n",
    "- Marginal\n",
    "\n",
    "- Condicional $P(A|B)$\n",
    "\n",
    "Para explicar estos conceptos que suelen darse de manera muy abstracta, seran explicado con un juego de dos dados, estudiando el espacio muestral, donde la malla ser√° la matriz por la que las filas y columnas representan el estado del primer dado y del segundo, teniendo un espacio muestral de 36 combinaciones\n",
    "\n",
    "<img src=\"./img/dados.PNG\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifiquemos las siguientes probabilidades y sus interpretaciones formulando la siguiente pregunta\n",
    "\n",
    "### Probabilidad Conjunta \n",
    "\n",
    "**Formula General:**\n",
    "\n",
    "$P(A\\cap B)$\n",
    "\n",
    "**¬øCual es la probabilidad de que ambos dados caigan en n√∫mero par?**\n",
    "\n",
    "Esta pregunta se puede responder de forma sencilla, considerando, que el espacio muestral de los 2 dados y sus 36 posibilidades solo tenemos 9 sucesos exitosos que cumplan con el.\n",
    "\n",
    "<img src=\"./img/dosdadospar.PNG\" width='500'>\n",
    "\n",
    "Entonces decimos que los estados o sucesos exitosos son 9 posibilidades de 36, por la tanto la probabilidad quedar√≠a como $\\frac{9}{36}$ y simplificado $\\frac{1}{4}$.\n",
    "\n",
    "- $P(par, par) = \\frac{9}{36} = \\frac{1}{4}$\n",
    "\n",
    "Esta probabilidad que corresponde a un suceso como tal, en realidad seria la uni√≥n de dos sucesos, es decir que el dado A haya ca√≠do en par y el dado B tambi√©n haya ca√≠do en par, por lo tanto corresponde a dos sucesos separados, que es lo que llamamos una probabilidad conjunta (joint)\n",
    "\n",
    "- ${P(\\underbrace{\\underbrace{par}_{A}, \\underbrace{par}_{B}}_{\\text{Conjunta (joint)}}) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Una probabilidad conjunta es una probabilidad de dos o m√°s sucesos, que calculamos haciendo un conteo directo al espacio muestral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Condicional \n",
    "\n",
    "$P(A|B)$\n",
    "\n",
    "\n",
    "**¬øCual es la probabilidad es de que un dado caiga en par, sabiendo que el dado B ya cay√≥ en par?**\n",
    "\n",
    "Como ves, esta pregunta es ligeramente distinta a la pregunta anterior, ya que supone una condici√≥n previa que restringe el uso enter√≥ del espacio muestral.\n",
    " \n",
    "Ahora solo tenemos que considerar las situaciones donde ya sabemos que B es par\n",
    "\n",
    "<img src=\"./img/bpar.PNG\" width='400'>\n",
    "\n",
    "La parte de la pregunta que nos dice \"el dado B ya cay√≥ en par\", lo que hace es restringir el espacio muestral, teniendo antes 36 posibilidades a tener ahora solo 18 \n",
    "posibilidades.\n",
    "\n",
    "Entonces ahora que reducimos el espacio muestral, decimos ?cual es la probabilidad de que a caiga en par, sabiendo que b ya es par?.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}}}$\n",
    "\n",
    "Como esto impone una condici√≥n previa a este tipo de probabilidades con la barrita vertical [(\"|\" o \"tal que\")](https://es.wikipedia.org/wiki/Notaci%C3%B3n_matem%C3%A1tica#Expresiones), la definimos como Probabilidad Condicional.\n",
    "\n",
    "Habiendo ya restringido el espacio muestral, volveremos a realizar un conteo pero solo teniendo en cuenta el espacio restringido\n",
    "\n",
    "<img src=\"./img/bparR.PNG\" width='400'>\n",
    "\n",
    "El n√∫mero de sucesos exitosos no cambio, sino solo el n√∫mero de sucesos posibles por lo que el resultado con el espacio muestral reducido quedar√° tal que\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}} = \\frac{9}{18}}$\n",
    "\n",
    "As√≠ vemos que tenemos dos probabilidades distintas, para dos preguntas distintas. Pero entonces nos preguntamos...\n",
    "\n",
    "**¬øC√≥mo est√°n relacionadas estas probabilidades?**\n",
    "\n",
    "Resulta que podemos formular la pregunta de cu√°l es la probabilidad de que B caiga en par, esto seria una probabilidad tradicional, ya que no ponemos ninguna condici√≥n, donde disponemos del espacio muestral completo teniendo las 36 opciones disponibles, pero... ¬øcu√°ntos de √©sos sucesos corresponden al estado par?\n",
    "\n",
    "<img src=\"./img/bebesito fiu fiu.png\" width='400'>\n",
    "\n",
    "Entonces de la misma manera 36 opciones, donde tenemos 3 columnas con 6 sucesos que cumplen la premisa de la pregunta, d√°ndonos 18 sobre 36\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(B=par)}_{\\text{EM completo}} = \\frac{18}{36}}$\n",
    "\n",
    "Ahora vemos que tenemos 3 probabilidades que fueron los resultados de 3 preguntas diferentes, pero podemos decir que **la probabilidad conjunta del suceso A y B, es igual a la probabilidad condicional de A dado B, por, la probabilidad de B**\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)}_{\\text{conjunta}} = \\underbrace{P(A | B)}_{\\text{condicional}}  * \\underbrace{P(B)}_{\\text{prob de B}}}$\n",
    "\n",
    "Esto no es un caso particular del ejemplo dado, sino, que es una f√≥rmula general, **la Regla del Producto**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)=P(A|B)*P(B)}_{\\text{Regla del producto}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Marginal\n",
    "\n",
    "Es cuando se obtiene una probabilidad sencilla a partir de una probabilidad conjunta. Es decir cuando se tiene las probabilidades conjuntas de 2 sucesos y se quiere saber solo la probabilidad de que suceda el primer suceso independiente de lo que pasa con el otro, as√≠ eso se define como **la suma de todas la probabilidades conjuntas sobre los dem√°s estados que no est√° considerando A**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A) = \\Sigma p(A,B)}_{Marginal}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Por medio del juego de los dados logramos definir de forma natural tres tipos de probabilidades\n",
    "\n",
    "Primero definimos la **Probabilidad Conjunta** que como vimos, es una probabilidad que considera la ocurrencia de diferentes, pero simult√°neos eventos aleatorios.\n",
    "\n",
    "Luego esta se relaciona con la **Probabilidad Condicional** por medio de la Regla del Producto. Es importante aclarar que la probabilidad condicional **NO IMPLICA CAUSALIDAD**, es decir, que la probabilidad de que suceda A dado que sucedio B, no quiere decir que B sea la causa de A. Puede que en situaciones particulares ocurra, pero son dos conceptos diferentes.\n",
    "\n",
    "Con esto terminamos por decir que la **Probabilidad Marginal**, se obtienen haciendo sumas sobre ciertas variables aleatorias o ciertos sucesos sobre ciertas variables aleatorias dentro de la probabilidad conjunta. Siempre que hagamos sumas de probabilidades conjuntas y dejemos libre una de las variables, decimos que estamos obteniendo la probabilidad marginal de dicho evento aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de c√°lculo de probabilidad\n",
    "\n",
    "### Correlaci√≥n de eventos\n",
    "\n",
    "Con un par de ejemplos sencillos, buscaremos ganar m√°s intuici√≥n sobre el uso de la probabilidad, como calcularla y c√≥mo debemos interpretarlas. Aprenderemos c√≥mo la correlaci√≥n de eventos nos permite descubrir y aplicar asociaciones l√≥gicas entre distintos eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Juego de los Dados\n",
    "\n",
    "Para este ejemplo, tendremos en cuenta 3 eventos aleatorios:\n",
    "\n",
    "- $A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "- $B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "- $C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "Podr√≠amos preguntarnos sobre la probabilidades de cada uno de estos eventos, sin condicionarlos a la ocurrencia previa de otro evento.\n",
    "\n",
    "Veamos la diferencia entre la probabilidad condicionada entre uno u otros sucesos, y las probabilidades sin condicionar para ver qu√© conceptos surgen.\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "Dados nuestros tres sucesos, consideraremos nuestras probabilidades de una manera sencilla.\n",
    "\n",
    "Veamos en primer lugar una probabilidad tradicional.\n",
    "\n",
    "D√≥nde queremos saber cual es la probabilidad de que suceda A, sin ninguna condici√≥n adicional. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    " \n",
    "Al ser un dado, sabemos que las posibilidades son 6, y que caiga en 4 es solo una de ellas, por lo tanto decimos que la probabilidad de A, es un sexto:\n",
    "\n",
    "$\\displaystyle{ P(A)=\\frac{1}{6} \\rightarrow{16.6\\%}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlaci√≥n Positiva\n",
    "\n",
    "Que sucede, si ahora nos preguntamos, ? cual es la probabilidad de que suceda A, sabiendo que ya ha sucedido B?\n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Gramaticalmente esto lo traducir√≠amos a la vida real como el hecho de que lance una vez el dado, y cay√≥ en un n√∫mero par, provocando que nuestro espacio muestral se haya reducido, as√≠ que el n√∫mero de posibilidades ya no es 6, sino 3, y de esas 3, solo una posibilidad corresponde a 4. \n",
    "\n",
    "$\\displaystyle{P(A|B)=\\frac{1}{3} \\rightarrow 33.3\\%}?$\n",
    "\n",
    "Por lo tanto decimos esta probabilidad condicional de que suceda A dado B, es mayor que la probabilidad tradicional de que suceda A, nos dice, que el hecho de que haya ocurrido B, aumenta la probabilidad de que ocurra A. Entonces es cuando decimos que los eventos A y B est√°n **positivamente correlacionados**.\n",
    "\n",
    "Recordemos el concepto de Correlaci√≥n de manera sencilla. La correlaci√≥n es lo que nos dice como dos variables, eventos, sucesos o activos se relacionan el uno al otro. ([Profundizar conceptos de Correlacion. Tema 3, Capitulo VI](https://deepnote.com/@mazzaroli/Estadistica-Descriptiva-para-Ciencias-de-Datos-b8622ee2-5fb0-44f3-8791-96915665574e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlaci√≥n Negativa\n",
    "\n",
    "Por otro lado tambi√©n podemos preguntarnos sobre cu√°l es la probabilidad de que suceda A sabiendo que ya sucedi√≥ C. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "$P(A|C) = ?$\n",
    "\n",
    "Entonces, si ya sabemos que C sucedi√≥, y el resultado es alg√∫n n√∫mero impar, vemos que el espacio muestral se vio limitado a estas opciones: $\\{1,3,5\\}$, y resulta que A solo puede ser el n√∫mero $\\{4\\}$.\n",
    "\n",
    "Como no hay una intersecci√≥n entre el  $\\{1,3,5\\}$ y el elemento $\\{4\\}$, esto representa sucesos excluyentes, por lo tanto quedamos con un intersecci√≥n o conjunto vac√≠o.\n",
    "\n",
    "$\\{1,3,5\\} \\cap  \\{4\\} = \\varnothing$\n",
    "\n",
    "Por lo tanto decimos que la condici√≥n $C$ reduce el espacio muestral, dici√©ndonos que los sucesos posibles son 3, pero los sucesos exitosos son 0, d√°ndonos una probabilidad de 0. Entonces decimos que la ocurrencia de $C$, redujo la ocurrencia de $A$, por lo tanto decimos que los eventos A y C est√°n **negativamente correlacionados**\n",
    "\n",
    "Que la probabilidad nos de 0, osea que los elementos sean Excluyente, no quiere decir que los elementos sean independientes, sino, son altamente dependientes\n",
    "\n",
    "$Excluyente \\neq Independiente$\n",
    "\n",
    "**Conclusi√≥n del Juego de los dados**\n",
    "\n",
    "Con este sencillo ejercicio evidenciamos como cuando dos eventos pueden estar tanto positivamente y negativamente correlacionados. Y concluimos en:\n",
    "\n",
    "- Correlaci√≥n Positiva es cuando la ocurrencia de un evento, **aumenta** la probabilidad de suceso de otro evento correlacionados\n",
    "\n",
    "- Correlaci√≥n negativa es cuando la ocurrencia de un suceso **disminuye** la probabilidad de ocurrencia del otro.\n",
    "\n",
    "- Dos elementos excluyentes, no son independientes, por lo contrario, tienen correlaci√≥n negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Juego de ruleta\n",
    "\n",
    "Para este ejemplo, usaremos el conocido juego de la ruleta que se pueden ver en muchos casinos, donde tendremos a dos jugadores, que cada uno apostar√° a cuatro n√∫meros dentro de las ocho posibilidades dentro del rango del espacio muestral.\n",
    "\n",
    "<img src=\"./img/ruleta.png\" width=\"400\">\n",
    "\n",
    "El conjunto del $jugador\\,1$ lo llamaremos como conjunto $A$ y al del $jugador\\,2$ conjunto $B$, donde diferenciaremos los conjuntos de n√∫meros que apostaron por el color rojo y azul.\n",
    "\n",
    "<img src=\"./img/ruleta color.png\" width=\"400\">\n",
    "\n",
    "Para facilitar el entendimiento del ejercicio, pasaremos a llamar los conjuntos de los jugadores a conjunto $A$ y $B$.\n",
    "\n",
    "$Jugador\\,1 \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 \\longrightarrow B = \\{5,6,7,8\\}$\n",
    "\n",
    "Aclarado esto, comenzamos el ejercicio pregunt√°ndonos:\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1?**\n",
    "\n",
    "En este caso, tanto los sucesos del $jugador\\,1$ y el $jugador\\,2$ son excluyentes, ya que sus apuestas son diferentes, por lo tanto no tienen un conjunto de intersecciones.\\\n",
    "Al analizar la probabilidad de que gane el $jugador\\,1$, est√° dada por las 8 casillas de la ruleta y de esas 8 posibilidades, solo 4 har√°n que gane el $jugador\\,1$.\n",
    "\n",
    "Quedando tal que:\n",
    "\n",
    "$P(A) = 4/8 = 1/2 = 50\\%$\n",
    "\n",
    "Pero... ¬øQu√© pasar√≠a si ahora agregamos una condici√≥n?\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Vemos que la condici√≥n de restringir el espacio muestral completo, al conjunto B, redujo el n√∫mero de eventos exitosos, teniendo como el n√∫mero de eventos exitosos igual a 0, ya que al no existir un punto de intersecci√≥n entre el conjunto A y B, no queda m√°s que un conjunto vac√≠o.\n",
    "\n",
    "$P(A|B) = \\frac{0}{4} = 0$\n",
    "\n",
    "Entonces evidenciamos un ejercicio de eventos excluyentes.\n",
    "\n",
    "____\n",
    "\n",
    "**¬øQu√© suceder√≠a si presentamos una situaci√≥n ligeramente diferente?**\n",
    "\n",
    "Donde el $Jugador\\,2$ cambie su apuesta al conjunto de n√∫meros 4,5,6,7 y el $Jugador\\,1$ mantiene su conjunto del principio.\\\n",
    "Quedando los conjuntos tal que: \n",
    "\n",
    "$Jugador\\,1 = {1,2,3,4} \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 = {4,5,6,7} \\longrightarrow B = \\{4,5,6,7\\}$\n",
    "\n",
    "Recuerda que en general lo que elija el $Jugador\\,1$ y el $Jugador\\,2$, no tienen porque tener haber relaci√≥n alguna entre sus apuestas, ya que cada uno est√° apostando a las posibilidades, donde cada uno eligi√≥ n√∫meros a su propio criterio.\n",
    "\n",
    "En este caso logramos ver que si ocurre una intersecci√≥n entre el conjunto del $Jugador\\,1$ y el nuevo conjunto del $Jugador\\,2$.\n",
    "\n",
    "<img src=\"./img/ruletaAyB.png\" width=\"500\">\n",
    "\n",
    "Entonces nos volvemos a preguntar...\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "Al igual que la vez anterior, **la condici√≥n B restringe el espacio muestral** a 4 de las 8 posibilidades, y la intersecci√≥n entre el conjunto A y B solo ocurre en una posibilidad, por lo tanto la probabilidad de A dado B quedar√≠a tal que:\n",
    "\n",
    "$P(A|B) = 1/4 = 25\\%$\n",
    "\n",
    "**¬øQu√© buscamos demostrar con este ejemplo?**\n",
    "\n",
    "Lo que queremos decir, es que gracias el conocimiento previo de saber que el $Jugador\\,2$ haya ganado, la probabilidad de que el $Jugador\\,1$ tambi√©n ganar√°, es del 25%.\\\n",
    "A diferencia de antes, cuando las probabilidades de que el $Jugador\\,1$ gan√©, sabiendo que el $Jugador\\,2$ gano, eran del 0%.\n",
    "\n",
    "**Conclusiones del Juego de la Ruleta**\n",
    "\n",
    "- La ocurrencia del conocimiento previo de que el jugador 2 haya ganado, lo que provoc√≥ fue que se reduzca la probabilidad de que el jugador 1 haya ganado. Por lo tanto sabemos que la coincidencia de los eventos A y B representan eventos que se encuentran negativamente correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reto para practicar\n",
    "\n",
    "Sabemos que el jugador 1 mantiene los n√∫meros que eligi√≥ al principio y jugador 2 cambio los suyos por el 2, 3, 6 y 7.\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el jugador 2 gano?**\n",
    "\n",
    "$jugador \\,1 = {1,2,3,4}$\\\n",
    "$jugador \\,2 = {2,3,6,7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos avanzados con probabilidad\n",
    "\n",
    "Continuaremos desarrollando ejemplos para \n",
    "\n",
    "### Paradoja ¬øni√±o o ni√±a?\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde el mayor es un var√≥n.\n",
    "1. Una mujer tiene dos beb√©s donde uno de ellos es var√≥n.\n",
    "\n",
    "Parecen parecidos pero no, en probabilidades cambia\n",
    "\n",
    "Tablero formulamos la siguiente pregunta\n",
    "\n",
    "Cual es la probabilidad de esta mujer tenga dos hijos varones.\n",
    "\n",
    "El fin del ejercicio es darse cuenta que la informaci√≥n de cada enunciado es diferente.\\\n",
    "Y para el c√°lculo de probabilidades de un ejerc q parece tan sencillo, primero deberemos calcular el espacio muestral, donde dibujaremos una matriz, donde en un eje se encontrar√°n los posibles g√©neros de un hijo, y en el otro eje los g√©neros del otro hijo.\n",
    "\n",
    "\n",
    "$\\underbrace{\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & MM  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}}_\\text{Espacio Muestral} \\hspace{3em} \\begin{matrix} F=Femenino \\\\ M=Masculino \\end{matrix}$\n",
    "\n",
    "Para dar un ejemplo, daremos que sin conocimiento previo nos preguntamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **¬øCual es la posibilidad de que una mujer tenga 2 hijos varones?**\n",
    "\n",
    "Tal cual lo presentamos sin ninguna condici√≥n, planteamos una probabilidad tradicional, y consideramos el espacio muestral completo, donde el n√∫mero de eventos posibles es $4$, y el n√∫mero de eventos exitosos es $1$.\n",
    "\n",
    "$\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & (MM)  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}$\n",
    "\n",
    "Y la probabilidad quedar√≠a tal que:\n",
    "\n",
    "$\\displaystyle{P(MM) = \\frac{1}{4}=25\\%}$\n",
    "\n",
    "Por lo tanto, la probabilidad es solamente de $\\frac{1}{4}$ sin ninguna condici√≥n previa, donde esta probabilidad no representa ni al caso 1 ni 2 mencionados anteriormente, sino simplemente a una situaci√≥n general donde no tenemos informaci√≥n previa al g√©nero de los hijos de dicha mujer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situaci√≥n 1\n",
    "\n",
    "Pero qu√© suceder√≠a si ahora imponemos la situaci√≥n donde tenemos la informaci√≥n previa de que el mayor de los hijos es un var√≥n. Entonces replantear√≠amos el ejercicio ahora de esta forma:\n",
    "\n",
    "**¬øCual es la probabilidad de que ambos hijos sean varones, sabiendo que el mayor es var√≥n?**\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor Var√≥n}) = ?$\n",
    "\n",
    "Con la informaci√≥n que tenemos podemos restringir el espacio muestral sabiendo que uno de los ejes (hijos) es el mayor, restringiendo el espacio muestral a solamente dos estados.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        FM & |MM|  \\\\\n",
    "        FF & |MF|  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Y de esta manera apreciamos que entre estos dos estados, solo uno satisface el enunciado. Quedando la probabilidad tal que:\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor M}) = \\frac{1}{2}=50\\%$\n",
    "\n",
    "Este resultado funciona bien con la situaci√≥n 1, pero ¬øQu√© diferencia existe entre la situaci√≥n 1 y 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situaci√≥n 2\n",
    "\n",
    "Comparemos la sutileza gramatical entre la situaci√≥n 1 y 2\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde <u>el mayor es un var√≥n</u>.\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde <u>uno de ellos es var√≥n</u>.\n",
    "\n",
    "La diferencia de decir entre el hijo mayor es var√≥n, y uno de ellos es var√≥n, implica que en realidad no sabemos cu√°l de ellos es var√≥n.\\\n",
    "Aunque escape de la intuici√≥n, este peque√±o cambio genera una diferencia en el espacio muestral, y lo demostraremos en la matriz para que se pueda apreciar el cambio del enunciado 2.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        [FM] & [MM]  \\\\\n",
    "        FF & [MF]  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "El hecho de decir que, uno de ellos es el var√≥n, representan 3 posibles estados en el espacio muestral, porque en cada uno de los ejes, al menos uno de los hijos es var√≥n.\n",
    "\n",
    "Cuando escribimos esto en la probabilidad, decimos, que la probabilidad de que ambos hijos sean varones, sabiendo que alguno de ellos es var√≥n es de un estado exitoso sobre tres posibles estados:\n",
    "\n",
    "$\\displaystyle{P(MM \\, | \\, \\text{alguno M}) = \\frac{1}{3} = 33.\\hat{3}\\%}$\n",
    "\n",
    "As√≠ podemos demostrar que las posibilidades de la situaci√≥n 1 y 2 son diferentes, aunque parezcan igual y se debe a que la cantidad de informaci√≥n que contiene cada frase debido a esa sutileza gramatical es diferente y esto determina distintos resultados en probabilidad.\\\n",
    "Donde en la situaci√≥n 1 la probabilidad de que los dos hijos sean varones es mayor, debido a la mayor cantidad de informaci√≥n dada en el enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de Monthy Hall\n",
    "\n",
    "<img src=\"https://m.media-amazon.com/images/M/MV5BNjUxNjMyZmUtYWE4Yi00Mzg2LWJkZmYtY2YyNjQ4ZmIyMGQwL2ltYWdlXkEyXkFqcGdeQXVyMTIxMDUyOTI@._V1_.jpg\" width=\"400\">\n",
    "\n",
    "En nuestra segunda paradoja trataremos el caso del programa de televisi√≥n *Let's make a deal*, dado por el conductor Monthy Hall, al que de se debe su nombre en probabilidad a esta paradoja, c√≥mo, **El problema de Monthy Hall**  \n",
    "\n",
    "El ejercicio consist√≠a en que el presentador le presentaba a un participante tres puertas, donde el participante ten√≠a que elegir una entre las tres posibles puertas, donde detr√°s de dos puertas no hab√≠a nada y solo en una hab√≠a un premio.\n",
    "\n",
    "En una situaci√≥n tradicional, el presentador le preguntar√≠a al participante que elija una puerta, entonces nos preguntariamos\n",
    "\n",
    "**¬øCual es la posibilidad de que el participante elija la puerta correcta?**\n",
    "\n",
    "Siendo una probabilidad tradicional, dibujaremos el espacio muestral y veriamo todas las opciones, donde podremos ver que las tres opciones inicialmente, todas son igualmente probables, por lo tanto el participante piense que la probabilidad de elegir la puerta correcta sea de un tercio por la naturaleza de la situaci√≥n.\n",
    "\n",
    "$\\displaystyle{\\begin{vmatrix} P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\\begin{matrix}  \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\ \\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\end{matrix}}$\n",
    "\n",
    "El truco del show era de que una vez que el participante eligiera una puerta, Monthy Hall abre una de las puertas (obviamente el presentador abrir√≠a una puerta sin recompensa, este era el punto de informaci√≥n adicional), luego de el presentador abriera la puerta sin recompensa, Monthy le preguntar√≠a al participante, que ahora cuenta de informaci√≥n adicional (la puerta que abri√≥ Monthy):\n",
    "\n",
    "Ahora que sabe que esta puerta no ten√≠a recompensa, ¬ømantiene la puerta que eligi√≥, o prefiere cambiar de puerta?\n",
    "\n",
    "Entonces, la intuici√≥n a primera vista nos hace decir:\n",
    "\n",
    "¬øCual es la probabilidad de que cambie de puerta y gane? o ¬øCu√°l es la probabilidad de que mantenga la puerta y gane?\n",
    "\n",
    "Dibujemos el espacio muestral para representar esta idea de forma m√°s visual:\n",
    "\n",
    "Este ser√≠a muestral antes de elegir una puerta\n",
    "\n",
    "$\n",
    "\\begin{vmatrix}P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Entonces digamos que elegimos la puerta 1, y el presentador abri√≥ la puerta 3 ya que esta no tiene premio. El espacio muestral se nos restringir√≠a a las situaciones donde la puerta 3 no tiene premios, quedando tal que\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{matrix}  \\\\\\longrightarrow 1/2 = 50\\% \\\\ \\longrightarrow 1/2 = 50\\% \\\\\\end{matrix}\n",
    "$\n",
    "\n",
    "Donde el n√∫mero de estados posibles ya no es 3, sino 2, quedando la probabilidad de √©xito de un medio.\\\n",
    "Entonces el razonamiento es que al tener 2 opciones donde solo 1 es de √©xito y ambas tienen 50% de posibilidades de ser la correcta, el participante asume que da igual si mantiene la puerta o no, ya que en ambas tiene 50% de probabilidad de ganar. Este es el primer razonamiento que se podr√≠a hacer con la intuici√≥n natural de las probabilidades, pero la paradoja es que esto es **falso**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øPor qu√© cambian las probabilidades?\n",
    "\n",
    "Pero... ¬øen realidad hay m√°s probabilidades de ganar si cambio la puerta una vez que el presentador haya descartado una?\n",
    "\n",
    "La respuesta es s√≠! Porque resultan en situaciones distintas, al igual que en el ejemplo anterior, las probabilidades pueden verse modificadas cuando hay una cambio en la cantidad de informaci√≥n disponible a la hora de tomar una decisi√≥n, y este cambio de informaci√≥n fue el hecho de que el presentador haya abierto la puerta, modificando la probabilidad de √©xito.\n",
    "\n",
    "Cambiemos el esquema mediante el cual ahora calcularemos nuestras nuevas probabilidades.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 0 \\\\ 0 \\\\ (üèÜ) \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 0 \\\\ (üèÜ) \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ (üèÜ) \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\hspace{1em}\n",
    "\\begin{matrix}   \\\\ üèÜ\\rightarrow \\text{premio} \\\\ üßî\\rightarrow \\text{participante} \\\\ üé§\\rightarrow \\text{presentador} \\\\ \\end{matrix}\n",
    "$\n",
    "\n",
    "\n",
    "En este nuevo diagrama consideraremos dos columnas nuevas, donde representar√° el caso de si mantenemos la misma puerta que elegimos, o el caso en que cambiemos la puerta sabiendo la informaci√≥n adicional que nos d√© el presentador.\n",
    "\n",
    "#### Situaci√≥n 1\n",
    "\n",
    "Entonces supongamos que elegimos la puerta 1 y el presentador abriera la puerta 2, ya que la 3 tiene el premio, por lo tanto no la abrir√≠a.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî   \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§   \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ   \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\    \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "¬øQue suceder√≠a en esta situaci√≥n?\n",
    "\n",
    "En esta situaci√≥n, si me mantuviera en la puerta 1, que es la que elegimos al principio, no ganariamos el premio, pero si la cambiamos al a puerta 3, entonces si lo ganariamos. Quedando el diagrama tal que: \n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚ùå \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚úÖ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Situaci√≥n 2\n",
    "\n",
    "\n",
    "Sigamos usando el mismo razonamiento con el siguientes caso, donde abrimos la puerta 1, y el presentador tendr√° que abrir la puerta 3, ya que en la puerta 2 se encuentra el premio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\  üßî  \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\  üèÜ  \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  üé§  \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\  ‚ùå  \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\  ‚úÖ  \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Donde si me quedo con la puerta que eleg√≠ perder√≠a, pero si la cambiara, ganaria.\n",
    "\n",
    "#### Situaci√≥n 3\n",
    "\n",
    "Y en la ultima situacion, seria que abriera la puerta 1 que contiene el premio, y daria igual la puerta que abriera el presentador, ya que ni la puerta 2 y 3 tienen premio, siendo el √∫nico caso donde si mantengo la puerta ganaria.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚úÖ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚ùå \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Resoluci√≥n\n",
    "\n",
    "Estas son las situaciones que tendr√≠amos que tener en cuenta para saber ¬øCual es la probabilidad de ganar si me quedo con la misma puerta?\n",
    "\n",
    "Para saber esto veamos la matriz completa de todas las situaciones que vimos en el ejercicio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî \\\\ üßî \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\\\ üèÜ \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ \\\\ üé§ \\\\ 0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚ùå \\\\ ‚ùå \\\\ ‚úÖ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚úÖ \\\\ ‚úÖ \\\\ ‚ùå \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Si nos hubi√©ramos quedado con la misma puerta que elegimos al principio, solo en un caso hubi√©ramos tenido la probabilidad de ganar de los tres casos, quedando tal que:\n",
    "\n",
    "$\\displaystyle{P(üèÜ|Mantener)= \\frac{1}{3}}$\n",
    "\n",
    "Pero a diferencia de si hubi√©ramos cambiado de puerta luego de la informaci√≥n adicional dada por el presentador, tendr√≠amos dos casos de eventos exitosos contra los tres que ten√≠amos.\n",
    "\n",
    "$\\displaystyle{P(üèÜ|Cambiar)= \\frac{2}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Con estos dos ejercicios demostramos que el c√°lculo de probabilidades, no siempre es intuitivo y que hay tener cuidado al entender cual es el espacio muestral sobre cual estamos trabajando, dado que tengamos informaci√≥n adicional, o no, sobre cierta situaci√≥n a la cual realizaremos el c√°lculo de probabilidades.\n",
    "\n",
    "Con estos dos ejercicios dimos el inicio para desarrollar nuestra intuici√≥n probabil√≠stica!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 3: Distribuciones de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es una distribuci√≥n? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones discretas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usando la distribuci√≥n binomial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones continuas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øC√≥mo estimar una distribuci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 4: MLE (Maximum Likelihood Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es MLE? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaci√≥n de regrsi√≥n log√≠stica "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 5: Inferencia bayesiana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoremas de Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "642679db579c39e8c54388d8c67ee59d6b9479549eff357c7b1dae31a7261e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
