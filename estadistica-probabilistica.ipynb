{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matem√°ticas para Ciencias de Datos: Estad√≠stica Probabilistica\n",
    "\n",
    "En este articulo buscamos entender por que la probabilidad es tan importante en Ciencias de datos y el Machine Learning en general\n",
    "\n",
    "Para esto primero abordaremos el concepto de **probabilidad**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 1: Incertidumbre y probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es la probabilidad?\n",
    "\n",
    "En que situaciones necesitamos usar la probabildiad? para eso iremos al concepto basico que nos induce a esto. Por ello nos haremos esta pregunta:\n",
    "\n",
    "**Que es la probabilidad?**\n",
    "\n",
    "**La probabilidad es la herramienta a la que recurrimos cuando hay incertdibumbre.**\n",
    "\n",
    "La incertidumbre surge a la hora de tomar decisiones cuando tenemos informacion incompleta. Los juegos de azar son el ejemplo perfecto, ya que no podemos predecir el resutlado en un juego de cartas o dados en un casino.\n",
    "\n",
    "Esto se debe a situaciones que tienen un grado de complejidad donde no es posible tener todas las variables suficiente, con todos los datos para predecir de que si lanzas los dados de cierta manera o juegas las cartas de cierta manera se terminara por dar un resultado.\n",
    "\n",
    "Podemos resumir lo anterior como **la incertidumbre es la toma de decisiones con informacion incompleta**.\n",
    "\n",
    ">\"El azar no es mas que la medida de nuestra ignorancia. \n",
    ">Los fenomenos fortuitos son, por definicion, aquellos cuyas leyes o causas simplemente ignoramos\"\n",
    ">\n",
    "> **Henri Poincar√©**\n",
    "\n",
    "Por el hecho de que vivimos en una realidad donde la gran mayoria de nuestras decisiones las tomamos con informacion incompleta, los matematicos desarrollaron un esquema para cuantificar esta incertidumbre, dando asi el area de la Probabilidad en estadistica.\n",
    "\n",
    "**Probabilidad**\n",
    "\n",
    "En matematicos decimos que la probabilidad es el lenguaje y conjunto de herramientas matematicas que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Asi entendemos la propia palabra *probabilidad* como el area de investigacion, el concepto matematico puntual de la probabilidad tiene algunas sutilesas que conducen con frecuencia a confusiones.\n",
    "\n",
    "### Axiomas de la probabilidad\n",
    "\n",
    "Entender los elementos escenciales de la probabilidad\n",
    "\n",
    "Todo conjunto logico tiene que estar basado a un conjunto de axiomas, que significa que es un conjunto de setencias o afirmaciones, que no son derivables de algo mas fundamental, es decir que no requiere demostracion, por que lo asumimos como verdad.\n",
    "\n",
    "\n",
    "#### Sucesos\n",
    "\n",
    "Para comenzar definiremos los sucesos, ya que en cualquier libro de referencia, cualquier curso, o idioma donde estudies las matematicas de la probabilidad, encontraras que la definicion mas simple es que la probabilidad $(P)$, es la division de dos cantidades, numeros de sucesos exitodos sobre numero de sucesos totales.\n",
    "\n",
    "$\\displaystyle{P=\\underbrace{\\frac{N¬∞ \\text{sucesos exitosos}}{N¬∞ \\text{sucesos totales}}}_\\text{creencia del total}}$\n",
    "\n",
    "\n",
    "\n",
    "Ejemplo, cuando lanzas un dato, el resutlado son 6 posibiladades, cada una de esas posibilidades, es un suceso. \n",
    "Los sucesos totales son 6, pero cuando queremos saber cuales son las probabilidades de que el dado caiga en 2, como el 2 es un suceso de los seis, decimos que la probabilidad es de un sexto $({\\frac{1}{6}})$. \n",
    "\n",
    "Pero esto tiene una sutileza que nos conduce a dos escuelas de pensamientos en estadistica, la escuela Frecuentista y escuela Bayesiana.\n",
    "\n",
    "### Por que se divide el pensamiento estadistico?\n",
    "\n",
    "Cuando definimos que un sexto es la probabilidad de que un dado caiga en 2, aunque no parezca evidente, estamos asumiendo que todas las caras son igualmente probables. por lo tanto asumimos que todas las caras son igualmente probables. \n",
    "\n",
    "Lo mismo podemos definir con una moneda, donde tenemos dos posibles sucedos (cara o cruz), donde asumimos que la probabilidad de que caiga cara es de un medio $(\\frac{1}{2})$ y que caiga cruz tambien es de un medio.\n",
    "\n",
    "Pero que tan cierto es esto?\n",
    "\n",
    "Dependiendo de como interpretemos que es un suceso, o el numero de sucesos exitosos, podriamos hacer un ejercicio donde tiramos una moneda al aire 10 veces, y si la probabilidad es como la entendemos hasta ahora, de las 10 probabilidades, 5 deberian caer en cara y 5 en cruz.\n",
    "\n",
    "Haz el ejercicio y anota si realmente de las 10 veces te cayo 5 veces en cara o cruz. \n",
    "\n",
    "Probablemente no fue asi verdad, no?\n",
    "\n",
    "Aca es cuando diferenciamos las escuelas Frecuentistas y Bayesianas.\n",
    "\n",
    "#### Escuela Frecuentista\n",
    "\n",
    "Este pensamiento de probabilidad, nos explica que estos numeros que llamamos probabilidad (en esta ocacion puede ser la cara y la cruz), son numeros que solo se alcazan a la medida que haces infinitos lanzamientos de la moneda o dado, la proporcion del numero de lanzamientos exitosos y el numero de lanzamientos totales tiende a un medio, se acerca cada vez mas a 0.5. Como no hay forma de demostrar esto, por eso denominamos esto como un axioma.\n",
    "\n",
    "Las probabilidades sobre estos posibles sucesos que llamamos elementales, es por que son las ocurrencias mas basicas sobre un suceso probabilistico, donde una moneda solo tendria dos opciones, un dado seis opciones. Por esto debemos diferenciar sobre lo que es un suces elemental y un suceso\n",
    "\n",
    "**Suceso elemental:**\n",
    "\n",
    "Podemos entender a un suceso elemental como:\n",
    "> \"El resultado de lanzar un dado es 4\"\n",
    "\n",
    "Donde decimos que es elemental por que el resultado 4 solo se puede dar de una manera, que es que el daido caiga en 4 y nada mas.\n",
    "\n",
    "Suceso\n",
    "\n",
    "Un suceso en general se percibe como:\n",
    "> \"El suceso de lanzar un dado es par\"\n",
    "\n",
    "No es elemental porque es la union de varios sucesos elementales, donde el resultado puedo ser 2, 4 o 6.\n",
    "\n",
    "El uso de sucesos y sucesos elementales, se encuentran en el [espacio muestral](https://es.wikipedia.org/wiki/Espacio_muestral)  $(EM)$, **que es el conjunto de todos los posibles resultados de un evento aleatorio.** El dado tendria un espacio de seis, ya que tiene seis caras en la que puede caer, a cada uno de estos elementos del espacio muestral es lo que llamamos los sucesos elementales.\n",
    "\n",
    "En probabilidad entendequemos que todo evento aleatorio, viene escrito en un espacio muestral donde cada elemento son todas las posibles ocurrencias de ese evento aleatorio probabilistico, donde cada uno de los elementos le asignamos un numero que es una propiedad intrinseca. En el ejemplo de los dados le dariamos el elemento 1/6, ya que cada cara es igualmente probable y a esto lo asumimos como un axioma.\n",
    "\n",
    "<img src=\"./img/espacio muestral.PNG\" width=\"500\">\n",
    "\n",
    "Este tipo de probabilidad fundamental, sobre cada suceso elemental, de un espacio muestral, definimos a un sexto como la probabilidad de que caiga cada cara, a esto lo definimos como un axioma.\n",
    "\n",
    "En la vida real tendriamos que hacer infinitos intentos de esta situacion en particular, al ser un escenario abstracto, lo asumimos cierto dentro de un esquema axiomatica, es decir, la probabilidad hace parte de los axiomas y de esas propiedades intrinsecas de un problema aleatorio.\n",
    "\n",
    "La probabilidad que se le asigna a cada posible ocurrencia de un sistema aleatorio, posee varias propiedades que deben cumplirse para que el equema axiomatico tenga sentido:\n",
    "\n",
    "- $0 < P < 1$ Tienen que ser numeros que vayan del 0% al 100%, donde 0 es igual a 0% y 1 es igual a 100%.\n",
    "- $certeza \\rightarrow P=1$ Un elemento totalmente certero lo llamos con un 1.\n",
    "- $imposibilidad \\rightarrow p=0$ Un elemento imposiblemente certero lo llamos con un 0.\n",
    "- $disjuntos \\rightarrow P(A \\cup B)=P(A) + P(B)$ la probabilidad de dos elementos disjuntos sucedan, es la suma de las probabilidades de cada uno de estos.\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "La posibilidad de que al arrojar un dado caiga en 2 y en 4 es la suma de la probabilidad de ambos sucesos, ya que no puede caer en 2 y en 4 al mismo tiempo\n",
    "\n",
    "Por lo que decimos que la probabilidad de que el dado caiga en 2 o en 4 es de dos sexto $(\\frac{2}{6})$, ya que son dos eventos posibles dentro de los seis eventos posibles.\n",
    "\n",
    "### Que es realmente la probabilidad?\n",
    "\n",
    "Para concluir debemos determinar que es realmente la probabilidad.\n",
    "\n",
    "Muchos dicen que es la creencia que tenemos sobre sucesos elementales. Ya que desde la perspectiva frecuentista, no tenemos forma de determinarlos realmente, asi que la probabilidad se incluye como un axioma en un conjunto de reglas que nos permite cuantificar la incertidumbre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probabilidad en Machine Learning\n",
    "\n",
    "En este m√≥dulo entenderemos como el Machine Learning y Ciencias de dato en general, como, el concepto o herramientas de probabilidad \n",
    "\n",
    "Recordemos que la probabilidad es un conjunto de herramientas y lenguaje matem√°tico que nos permite cuantificar la incertidumbre.\n",
    "\n",
    "Pero... donde se encuentra la incertidumbre en el machine learning?\n",
    "\n",
    "La fuente de la incertidumbre se encuentra en: \n",
    "- Los datos.\n",
    "- Atributos del modelo.\n",
    "- Arquitectura del modelo.\n",
    "\n",
    "Recuerda que en la vida real, recolectar y hacer la medici√≥n de los datos es un proceso imperfecto, ya que todos los instrumentos de medici√≥n tienen un margen de error, que ya nos introduce parte de incertidumbre en los datos.\n",
    "\n",
    "En Machine learning hablamos que un modelo se alimenta de atributos, o variables predictoras, estas variables con frecuencia son subconjuntos reducidos del problema total y real, lo que hace que esta reducci√≥n de variables ya es otra capa de incertidumbre.\n",
    "\n",
    "En matem√°ticas un modelo se entiende como una representaci√≥n simplificada de la realidad, y al ser una representaci√≥n simplificada, ya induce otra capa m√°s de incertidumbre.\n",
    "\n",
    "Estas tres son las principales fuentes de incertidumbre dentro del ML (Machine Learning), y por supuesto, estas fuentes de incertidumbre, son cuantificable con probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo de Clasificaci√≥n\n",
    "\n",
    "Ejemplo, un clasificador de documento de texto, donde tenemos un conjunto de documentos de texto de distintas categor√≠as, y nuestro modelo tiene que leer e identificar cual es el tema de conversaci√≥n y ubicarlos en una categor√≠a correspondiente de cada documento.\n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "Entonces, el modelo asignara cierta probabilidad a cada documento y as√≠ de determinara la clasificaci√≥n de los documentos.\n",
    "\n",
    "A este modelo es lo que llamamos un clasificador probabil√≠stico, y por definici√≥n del uso del propio modelo, ya damos uso a la probabilidad para identificar cual es la categor√≠a m√°s probable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Funcionamiento interno del modelo de Clasificador Probabil√≠stico \n",
    "\n",
    "<img src=\"./img/modelo de clasificacion.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "En nuestro caso, lo que hace el modelo es que tiene documentos, donde cada uno tiene etiquetas, la etiqueta ser√≠a la categor√≠a o tema al que se refiere.\n",
    "\n",
    "#### Fase de Entrenamiento\n",
    "\n",
    "<img src=\"./img/entrenamiento.PNG\" width=\"500\">\n",
    "\n",
    "\n",
    "Los documentos tienen una funci√≥n que extra los atributos, es decir, simplifica los elementos fundamentales del documento que me ayudaran a hacer la extracci√≥n de la categor√≠a, a esto es lo que llamamos el **Extractor de Atributos**. \n",
    "\n",
    "Una vez realizada la extracci√≥n, el documento fue reducido a un conjunto de atributos (Vector), que se pasara como input al algoritmo de Machine Learning de clasificaci√≥n. El cual ser√≠a un algoritmo de Machine Learning supervisado, porque le doy las etiquetas, donde el algoritmo leer√≠a los atributos y en base a esto, asignar√≠a una etiqueta.\n",
    "\n",
    "As√≠ es como entrenar√≠amos a un algoritmo de ML supervisado\n",
    "\n",
    "#### fase de Predicci√≥n\n",
    "\n",
    "Luego de la fase de entrenamiento, viene la fase de Predicci√≥n\n",
    "\n",
    "<img src=\"./img/prediccion.PNG\" width=\"500\">\n",
    "\n",
    "En el proceso donde el algoritmo aprendi√≥ a unir los atributos con las etiquetas correctas, ya podemos agarrar el modelo, entregarles documentos, en el cual usando el mismo proceso de extracci√≥n de atributos, para luego entrar en el modelo de clasificaci√≥n y predecir la etiqueta.\n",
    "\n",
    "Entonces podr√≠amos decir que tengo una tarea donde tengo que clasificar muchos documentos, pero como f√≠sicamente no se puedo por el tama√±o y n√∫mero de documentos, usar√≠a mi algoritmo que est√° bien entrenado y el modelo me dir√≠a si el texto est√° hablando sobre pol√≠tica, deportes, etc\n",
    "\n",
    "> *La mayor√≠a de modelos de clasificaci√≥n funcionan con este esquema en general* \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todas las etapas del modelo probabil√≠stico\n",
    "\n",
    "<img src=\"./img/etp modelos.PNG\" width=\"500\">\n",
    "\n",
    "Todas las etapas de un modelo, en ciertos aspectos involucra probabilidad.\n",
    "\n",
    "¬øPero como?\n",
    "\n",
    "#### Entrenamiento\n",
    "\n",
    "En la parte de entrenamiento, antes de pasar los documentos para extraer atributos e identificar la arquitectura, debemos escoger el modelo a usar\n",
    "\n",
    "- Dise√±o\n",
    "\n",
    "    El modelo a usar es lo que definimos por dise√±o, donde escogeremos si el modelo usar√≠a probabilidad o no (No todos los modelos se apoyaran de la matem√°tica probabil√≠stica, ya que no todos los modelos son probabil√≠sticos)\n",
    "\n",
    "    En este caso usaremos de ejemplo el modelo de Naive Bayes, ya que es un modelo probabil√≠stico, ya que el clasificador Na√Øve-Bayes aprende de los datos de entrenamiento y luego predice la clase de la instancia de prueba con la mayor probabilidad posterior.\n",
    "\n",
    "- Entrenamiento\n",
    "\n",
    "    Una vez elegido el dise√±o, tenemos que definir el entrenamiento.\n",
    "\n",
    "    El entrenamiento b√°sicamente es que el modelo aprenda algo que sabr√° mas adelante, que es el concepto de distribuci√≥n de probabilidad.\n",
    "\n",
    "    Esto es una manera de saber que probabilidad asignarle a cada una de las posibles ocurrencias de los datos, donde nos encontramos con el esquema MLE (Maximum Likelihood Estimation)\n",
    "\n",
    "    **¬øQu√© es un par√°metro de un modelo?** \n",
    "\n",
    "    En los modelos de aprendizaje autom√°tico, los par√°metros son las variables que se estiman durante el proceso de entrenamiento con los conjuntos de datos. Por lo que sus valores no los indica manualmente el cient√≠fico de datos, sino que son obtenidos.\n",
    "\n",
    "    **MLE**\n",
    "\n",
    "    En estad√≠stica, **la estimaci√≥n de m√°xima verosimilitud** (MLE) es un m√©todo para estimar los par√°metros de una distribuci√≥n de probabilidad supuesta, dados algunos datos observados. Esto se logra maximizando una funci√≥n de verosimilitud para que, bajo el modelo estad√≠stico asumido, los datos observados sean los m√°s probables.\n",
    "\n",
    "- Calibraci√≥n\n",
    "\n",
    "    Luego llegar√≠a la calibraci√≥n, que es el ajuste del modelo a trav√©s de los hiperparametros, donde iremos calibrando el modelo para que el error del modelo sea cada vez m√°s peque√±o. \n",
    "\n",
    "    Los hiperparametros se encuentran por fuera del esquema de optimizaci√≥n, donde a veces se lo denomina como tuneo o calibraci√≥n de hiperparametros, donde hay veces que se usan algoritmos de optimizaci√≥n bayesiana\n",
    "\n",
    "    **¬øQu√© es un hiper par√°metro?**\n",
    "\n",
    "    Son valores que generalmente no puedo configurar con la optimizaci√≥n del modelo, por lo que suelen ser indicados por el cient√≠fico de datos. El valor √≥ptimo de un hiper par√°metro no se puede conocer a priori para un problema dado. Por lo que se tiene que utilizar valores gen√©ricos, reglas gen√©ricas, los valores que han funcionado anteriormente en problemas similares o buscar la mejor opci√≥n mediante prueba y error. Siendo una buena opci√≥n buscar los hiper par√°metros la validaci√≥n cruzada.\n",
    "\n",
    "#### Predicci√≥n\n",
    "\n",
    "Luego del proceso de entrenamiento, viene el proceso de predicci√≥n, donde nos encontramos con la fase de interpretaci√≥n del modelo\n",
    "\n",
    "- interpretaci√≥n de la predicci√≥n\n",
    "\n",
    "    Independientemente de si el modelo es probabil√≠stico o no, para la correcta interpretaci√≥n  del modelo, la persona requiere de ciertos conceptos de probabilidad, ya que entender c√≥mo funciona el c√°lculo de probabilidad del modelo, nos permite tener una interpretaci√≥n correcta del mismo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 2: Fundamentos de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de probabilidad\n",
    "\n",
    "Profundizaremos sobre el concepto de probabilidad mismo, hablando de los distintos tipos de probabilidad\n",
    "\n",
    "Distintos tipos de situaciones tienen que cuantificar con conceptos adicionales sobre el concepto de probabilidad basico\n",
    "\n",
    "**Tipos de probabilidades**\n",
    "\n",
    "- Conjunta (Joint)\n",
    "\n",
    "- Marginal\n",
    "\n",
    "- Condicional $P(A|B)$\n",
    "\n",
    "Para explicar estos conceptos que suelen darse de manera muy abstracta, seran explicado con un juego de dos dados, estudiando el espacio muestral, donde la malla ser√° la matriz por la que las filas y columnas representan el estado del primer dado y del segundo, teniendo un espacio muestral de 36 combinaciones\n",
    "\n",
    "<img src=\"./img/dados.PNG\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identifiquemos las siguientes probabilidades y sus interpretaciones formulando la siguiente pregunta\n",
    "\n",
    "### Probabilidad Conjunta \n",
    "\n",
    "**Formula General:**\n",
    "\n",
    "$P(A\\cap B)$\n",
    "\n",
    "**¬øCual es la probabilidad de que ambos dados caigan en n√∫mero par?**\n",
    "\n",
    "Esta pregunta se puede responder de forma sencilla, considerando, que el espacio muestral de los 2 dados y sus 36 posibilidades solo tenemos 9 sucesos exitosos que cumplan con el.\n",
    "\n",
    "<img src=\"./img/dosdadospar.PNG\" width='500'>\n",
    "\n",
    "Entonces decimos que los estados o sucesos exitosos son 9 posibilidades de 36, por la tanto la probabilidad quedar√≠a como $\\frac{9}{36}$ y simplificado $\\frac{1}{4}$.\n",
    "\n",
    "- $\\displaystyle{P(par, par) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Esta probabilidad que corresponde a un suceso como tal, en realidad seria la uni√≥n de dos sucesos, es decir que el dado A haya ca√≠do en par y el dado B tambi√©n haya ca√≠do en par, por lo tanto corresponde a dos sucesos separados, que es lo que llamamos una probabilidad conjunta (joint)\n",
    "\n",
    "- $\\displaystyle{P(\\underbrace{\\underbrace{par}_{A}, \\underbrace{par}_{B}}_{\\text{Conjunta (joint)}}) = \\frac{9}{36} = \\frac{1}{4}}$\n",
    "\n",
    "Una probabilidad conjunta es una probabilidad de dos o m√°s sucesos, que calculamos haciendo un conteo directo al espacio muestral"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Condicional \n",
    "\n",
    "$P(A|B)$\n",
    "\n",
    "\n",
    "**¬øCual es la probabilidad es de que un dado caiga en par, sabiendo que el dado B ya cay√≥ en par?**\n",
    "\n",
    "Como ves, esta pregunta es ligeramente distinta a la pregunta anterior, ya que supone una condici√≥n previa que restringe el uso enter√≥ del espacio muestral.\n",
    " \n",
    "Ahora solo tenemos que considerar las situaciones donde ya sabemos que B es par\n",
    "\n",
    "<img src=\"./img/bpar.PNG\" width='400'>\n",
    "\n",
    "La parte de la pregunta que nos dice \"el dado B ya cay√≥ en par\", lo que hace es restringir el espacio muestral, teniendo antes 36 posibilidades a tener ahora solo 18 \n",
    "posibilidades.\n",
    "\n",
    "Entonces ahora que reducimos el espacio muestral, decimos ?cual es la probabilidad de que a caiga en par, sabiendo que b ya es par?.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}}}$\n",
    "\n",
    "Como esto impone una condici√≥n previa a este tipo de probabilidades con la barrita vertical [(\"|\" o \"tal que\")](https://es.wikipedia.org/wiki/Notaci%C3%B3n_matem%C3%A1tica#Expresiones), la definimos como Probabilidad Condicional.\n",
    "\n",
    "Habiendo ya restringido el espacio muestral, volveremos a realizar un conteo pero solo teniendo en cuenta el espacio restringido\n",
    "\n",
    "<img src=\"./img/bparR.PNG\" width='400'>\n",
    "\n",
    "El n√∫mero de sucesos exitosos no cambio, sino solo el n√∫mero de sucesos posibles por lo que el resultado con el espacio muestral reducido quedar√° tal que\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A=par | B=par)}_{\\text{condicional}} = \\frac{9}{18}}$\n",
    "\n",
    "As√≠ vemos que tenemos dos probabilidades distintas, para dos preguntas distintas. Pero entonces nos preguntamos...\n",
    "\n",
    "**¬øC√≥mo est√°n relacionadas estas probabilidades?**\n",
    "\n",
    "Resulta que podemos formular la pregunta de cu√°l es la probabilidad de que B caiga en par, esto seria una probabilidad tradicional, ya que no ponemos ninguna condici√≥n, donde disponemos del espacio muestral completo teniendo las 36 opciones disponibles, pero... ¬øcu√°ntos de √©sos sucesos corresponden al estado par?\n",
    "\n",
    "<img src=\"./img/bebesito fiu fiu.png\" width='400'>\n",
    "\n",
    "Entonces de la misma manera 36 opciones, donde tenemos 3 columnas con 6 sucesos que cumplen la premisa de la pregunta, d√°ndonos 18 sobre 36\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(B=par)}_{\\text{EM completo}} = \\frac{18}{36}}$\n",
    "\n",
    "Ahora vemos que tenemos 3 probabilidades que fueron los resultados de 3 preguntas diferentes, pero podemos decir que **la probabilidad conjunta del suceso A y B, es igual a la probabilidad condicional de A dado B, por, la probabilidad de B**\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)}_{\\text{conjunta}} = \\underbrace{P(A | B)}_{\\text{condicional}}  * \\underbrace{P(B)}_{\\text{prob de B}}}$\n",
    "\n",
    "Esto no es un caso particular del ejemplo dado, sino, que es una f√≥rmula general, **la Regla del Producto**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A,B)=P(A|B)*P(B)}_{\\text{Regla del producto}}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probabilidad Marginal\n",
    "\n",
    "Es cuando se obtiene una probabilidad sencilla a partir de una probabilidad conjunta. Es decir cuando se tiene las probabilidades conjuntas de 2 sucesos y se quiere saber solo la probabilidad de que suceda el primer suceso independiente de lo que pasa con el otro, as√≠ eso se define como **la suma de todas la probabilidades conjuntas sobre los dem√°s estados que no est√° considerando A**.\n",
    "\n",
    "$\\displaystyle{\\underbrace{P(A) = \\Sigma p(A,B)}_{Marginal}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Por medio del juego de los dados logramos definir de forma natural tres tipos de probabilidades\n",
    "\n",
    "Primero definimos la **Probabilidad Conjunta** que como vimos, es una probabilidad que considera la ocurrencia de diferentes, pero simult√°neos eventos aleatorios.\n",
    "\n",
    "Luego esta se relaciona con la **Probabilidad Condicional** por medio de la Regla del Producto. Es importante aclarar que la probabilidad condicional **NO IMPLICA CAUSALIDAD**, es decir, que la probabilidad de que suceda A dado que sucedio B, no quiere decir que B sea la causa de A. Puede que en situaciones particulares ocurra, pero son dos conceptos diferentes.\n",
    "\n",
    "Con esto terminamos por decir que la **Probabilidad Marginal**, se obtienen haciendo sumas sobre ciertas variables aleatorias o ciertos sucesos sobre ciertas variables aleatorias dentro de la probabilidad conjunta. Siempre que hagamos sumas de probabilidades conjuntas y dejemos libre una de las variables, decimos que estamos obteniendo la probabilidad marginal de dicho evento aleatorio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de c√°lculo de probabilidad\n",
    "\n",
    "### Correlaci√≥n de eventos\n",
    "\n",
    "Con un par de ejemplos sencillos, buscaremos ganar m√°s intuici√≥n sobre el uso de la probabilidad, como calcularla y c√≥mo debemos interpretarlas. Aprenderemos c√≥mo la correlaci√≥n de eventos nos permite descubrir y aplicar asociaciones l√≥gicas entre distintos eventos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 1: Juego de los Dados\n",
    "\n",
    "Para este ejemplo, tendremos en cuenta 3 eventos aleatorios:\n",
    "\n",
    "- $A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "- $B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "- $C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "Podr√≠amos preguntarnos sobre la probabilidades de cada uno de estos eventos, sin condicionarlos a la ocurrencia previa de otro evento.\n",
    "\n",
    "Veamos la diferencia entre la probabilidad condicionada entre uno u otros sucesos, y las probabilidades sin condicionar para ver qu√© conceptos surgen.\n",
    "\n",
    "____\n",
    "\n",
    "\n",
    "Dados nuestros tres sucesos, consideraremos nuestras probabilidades de una manera sencilla.\n",
    "\n",
    "Veamos en primer lugar una probabilidad tradicional.\n",
    "\n",
    "D√≥nde queremos saber cual es la probabilidad de que suceda A, sin ninguna condici√≥n adicional. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    " \n",
    "Al ser un dado, sabemos que las posibilidades son 6, y que caiga en 4 es solo una de ellas, por lo tanto decimos que la probabilidad de A, es un sexto:\n",
    "\n",
    "$\\displaystyle{ P(A)=\\frac{1}{6} \\rightarrow{16.6\\%}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlaci√≥n Positiva\n",
    "\n",
    "Que sucede, si ahora nos preguntamos, ? cual es la probabilidad de que suceda A, sabiendo que ya ha sucedido B?\n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$B = \\{\\text{El resultado de lanzar un dado es par}\\}$\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Gramaticalmente esto lo traducir√≠amos a la vida real como el hecho de que lance una vez el dado, y cay√≥ en un n√∫mero par, provocando que nuestro espacio muestral se haya reducido, as√≠ que el n√∫mero de posibilidades ya no es 6, sino 3, y de esas 3, solo una posibilidad corresponde al evento exitoso. \n",
    "\n",
    "$\\displaystyle{P(A|B)=\\frac{1}{3} \\rightarrow 33.3\\%}$\n",
    "\n",
    "Por lo tanto decimos esta probabilidad condicional de que suceda A dado B, es mayor que la probabilidad tradicional de que suceda A, nos dice, que el hecho de que haya ocurrido B, aumenta la probabilidad de que ocurra A. Entonces es cuando decimos que los eventos A y B est√°n **positivamente correlacionados**.\n",
    "\n",
    "Recordemos el concepto de Correlaci√≥n de manera sencilla. La correlaci√≥n es lo que nos dice como dos variables, eventos, sucesos o activos se relacionan el uno al otro. ([Profundizar conceptos de Correlacion. Tema 3, Capitulo VI](https://deepnote.com/@mazzaroli/Estadistica-Descriptiva-para-Ciencias-de-Datos-b8622ee2-5fb0-44f3-8791-96915665574e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Correlaci√≥n Negativa\n",
    "\n",
    "Por otro lado tambi√©n podemos preguntarnos sobre cu√°l es la probabilidad de que suceda A sabiendo que ya sucedi√≥ C. \n",
    "\n",
    "$A = \\{\\text{El resultado de lanzar un dado es 4}\\}$\n",
    "\n",
    "$C = \\{\\text{El resultado de lanzar un dado es impar}\\}$\n",
    "\n",
    "$P(A|C) = ?$\n",
    "\n",
    "Entonces, si ya sabemos que C sucedi√≥, y el resultado es alg√∫n n√∫mero impar, vemos que el espacio muestral se vio limitado a estas opciones: $\\{1,3,5\\}$, y resulta que A solo puede ser el n√∫mero $\\{4\\}$.\n",
    "\n",
    "Como no hay una intersecci√≥n entre el  $\\{1,3,5\\}$ y el elemento $\\{4\\}$, esto representa sucesos excluyentes, por lo tanto quedamos con un intersecci√≥n o conjunto vac√≠o.\n",
    "\n",
    "$\\{1,3,5\\} \\cap  \\{4\\} = \\varnothing$\n",
    "\n",
    "Por lo tanto decimos que la condici√≥n $C$ reduce el espacio muestral, dici√©ndonos que los sucesos posibles son 3, pero los sucesos exitosos son 0, d√°ndonos una probabilidad de 0. Entonces decimos que la ocurrencia de $C$, redujo la ocurrencia de $A$, por lo tanto decimos que los eventos A y C est√°n **negativamente correlacionados**\n",
    "\n",
    "Que la probabilidad nos de 0, osea que los elementos sean Excluyente, no quiere decir que los elementos sean independientes, sino, son altamente dependientes\n",
    "\n",
    "$Excluyente \\neq Independiente$\n",
    "\n",
    "**Conclusi√≥n del Juego de los dados**\n",
    "\n",
    "Con este sencillo ejercicio evidenciamos como cuando dos eventos pueden estar tanto positivamente y negativamente correlacionados. Y concluimos en:\n",
    "\n",
    "- Correlaci√≥n Positiva es cuando la ocurrencia de un evento, **aumenta** la probabilidad de suceso de otro evento correlacionados\n",
    "\n",
    "- Correlaci√≥n negativa es cuando la ocurrencia de un suceso **disminuye** la probabilidad de ocurrencia del otro.\n",
    "\n",
    "- Dos elementos excluyentes, no son independientes, por lo contrario, tienen correlaci√≥n negativa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo 2: Juego de ruleta\n",
    "\n",
    "Para este ejemplo, usaremos el conocido juego de la ruleta que se pueden ver en muchos casinos, donde tendremos a dos jugadores, que cada uno apostar√° a cuatro n√∫meros dentro de las ocho posibilidades dentro del rango del espacio muestral.\n",
    "\n",
    "<img src=\"./img/ruleta.png\" width=\"400\">\n",
    "\n",
    "El conjunto del $jugador\\,1$ lo llamaremos como conjunto $A$ y al del $jugador\\,2$ conjunto $B$, donde diferenciaremos los conjuntos de n√∫meros que apostaron por el color rojo y azul.\n",
    "\n",
    "<img src=\"./img/ruleta color.png\" width=\"400\">\n",
    "\n",
    "Para facilitar el entendimiento del ejercicio, pasaremos a llamar los conjuntos de los jugadores a conjunto $A$ y $B$.\n",
    "\n",
    "$Jugador\\,1 \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 \\longrightarrow B = \\{5,6,7,8\\}$\n",
    "\n",
    "Aclarado esto, comenzamos el ejercicio pregunt√°ndonos:\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1?**\n",
    "\n",
    "En este caso, tanto los sucesos del $jugador\\,1$ y el $jugador\\,2$ son excluyentes, ya que sus apuestas son diferentes, por lo tanto no tienen un conjunto de intersecciones.\\\n",
    "Al analizar la probabilidad de que gane el $jugador\\,1$, est√° dada por las 8 casillas de la ruleta y de esas 8 posibilidades, solo 4 har√°n que gane el $jugador\\,1$.\n",
    "\n",
    "Quedando tal que:\n",
    "\n",
    "$P(A) = 4/8 = 1/2 = 50\\%$\n",
    "\n",
    "Pero... ¬øQu√© pasar√≠a si ahora agregamos una condici√≥n?\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "$P(A|B) = ?$\n",
    "\n",
    "Vemos que la condici√≥n de restringir el espacio muestral completo, al conjunto B, redujo el n√∫mero de eventos exitosos, teniendo como el n√∫mero de eventos exitosos igual a 0, ya que al no existir un punto de intersecci√≥n entre el conjunto A y B, no queda m√°s que un conjunto vac√≠o.\n",
    "\n",
    "$P(A|B) = \\frac{0}{4} = 0$\n",
    "\n",
    "Entonces evidenciamos un ejercicio de eventos excluyentes.\n",
    "\n",
    "____\n",
    "\n",
    "**¬øQu√© suceder√≠a si presentamos una situaci√≥n ligeramente diferente?**\n",
    "\n",
    "Donde el $Jugador\\,2$ cambie su apuesta al conjunto de n√∫meros 4,5,6,7 y el $Jugador\\,1$ mantiene su conjunto del principio.\\\n",
    "Quedando los conjuntos tal que: \n",
    "\n",
    "$Jugador\\,1 = {1,2,3,4} \\longrightarrow A = \\{1,2,3,4\\}$\\\n",
    "$Jugador\\,2 = {4,5,6,7} \\longrightarrow B = \\{4,5,6,7\\}$\n",
    "\n",
    "Recuerda que en general lo que elija el $Jugador\\,1$ y el $Jugador\\,2$, no tienen porque tener haber relaci√≥n alguna entre sus apuestas, ya que cada uno est√° apostando a las posibilidades, donde cada uno eligi√≥ n√∫meros a su propio criterio.\n",
    "\n",
    "En este caso logramos ver que si ocurre una intersecci√≥n entre el conjunto del $Jugador\\,1$ y el nuevo conjunto del $Jugador\\,2$.\n",
    "\n",
    "<img src=\"./img/ruletaAyB.png\" width=\"500\">\n",
    "\n",
    "Entonces nos volvemos a preguntar...\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el resultado de la ruleta se encuentra dentro del conjunto B?**\n",
    "\n",
    "Al igual que la vez anterior, **la condici√≥n B restringe el espacio muestral** a 4 de las 8 posibilidades, y la intersecci√≥n entre el conjunto A y B solo ocurre en una posibilidad, por lo tanto la probabilidad de A dado B quedar√≠a tal que:\n",
    "\n",
    "$P(A|B) = 1/4 = 25\\%$\n",
    "\n",
    "**¬øQu√© buscamos demostrar con este ejemplo?**\n",
    "\n",
    "Lo que queremos decir, es que gracias el conocimiento previo de saber que el $Jugador\\,2$ haya ganado, la probabilidad de que el $Jugador\\,1$ tambi√©n ganar√°, es del 25%.\\\n",
    "A diferencia de antes, cuando las probabilidades de que el $Jugador\\,1$ gan√©, sabiendo que el $Jugador\\,2$ gano, eran del 0%.\n",
    "\n",
    "**Conclusiones del Juego de la Ruleta**\n",
    "\n",
    "- La ocurrencia del conocimiento previo de que el jugador 2 haya ganado, lo que provoc√≥ fue que se reduzca la probabilidad de que el jugador 1 haya ganado. Por lo tanto sabemos que la coincidencia de los eventos A y B representan eventos que se encuentran negativamente correlacionados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reto para practicar\n",
    "\n",
    "Sabemos que el jugador 1 mantiene los n√∫meros que eligi√≥ al principio y jugador 2 cambio los suyos por el 2, 3, 6 y 7.\n",
    "\n",
    "**¬øCual es la probabilidad de que gane el jugador 1, sabiendo que el jugador 2 gano?**\n",
    "\n",
    "$jugador \\,1 = {1,2,3,4}$\\\n",
    "$jugador \\,2 = {2,3,6,7}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos avanzados con probabilidad\n",
    "\n",
    "Continuaremos desarrollando ejemplos para \n",
    "\n",
    "### Paradoja ¬øni√±o o ni√±a?\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde el mayor es un var√≥n.\n",
    "1. Una mujer tiene dos beb√©s donde uno de ellos es var√≥n.\n",
    "\n",
    "Parecen parecidos pero no, en probabilidades cambia\n",
    "\n",
    "Tablero formulamos la siguiente pregunta\n",
    "\n",
    "Cual es la probabilidad de esta mujer tenga dos hijos varones.\n",
    "\n",
    "El fin del ejercicio es darse cuenta que la informaci√≥n de cada enunciado es diferente.\\\n",
    "Y para el c√°lculo de probabilidades de un ejerc q parece tan sencillo, primero deberemos calcular el espacio muestral, donde dibujaremos una matriz, donde en un eje se encontrar√°n los posibles g√©neros de un hijo, y en el otro eje los g√©neros del otro hijo.\n",
    "\n",
    "\n",
    "$\\underbrace{\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & MM  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}}_\\text{Espacio Muestral} \\hspace{3em} \\begin{matrix} F=Femenino \\\\ M=Masculino \\end{matrix}$\n",
    "\n",
    "Para dar un ejemplo, daremos que sin conocimiento previo nos preguntamos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **¬øCual es la posibilidad de que una mujer tenga 2 hijos varones?**\n",
    "\n",
    "Tal cual lo presentamos sin ninguna condici√≥n, planteamos una probabilidad tradicional, y consideramos el espacio muestral completo, donde el n√∫mero de eventos posibles es $4$, y el n√∫mero de eventos exitosos es $1$.\n",
    "\n",
    "$\\begin{matrix}\\begin{matrix}M \\\\F \\\\\\end{matrix}\\begin{vmatrix}FM & (MM)  \\\\FF & MF  \\\\\\end{vmatrix} \\\\\\begin{matrix}& F & & M\\end{matrix}\\end{matrix}$\n",
    "\n",
    "Y la probabilidad quedar√≠a tal que:\n",
    "\n",
    "$\\displaystyle{P(MM) = \\frac{1}{4}=25\\%}$\n",
    "\n",
    "Por lo tanto, la probabilidad es solamente de $\\frac{1}{4}$ sin ninguna condici√≥n previa, donde esta probabilidad no representa ni al caso 1 ni 2 mencionados anteriormente, sino simplemente a una situaci√≥n general donde no tenemos informaci√≥n previa al g√©nero de los hijos de dicha mujer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situaci√≥n 1\n",
    "\n",
    "Pero qu√© suceder√≠a si ahora imponemos la situaci√≥n donde tenemos la informaci√≥n previa de que el mayor de los hijos es un var√≥n. Entonces replantear√≠amos el ejercicio ahora de esta forma:\n",
    "\n",
    "**¬øCual es la probabilidad de que ambos hijos sean varones, sabiendo que el mayor es var√≥n?**\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor Var√≥n}) = ?$\n",
    "\n",
    "Con la informaci√≥n que tenemos podemos restringir el espacio muestral sabiendo que uno de los ejes (hijos) es el mayor, restringiendo el espacio muestral a solamente dos estados.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        FM & |MM|  \\\\\n",
    "        FF & |MF|  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "Y de esta manera apreciamos que entre estos dos estados, solo uno satisface el enunciado. Quedando la probabilidad tal que:\n",
    "\n",
    "$P(MM \\, | \\, \\text{Mayor M}) = \\frac{1}{2}=50\\%$\n",
    "\n",
    "Este resultado funciona bien con la situaci√≥n 1, pero ¬øQu√© diferencia existe entre la situaci√≥n 1 y 2?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Situaci√≥n 2\n",
    "\n",
    "Comparemos la sutileza gramatical entre la situaci√≥n 1 y 2\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde <u>el mayor es un var√≥n</u>.\n",
    "\n",
    "1. Una mujer tiene dos beb√©s donde <u>uno de ellos es var√≥n</u>.\n",
    "\n",
    "La diferencia de decir entre el hijo mayor es var√≥n, y uno de ellos es var√≥n, implica que en realidad no sabemos cu√°l de ellos es var√≥n.\\\n",
    "Aunque escape de la intuici√≥n, este peque√±o cambio genera una diferencia en el espacio muestral, y lo demostraremos en la matriz para que se pueda apreciar el cambio del enunciado 2.\n",
    "\n",
    "$$\n",
    "\\begin{matrix}\n",
    "    \\begin{matrix}\n",
    "        M \\\\F \\\\\n",
    "    \\end{matrix}\n",
    "    \n",
    "    \\begin{vmatrix}\n",
    "        [FM] & [MM]  \\\\\n",
    "        FF & [MF]  \\\\\n",
    "    \\end{vmatrix} \\\\\n",
    "    \n",
    "    \\begin{matrix}& F & & M     \n",
    "    \\end{matrix}\n",
    "\\end{matrix}\n",
    "$$\n",
    "\n",
    "El hecho de decir que, uno de ellos es el var√≥n, representan 3 posibles estados en el espacio muestral, porque en cada uno de los ejes, al menos uno de los hijos es var√≥n.\n",
    "\n",
    "Cuando escribimos esto en la probabilidad, decimos, que la probabilidad de que ambos hijos sean varones, sabiendo que alguno de ellos es var√≥n es de un estado exitoso sobre tres posibles estados:\n",
    "\n",
    "$\\displaystyle{P(MM \\, | \\, \\text{alguno M}) = \\frac{1}{3} = 33.\\hat{3}\\%}$\n",
    "\n",
    "As√≠ podemos demostrar que las posibilidades de la situaci√≥n 1 y 2 son diferentes, aunque parezcan igual y se debe a que la cantidad de informaci√≥n que contiene cada frase debido a esa sutileza gramatical es diferente y esto determina distintos resultados en probabilidad.\\\n",
    "Donde en la situaci√≥n 1 la probabilidad de que los dos hijos sean varones es mayor, debido a la mayor cantidad de informaci√≥n dada en el enunciado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El problema de Monthy Hall\n",
    "\n",
    "<img src=\"https://m.media-amazon.com/images/M/MV5BNjUxNjMyZmUtYWE4Yi00Mzg2LWJkZmYtY2YyNjQ4ZmIyMGQwL2ltYWdlXkEyXkFqcGdeQXVyMTIxMDUyOTI@._V1_.jpg\" width=\"400\">\n",
    "\n",
    "En nuestra segunda paradoja trataremos el caso del programa de televisi√≥n *Let's make a deal*, dado por el conductor Monthy Hall, al que de se debe su nombre en probabilidad a esta paradoja, c√≥mo, **El problema de Monthy Hall**  \n",
    "\n",
    "El ejercicio consist√≠a en que el presentador le presentaba a un participante tres puertas, donde el participante ten√≠a que elegir una entre las tres posibles puertas, donde detr√°s de dos puertas no hab√≠a nada y solo en una hab√≠a un premio.\n",
    "\n",
    "En una situaci√≥n tradicional, el presentador le preguntar√≠a al participante que elija una puerta, entonces nos preguntariamos\n",
    "\n",
    "**¬øCual es la posibilidad de que el participante elija la puerta correcta?**\n",
    "\n",
    "Siendo una probabilidad tradicional, dibujaremos el espacio muestral y veriamo todas las opciones, donde podremos ver que las tres opciones inicialmente, todas son igualmente probables, por lo tanto el participante piense que la probabilidad de elegir la puerta correcta sea de un tercio por la naturaleza de la situaci√≥n.\n",
    "\n",
    "$\\displaystyle{\\begin{vmatrix} P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\\begin{matrix}  \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\ \\longrightarrow 1/3 \\rightarrow 33.3\\% \\\\\\end{matrix}}$\n",
    "\n",
    "El truco del show era de que una vez que el participante eligiera una puerta, Monthy Hall abre una de las puertas (obviamente el presentador abrir√≠a una puerta sin recompensa, este era el punto de informaci√≥n adicional), luego de el presentador abriera la puerta sin recompensa, Monthy le preguntar√≠a al participante, que ahora cuenta de informaci√≥n adicional (la puerta que abri√≥ Monthy):\n",
    "\n",
    "Ahora que sabe que esta puerta no ten√≠a recompensa, ¬ømantiene la puerta que eligi√≥, o prefiere cambiar de puerta?\n",
    "\n",
    "Entonces, la intuici√≥n a primera vista nos hace decir:\n",
    "\n",
    "¬øCual es la probabilidad de que cambie de puerta y gane? o ¬øCu√°l es la probabilidad de que mantenga la puerta y gane?\n",
    "\n",
    "Dibujemos el espacio muestral para representar esta idea de forma m√°s visual:\n",
    "\n",
    "Este ser√≠a muestral antes de elegir una puerta\n",
    "\n",
    "$\n",
    "\\begin{vmatrix}P1 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Entonces digamos que elegimos la puerta 1, y el presentador abri√≥ la puerta 3 ya que esta no tiene premio. El espacio muestral se nos restringir√≠a a las situaciones donde la puerta 3 no tiene premios, quedando tal que\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1 \\\\ 0 \\\\ 1 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2 \\\\ 1 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3 \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{matrix}  \\\\\\longrightarrow 1/2 = 50\\% \\\\ \\longrightarrow 1/2 = 50\\% \\\\\\end{matrix}\n",
    "$\n",
    "\n",
    "Donde el n√∫mero de estados posibles ya no es 3, sino 2, quedando la probabilidad de √©xito de un medio.\\\n",
    "Entonces el razonamiento es que al tener 2 opciones donde solo 1 es de √©xito y ambas tienen 50% de posibilidades de ser la correcta, el participante asume que da igual si mantiene la puerta o no, ya que en ambas tiene 50% de probabilidad de ganar. Este es el primer razonamiento que se podr√≠a hacer con la intuici√≥n natural de las probabilidades, pero la paradoja es que esto es **falso**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬øPor qu√© cambian las probabilidades?\n",
    "\n",
    "Pero... ¬øen realidad hay m√°s probabilidades de ganar si cambio la puerta una vez que el presentador haya descartado una?\n",
    "\n",
    "La respuesta es s√≠! Porque resultan en situaciones distintas, al igual que en el ejemplo anterior, las probabilidades pueden verse modificadas cuando hay una cambio en la cantidad de informaci√≥n disponible a la hora de tomar una decisi√≥n, y este cambio de informaci√≥n fue el hecho de que el presentador haya abierto la puerta, modificando la probabilidad de √©xito.\n",
    "\n",
    "Cambiemos el esquema mediante el cual ahora calcularemos nuestras nuevas probabilidades.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ 0 \\\\ 0 \\\\ (üèÜ) \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ 0 \\\\ (üèÜ) \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ (üèÜ) \\\\ 0 \\\\ 0 \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\   \\\\  \\\\    \\\\ \\end{vmatrix}\n",
    "\\hspace{1em}\n",
    "\\begin{matrix}   \\\\ üèÜ\\rightarrow \\text{premio} \\\\ üßî\\rightarrow \\text{participante} \\\\ üé§\\rightarrow \\text{presentador} \\\\ \\end{matrix}\n",
    "$\n",
    "\n",
    "\n",
    "En este nuevo diagrama consideraremos dos columnas nuevas, donde representar√° el caso de si mantenemos la misma puerta que elegimos, o el caso en que cambiemos la puerta sabiendo la informaci√≥n adicional que nos d√© el presentador.\n",
    "\n",
    "#### Situaci√≥n 1\n",
    "\n",
    "Entonces supongamos que elegimos la puerta 1 y el presentador abriera la puerta 2, ya que la 3 tiene el premio, por lo tanto no la abrir√≠a.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî   \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§   \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ   \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\    \\\\ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\    \\\\ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "¬øQue suceder√≠a en esta situaci√≥n?\n",
    "\n",
    "En esta situaci√≥n, si me mantuviera en la puerta 1, que es la que elegimos al principio, no ganariamos el premio, pero si la cambiamos al a puerta 3, entonces si lo ganariamos. Quedando el diagrama tal que: \n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚ùå \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚úÖ \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Situaci√≥n 2\n",
    "\n",
    "\n",
    "Sigamos usando el mismo razonamiento con el siguientes caso, donde abrimos la puerta 1, y el presentador tendr√° que abrir la puerta 3, ya que en la puerta 2 se encuentra el premio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\  üßî  \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\  üèÜ  \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  üé§  \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\  ‚ùå  \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\  ‚úÖ  \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Donde si me quedo con la puerta que eleg√≠ perder√≠a, pero si la cambiara, ganaria.\n",
    "\n",
    "#### Situaci√≥n 3\n",
    "\n",
    "Y en la ultima situacion, seria que abriera la puerta 1 que contiene el premio, y daria igual la puerta que abriera el presentador, ya que ni la puerta 2 y 3 tienen premio, siendo el √∫nico caso donde si mantengo la puerta ganaria.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\  0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚úÖ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚ùå \\end{vmatrix}\n",
    "$\n",
    "\n",
    "#### Resoluci√≥n\n",
    "\n",
    "Estas son las situaciones que tendr√≠amos que tener en cuenta para saber ¬øCual es la probabilidad de ganar si me quedo con la misma puerta?\n",
    "\n",
    "Para saber esto veamos la matriz completa de todas las situaciones que vimos en el ejercicio.\n",
    "\n",
    "$\n",
    "\\begin{vmatrix} P1       \\\\ üßî \\\\ üßî \\\\ üèÜ \\end{vmatrix}\n",
    "\\begin{vmatrix} P2       \\\\ üé§ \\\\ üèÜ \\\\ üé§ \\end{vmatrix}\n",
    "\\begin{vmatrix} P3       \\\\ üèÜ \\\\ üé§ \\\\ 0 \\end{vmatrix}\n",
    "\\begin{vmatrix} Mantener \\\\ ‚ùå \\\\ ‚ùå \\\\ ‚úÖ \\end{vmatrix}\n",
    "\\begin{vmatrix} Cambiar  \\\\ ‚úÖ \\\\ ‚úÖ \\\\ ‚ùå \\end{vmatrix}\n",
    "$\n",
    "\n",
    "Si nos hubi√©ramos quedado con la misma puerta que elegimos al principio, solo en un caso hubi√©ramos tenido la probabilidad de ganar de los tres casos, quedando tal que:\n",
    "\n",
    "$\\displaystyle{P(üèÜ|Mantener)= \\frac{1}{3}}$\n",
    "\n",
    "Pero a diferencia de si hubi√©ramos cambiado de puerta luego de la informaci√≥n adicional dada por el presentador, tendr√≠amos dos casos de eventos exitosos contra los tres que ten√≠amos.\n",
    "\n",
    "$\\displaystyle{P(üèÜ|Cambiar)= \\frac{2}{3}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusi√≥n\n",
    "\n",
    "Con estos dos ejercicios demostramos que el c√°lculo de probabilidades, no siempre es intuitivo y que hay tener cuidado al entender cual es el espacio muestral sobre cual estamos trabajando, dado que tengamos informaci√≥n adicional, o no, sobre cierta situaci√≥n a la cual realizaremos el c√°lculo de probabilidades.\n",
    "\n",
    "Con estos dos ejercicios dimos el inicio para desarrollar nuestra intuici√≥n probabil√≠stica!\n",
    "\n",
    "[Video explicativo Monthy Hall - Javie Santaolla](https://www.youtube.com/watch?v=1BpTBzDQuRE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 3: Distribuciones de probabilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es una distribuci√≥n? \n",
    "\n",
    "**¬øQu√© es una distribuci√≥n de probabilidad?**\n",
    "\n",
    "**Es una funci√≥n**, en el sentido matem√°tico del c√°lculo, **donde a cada uno de los posibles estados de una variable aleatoria dentro del espacio muestral**, se le asigna una probabilidad.\n",
    "\n",
    "Como ejemplo tenemos el ejercicio del dado que tiene un espacio muestral de 6 posibles estados, y cada uno de esos estados tiene una probabilidad de \\frac{1}{6},  en este caso esta distribuci√≥n ser√≠a una funci√≥n constante, donde a cada estado se le asigna un valor, siendo la misma, una funci√≥n discreta.\n",
    "\n",
    "En general **mencionaremos a la $X$ may√∫scula como una variable aleatoria**, donde **$P$, ser√° la funci√≥n**, que a cada una de las ocurrencias o valores posibles de esta variable aleatoria, se le asignar√° un n√∫mero que denominaremos la probabilidad.\n",
    "\n",
    "\n",
    "$X \\, aleatoria \\longrightarrow \\underbrace{P(X = x)}_\\text{probabilidad de ocurrencia}$\n",
    "\n",
    "De esta manera comprendemos que **$P$ es funci√≥n de la variable aleatoria**\n",
    "\n",
    "$P=f(X)$\n",
    "\n",
    "Una convenci√≥n en probabilidad, es que, las **letras may√∫sculas denotan las variables**, mientras que las **letras min√∫sculas denotar los posibles valores que estas variables aleatorias pueden tomar**.\n",
    "\n",
    "$X \\rightarrow \\text{variable aleatoria}$\\\n",
    "$x \\rightarrow \\text{valores posibles en el espacio muestral}$\n",
    "\n",
    "Al igual que sucede en el c√°lculo, las funciones poseen un Dominio.\n",
    "\n",
    "El dominio viene por **todos los valores posibles de la variable aleatoria por la cual la funci√≥n puede ser calculada**, donde estos dominios podr√°n as√≠ dividirse en conjuntos discretos o continuos, **donde tendremos tanto funciones discretas o funciones continuas.**\n",
    "\n",
    "$\n",
    "Dom(X) = \n",
    "     \\begin{cases}\n",
    "        Discreto, &\\quad \\{1,2,3,4,5,6\\} \\\\\n",
    "        \\\\\n",
    "        Continuo,  &\\quad [0,\\infty] \\\\\n",
    "     \\end{cases}\n",
    "$\n",
    "\n",
    "[Articulo dedicado a Funciones Matematicas para Ciencias de Datos](https://deepnote.com/@mazzaroli/Introduccion-a-Funciones-Matematicas-para-Data-Science-e-Inteligencia-Artificial-f9a47b52-0308-4e95-a3d3-c3de3ef7b14f)\n",
    "\n",
    "Un ejemplo de una distribuci√≥n discreta podr√≠a usarse de ejemplo el juego de los dados, porque los valores tienen un n√∫mero finito de estados, donde tenemos a las 6 caras del dado, y la variable aleatoria ser√≠a la cara que me dar√≠a el dado como resultado. \n",
    "\n",
    "A diferencia de las variables aleatorias que pueden ser continua, por ejemplo, la temperatura, ya que puede considerarse como una variable aleatoria y es continua, porque no precisa necesariamente tener que ser un n√∫mero entero, sino, que puede ser un valor decimal cualquiera dentro de un rango definido.\n",
    "\n",
    "Profundizaremos sobre los aspectos matem√°ticos de estas funciones particulares, que llamamos distribuciones de probabilidad:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribuci√≥n de Probabilidad\n",
    "\n",
    "Coincidiremos a $X$ mayuscula como una variable aleatoria donde $P$ de $X$, ser√° una \n",
    "funci√≥n de distribuci√≥n de probabilidad, o tambi√©n conocida como [**densidad de probabilidad**](https://es.wikipedia.org/wiki/Funci%C3%B3n_de_densidad_de_probabilidad)\n",
    "\n",
    "$\\displaystyle{X \\rightarrow P(X) \\rightarrow \\text{densidad de probabilidad}}$\n",
    "\n",
    "Donde **$P(X)$ puede tener un car√°cter discreto o un car√°cter continuo**, que estar√°n determinados por los valores posibles de la variable aleatoria $X$\n",
    "\n",
    "$\n",
    "P(X) \n",
    "    \\begin{cases}\n",
    "    Discreto\\\\\n",
    "    \\\\\n",
    "    Continuo\\\\\n",
    "    \\end{cases}\n",
    "$\n",
    "\n",
    "Como toda funci√≥n, se puede graficar, as√≠ que cuando una distribuci√≥n de probabilidad es continua, podemos describirlo como una distribuci√≥n gaussiana en un plano de ejes cartesianos, donde dado un punto $x$ ($x$ min√∫scula = ocurrencia de un valor espec√≠fico dentro del conjunto de variables), la imagen, dada la funci√≥n, es la probabilidad de que ocurra ese valor particular\n",
    "\n",
    "<img src='./img/dist normal.png' width='300'>\n",
    "\n",
    "Y como toda funci√≥n en calculo, la podemos derivar o integrar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integral de una distribuci√≥n\n",
    "\n",
    "**¬øQu√© significa la integral de una distribuci√≥n?**\n",
    "\n",
    "Al igual que podemos preguntarnos _¬øCu√°l es la probabilidad de que la variable tenga un valor en particular?_ que seria haciendolo con la funci√≥n de densidad de probabilidad.\n",
    "\n",
    "$P(X=x)=?$\n",
    "\n",
    "Tambi√©n podemos preguntarnos ¬ø**Cu√°l es la probabilidad de que mi variable aleatoria tenga valores menores o iguales que un valor espec√≠fico dado?**\n",
    "\n",
    "$P(X\\leq x)=?$\n",
    "\n",
    "Para calcular esto, debemos recordar los conceptos de c√°lculo integral, donde ser√≠an todos los valores que se encuentre por detr√°s del valor umbral, y esto es lo que llamamos en c√°lculo, un √°rea bajo la curva\n",
    "\n",
    "<img src='./img/area curva.png' width='300'>\n",
    "\n",
    "As√≠ es como sabemos que este tipo de probabilidades ($P(X\\leq x)$) est√°n dadas por una integral en funci√≥n de la distribuci√≥n.\\\n",
    "Donde decimos que la probabilidad de que mi variable aleatoria tome valores menores o iguales que un cierto valor espec√≠fico, est√° dado por la integral de mi distribuci√≥n de probabilidad $P$ de $X$, respecto a la variable de $X$, integrando sobre todos los posibles valores que sean menores o igual que $x$.\n",
    "\n",
    "$\\displaystyle{P(X\\leq x) = \\int\\limits_{X\\leq x}P(X)dX}$\n",
    "\n",
    "Esto es una integral, es el √°rea debajo de la curva y tambi√©n representa una probabilidad.\n",
    "\n",
    "En general decimos **cuando $x$ min√∫sculo no es un valor num√©rico**, sino, un valor cualquiera dado que p**uede considerarse como un par√°metro, esto determinar√°** una nueva funci√≥n que llamamos **la Distribuci√≥n Acumulada** $C(X)$\n",
    "\n",
    "$\\displaystyle{P(X\\leq \\underbrace{x}_{parametro}) = \\int\\limits_{X\\leq x}P(X)dX}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Funci√≥n de distribuci√≥n acumulada\n",
    "\n",
    "Entonces decimos que **la distribuci√≥n acumulada, representa la probabilidad de que mi variable aleatoria tome valores menores o iguales que esta $x$ dada, lo que llamamos una funci√≥n de probabilidad acumulada.**\n",
    "\n",
    "$\\displaystyle{P(X\\leq \\underbrace{x}_{parametro}) = \\int\\limits_{X\\leq x}P(X)dX = C(x) \\longleftarrow Funci√≥n \\, Probabilidad \\, Acumulada}$\n",
    "\n",
    "**La interpretaci√≥n de la funci√≥n de probabilidad acumulada, es la integral de la funci√≥n de densidad de probabilidad.**\\\n",
    "**Y sirve para** responder el tipo de preguntas que surgen cuando no nos preguntamos por un valor en particular de la probabilidad, sino, **cuando nos referimos a un rango dentro de la probabilidad**, por ejemplo:\n",
    "\n",
    "**¬øCual es la probabilidad de que al tirar un dado el resultado sea un n√∫mero menor o igual a x?**\n",
    "\n",
    "Por ejemplo, cu√°l es la probabilidad de que al tirar un dado el resultado sea un n√∫mero menor o igual al 2, *donde este ejemplo espec√≠ficamente se trata de una funci√≥n discreta*.\n",
    "\n",
    "**La funci√≥n de probabilidad acumulada tambi√©n se utiliza para funciones discretas**, solo que en este caso, la gr√°fica en el plano cartesiano ya no se ver√≠a como una curva suave, sino, como un histograma.\\\n",
    "Donde cada una de sus caras tendr√° una probabilidad, que ser√≠a la frecuencia con la que ocurrir√≠a cada uno de estos eventos.\n",
    "\n",
    "<img src='./img/histograma.png' width='300'>\n",
    "\n",
    "**Cuando queremos calcular la probabilidad acumulada de una funci√≥n discreta**, porque queremos responder la misma pregunta sobre ¬øCu√°l es la probabilidad de que mi variable aleatoria tomar√° valores menores o iguales de cierto valor? **ya no se usar√≠an integrales, sino, sumas discretas**, donde sum√≥ todas las probabilidades en las que mi variable aleatoria tenga los valores menores o iguales al par√°metro de referencia. \n",
    "\n",
    "$\\displaystyle{P(X\\leq x) = \\sum_{X\\leq{x}}P(X) \\longrightarrow Funci√≥n \\, Probabilidad \\, Acumulada}$\n",
    "\n",
    "Esta tambi√©n forma parte de la definici√≥n de **Probabilidad Acumulada**, pero es la funci√≥n para los casos de **funciones discretas.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reto\n",
    "\n",
    "Desarrolla una expresi√≥n matem√°tica para el siguiente caso:\n",
    "\n",
    "¬øCual es la probabilidad de que mi variable aleatoria tome valores entre dos umbrales?\n",
    "\n",
    "$P(a \\leq X \\leq b)=?$\n",
    "\n",
    "Pista:\\\n",
    "Consideramos este caso como una <u>variable aleatoria continua</u>, donde tengo el umbral entre a y b\n",
    "\n",
    "<img src='./img/integral.png' width='300'>\n",
    "\n",
    "### Soluci√≥n\n",
    "\n",
    "$\\displaystyle{P(a \\leq X \\leq b)\\hspace{1em}=\\hspace{1em} \\int\\limits^{b}_{a}P(X)dx\\hspace{1em}=\\hspace{1em}P(b)-P(a)\\hspace{1em}=\\hspace{1em}C(X)}$\n",
    "\n",
    "### Conclusi√≥n\n",
    "\n",
    "**La probabilidad** es un campo que **depende** mucho **de los elementos del c√°lculo**, porque esas funciones que nos permiten determinar probabilidades sobre los diferentes estados de una variable aleatoria, son espec√≠ficamente las que definimos en el c√°lculo sobre un punto de vista matem√°tico, **tales como sus propiedades matem√°ticas de derivacion e integracion que se aplican sobre funciones normales en c√°lculo, pueden ser aplicadas en probabilidad.**\\\n",
    "En el caso particular de la distribuci√≥n de distribuci√≥n acumulada, que es la integral de la funci√≥n de la densidad de probabilidad.\n",
    "\n",
    "Pero no te asustes! porque estas son las bases para que entiendas los mecanismos detr√°s del c√°lculo de probabilidad, pero en la pr√°ctica, pasaremos al c√≥digo con Python para desarrollar esto como lo har√≠a todo un cient√≠fico de datos!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones discretas \n",
    "\n",
    "Profundizaremos en como trabajar con distribuciones discretas, tales como el lanzamiento de monedas y dados, donde para este tipo de ejercicios, surge de manera natural la **distribucion de Bernoulli**.\n",
    "\n",
    "### Distribucion de Bernoulli\n",
    "\n",
    "Una distribucion de Bernulli es una funcion que asigna a la variable binaria dos valores, cuando $X$ sea igual a 1 (exito) ocurre con la probabilidad $p$, donde p valdria 0,5 dado un caso de probabilidad equilibrada, y cuando $X$ sea igual a 0 (fracaso) se representa con la con la probabilidad de $1 - p$, porque la suma de las probabilidades tiene que dar el 100%.\\\n",
    "Se dice que la variable aleatoria $X$, de distribuye como una Bernoulli de parametro $p$ con $0 <p < 1$\n",
    "\n",
    "#### Formula de Bernoulli\n",
    "$\n",
    "P(X=1)=p\\\\\n",
    "P(X=0)=1-p\\\\\n",
    "0<p<1\n",
    "$\n",
    "\n",
    "Desde la definicion de esta funcion, podemos empezar a considerar situaciones mas complejas con base al ejercicio de lanzar monedas, pero... no te preguntas sobre ¬øcomo podemos hacer mas complejo lanzar una moneda?, si solo hay 2 posibilidades del 50%, la respuesta es lanzar una $n$ cantidad de monedas, 2, 3, 4 o las que yo quiera.\n",
    "\n",
    "Por lo tanto decimos que cuando tenemos secuencias repetitivas de eventos binarios (eventos tipo Bernulli), es cuando tenemos que hablar de la famosa **Distribucion binomial**, entonces en este punto es cuando empezaremos a desarrollar sus pasos precedentes, hasta poder entender de forma natural y sencilla dobre como surgen de manera fundamental las distribuciones binomiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo Distribuci√≥n Bernoulli\n",
    "\n",
    "##### Caso 1\n",
    "\n",
    "Podemos decir que tenemos tres monedas que lanzaremos 1 vez cada una o que lanzaremos la misma moneda tres veces, donde la probabilidad de que obtengamos cara y cruz en cada lanzamientos es igualmente probable en ambos casos. \n",
    "\n",
    "Entonces nos preguntamos:\n",
    "\n",
    "**¬øCual es la probabilidad de 3 lanzamientos de una monedas, en 2 de esos 3 lanzamientos obtengamos cara?**\n",
    "\n",
    "Al graficar y contar las combinaciones, vemos que existen 8 posibles escenarios al lanzar las monedas:  \n",
    "\n",
    "<img src='./img/moneda.png' width='350'>\n",
    "\n",
    "Asi sabemos que trabajamos con un espacio muestral de 8 posibilidades, y de esas 8 solo en 3 casos obtendriamos 2 caras. \n",
    "\n",
    "<img src='./img/caras.png' width='350'>\n",
    "\n",
    "Por lo tanto decimos que la probabilidad de lanzar 3 veces una moneda y obtener 2 caras es de:\n",
    "\n",
    "$\\displaystyle{P(2\\,Caras|3\\, Lanzamientos)=\\frac{3}{8}}$\n",
    "\n",
    "Asumimos en esta situacion que la probabilidad de obtener cara o cruz, es igualmente probable en cada lanzamiento, porque esta es la hipotesis con la que hemos trabajado desde el principio del articulo, donde decimos que hay probabilidades fundamentales que son axiomaticas y por lo tanto asumimos que son igualmente probable.\\\n",
    "Pero en caso de la distribucion de Bernulli, cuando esto no sucede, definimos el numero $p$ minuscula, que asigna la probabilidad de uno u otro suceso.\n",
    "\n",
    "*En la vida real este parametro se ajusta acorde los datos que obtengamos en practica de X experimento.* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Caso 2\n",
    "\n",
    "Si complejizamos el caso de la distribucion binomial, donde ya no nos preguntandonos por 3 lanzamientos de monedas, sino, por $n$ lanzamientos, donde $n$ podria ser un numero muy grande, y de esos $n$ lanzamientos, podemos tener $k$ caras, que es la variable donde definiremos cuantas caras queremos tener segun el numero $n$ de lanzamientos.\n",
    " \n",
    "$\\displaystyle{P(K=Caras\\;|\\;n=Lanzamientos)=?}$\n",
    "\n",
    "En este punto vemos que la formula se complejiza, ya que mientras mas lanzamientos haya, el espacio muestral $(EM)$ crece de manera mayor que la exponencial.\n",
    "\n",
    "[Calcular espacio muestral para una n cantidad de probabilidades](https://es.wikipedia.org/wiki/Espacio_muestral#Procesos_estoc%C3%A1sticos_finitos_y_diagramas_de_%C3%A1rbol)\n",
    "\n",
    "Entonces en este punto nos preguntamos:\n",
    "\n",
    "**¬øExiste alguna formula general para contar todos estos posibles estados y sobre ellos hacer el conteo de probabilidades?**\n",
    "\n",
    "La respuesta es claro que si, de esto es lo que se trata especificamente <u>la funcion de distribucion binomial.</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduccion a la distribucion binomial\n",
    "\n",
    "Volviendo a nuestro problema de los 3 lanzamientos de una moneda, usaremos la letra $k$ para definir el numero de caras o sucesos exitosos, que queremos obtener a partir de  los $n$ lanzamientos.\n",
    "\n",
    "Veamos como seria la distribucion binomial de este problema, donde ya sabemos que es binomial, pero...\n",
    "\n",
    "**¬øque quiere decir que una distribucion sea binomial exactamente?**\n",
    "\n",
    "Graficamente sabemos que cuando una [distribucion es discreta](https://es.wikipedia.org/wiki/Distribuci%C3%B3n_de_probabilidad#Distribuciones_de_variable_discreta), la grafica tendra forma de un [diagrama de barras o histograma](https://es.wikipedia.org/wiki/Histograma), donde cada barra representa la [frecuencia relativa](https://es.wikipedia.org/wiki/Frecuencia_estad%C3%ADstica#Frecuencia_relativa) de un evento posible en el eje X.\n",
    "\n",
    "Entonces decimos que los eventos posibles son los resultado que podemos obtener de de cada lanzamiento: **0 caras, 1 cara, 2 caras y como maximo 3 caras**.\\\n",
    "Estas son las 4 posibilidades sobre las que podemos calcular las frecuencias relativas.\n",
    "\n",
    "<img src='./img/barras.png' width='300'>\n",
    "\n",
    "De todos los eventos, sabemos que tenemos 8 posibilidades, que seria nuestro espacio muestral.\n",
    "\n",
    "<img src='./img/monedabinomial.png' width='300'>\n",
    "\n",
    "\n",
    "Entonces... **¬øCuantas opciones del E.M resultan en 0 caras, en 1 cara, 2 caras y 3 cars?**\n",
    "\n",
    "Como vemos en el grafico del espacio muestral, solo en un caso tenemos 0 caras, en 3 casos tenemos 1 y 2 caras, y en solo un caso tenemos 3 caras.\\\n",
    "Quedando la probabilidad quedaria tal que:\n",
    "\n",
    "Donde:\\\n",
    "$\\displaystyle{P(k= cara ,\\; n= lanzamientos) = \\frac{k}{EM}}$\n",
    "\n",
    "$\n",
    "\\displaystyle{P(0,3) = \\frac{1}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(1,3) = \\frac{3}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(2,3) = \\frac{3}{8}} \\hspace{3em}\n",
    "\\displaystyle{P(3,3) = \\frac{1}{8}}\n",
    "$\n",
    "\n",
    "\n",
    "<img src='./img/monedabinomialposibilidades.png' width='800'>\n",
    "\n",
    "De esta forma podemos reflejar el concepto de como se veria la distribucion binomial para este caso en particular."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combinatorio o Coeficiente binomial\n",
    "\n",
    "Volviendo a la pregunta inicial.\n",
    "\n",
    "**¬øExiste alguna formula general para contar todos estos posibles estados y sobre ellos hacer el conteo de probabilidades?**\n",
    "\n",
    "Y como ya mencionamos antes, si disponemos una formula general! \n",
    "\n",
    "En matem√°ticas contamos con un elemento que son los [coeficientes binomiales, **n√∫meros combinatorios** o combinaciones](https://es.wikipedia.org/wiki/Coeficiente_binomial) son n√∫meros estudiados en [matematicas combinatoria](https://es.wikipedia.org/wiki/Combinatoria) que corresponden al n√∫mero de formas en que se puede extraer subconjuntos a partir de un conjunto dado.\\\n",
    "**El numero combinatorio $\\binom{n}{k}$ es el numero de subconjuntos $k$ elementos que satisfacen algun requisito de un conjunto con $n$ elementos, y el subconjunto $k$ tiene que ser menor que el conjutno $n$.**\n",
    "\n",
    "#### **Formula del Combinatorio:**\n",
    "\n",
    "$\\displaystyle C_{n}^{k} = \\binom {n}{k}=\\frac {n!}{k!\\cdot (n-k)!}$\n",
    "\n",
    "donde:\\\n",
    "$\n",
    "n = \\text{numero de intentos} \\\\\n",
    "k = \\text{numero de aciertos} \\\\\n",
    "r \\leq n \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejemplo Combinatorio o Coeficiente binomial\n",
    "\n",
    "Ahora que sabemos que existe una manera de contar de forma general todos los posibles estados dentro de un espacio muestral, pasaremos con un ejemplo para ver como nos ayuda a conocer la probabilidad de exito donde:\n",
    "\n",
    "**Queremos obtener la probabilidad de obtener $\\pmb{k}$ veces cara, dado $\\pmb{n}$ lanzamientos.**\n",
    "\n",
    "donde:\\\n",
    "$n = 3$\\\n",
    "$k = 1$\n",
    "\n",
    "Donde la probabilidad quedaria tal que:\n",
    "\n",
    "$P(1,3)=?$\n",
    "\n",
    "Usando el Combinatorio pasaremos a contar los posibles estados de exito de obtener 1 cara dado 3 lanzamientos de una moneda quedando tal que:\n",
    "\n",
    "$\\displaystyle\n",
    "P(k,n) \\rightarrow C^{n}_{k}\n",
    "$\n",
    "\n",
    "Donde sabemos que $n$ es el numero de lanzamientos que son 3 y $k$ seria el numero de exitos dado $n$ que es 1:\n",
    "\n",
    "${\\displaystyle P(1,3) \\longrightarrow C^{3}_{1} = {\\binom {3}{1}} = {\\frac {3!}{1!\\cdot (3-1)!}} = {\\frac {1*2*3}{1* 1*2}} = {\\frac {\\cancel{1}*\\cancel{2}*3}{\\cancel{1}*\\cancel{2}}} = 3}$\n",
    "\n",
    "Asi es como sabemos las las posibles manera de obtener este resultado, que es 3.\n",
    "\n",
    "Por ultimo decimos que la probabilidad esta dada por el resultado del combinatorio entre el espacio muestral total, que es 8, ya que son todos los estados posibles de lanzar 3 veces una moneda.\n",
    "\n",
    "${\\displaystyle P(k,n) = \\frac{C}{EM} \\longrightarrow P(3,1) = \\frac{3}{8}}$\n",
    "\n",
    "Entonces vemos que a traves de la formula combinatoria somos capaces de contar los estados dado dicho evento y lo podemos demostrar, comparando el resultado que obtivimos con el grafico de la distribucion binomial que realizamos anteriormente, donde la barra que reflejaba la probabilidad de obtener 1 cara de 3 lanzamientos de una moneda era de $\\frac{3}{8}$.\n",
    "\n",
    "Asi a traves del simbolo combinatorio que nos permite contar los estados posibles, podemos desarrollar el calculo de conteo de probabilidades, de esta manera dando paso a la introduccion de la formula general de Distribucion Binomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribucion Binomial\n",
    "\n",
    "Definimos a la distribuci√≥n binomial o distribuci√≥n bin√≥mica como una distribuci√≥n de probabilidad discreta que cuenta el n√∫mero de √©xitos en una secuencia de ${\\displaystyle n}$ ensayos de Bernoulli independientes entre s√≠, con una probabilidad fija ${\\displaystyle p}$ de ocurrencia de √©xito entre los ensayos.\n",
    "\n",
    "Decimos que la probabilidad de un suceso particual, es igual al numero de estados que conducen a ese suceso, multiplicado por la probabilidad de cada estado individual:\n",
    "\n",
    "$p \\rightarrow suceso \\rightarrow  p *  estados \\, suceso $\n",
    "\n",
    "Usando el ejemplo de las monedas:\n",
    "\n",
    "Donde sabemos que el numero 3 son los estados exitosos que obtivimos a partir del combinatorio $C^n_k$ y la probabilidad de individual de cada uno de los estados es de $\\frac{1}{8}$.\n",
    "\n",
    "Quedandonos el resultado tal que:\n",
    "\n",
    "${\\displaystyle  p =\\frac{1}{8} * 3 = \\frac{3}{8}}$\n",
    "\n",
    "\n",
    "Estas probabilidades estarian dadas por la formula general que desarremos don podemos "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desarrollo formula Distribucion Binomial \n",
    "\n",
    "Cuando tengamos una probabilidad que dados de $n$ intentos, y queramos obtener $k$ resultados, el numero de estados exitosos es igual a $n$ combinado $k$.\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k}}$\n",
    "\n",
    "Esto lo que quiere decir es que de una $n$ cantidad de estados, solo habra una cantidad $k$ de estados que satifasgan los resultados deseados y cada estado $k$ tendra una probabilidad $p$\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "De lanzar una $n$ cantidad de monedas, solo habra una $k$ cantidad que caiga en cara, donde cada una de esas $k$ monedas tendra una probabilidad $p$.\n",
    "\n",
    "$\\displaystyle{\\overbrace{\\underbrace{coin}_k ,\\underbrace{coin}_k ,\\underbrace{coin}_{\\underbrace{k}_p},\\cdots ,coin ,coin ,coin,coin}^{n}}$\n",
    "\n",
    "Asumimos que p para el caso ideal tendria una probabilidad de 1/2, pero puede que esto no sea asi, asi que denotamos la letra $p$ por si las probabilidades no se encuentran balanceadas y multiplicamos la probabilidad de cada uno de estos eventos, que seria la probabilidad e la primera moneda, por la probabilidad de la segunda, la tercera y asi considerando a todas las $k$, que seria equivalente a elevar la probabilidad $p$ a la $k$.\n",
    "\n",
    "$\n",
    "p(k_1) \\hspace{0.5em} * \\hspace{0.5em}\n",
    "p(k_2) \\hspace{0.5em} * \\hspace{0.5em}\n",
    "\\dots* \\hspace{0.5em} * \\hspace{0.5em}\n",
    "p(k_n) \\hspace{0.5em} = \\hspace{0.5em}\n",
    "p^k\n",
    "$\n",
    "\n",
    "Quedando la formula general tal que:\n",
    "\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k} p^{k} }$\n",
    "\n",
    "\n",
    "Si la probabilidad de que el evento individual exito es p, decimos que la probabilidad del evento fallido es $q=1-p$ tal cual vimos en la distribucion de bernulli.\n",
    "\n",
    "$\\displaystyle{P(k,n) = \\binom{n}{k} p^{k} q}$\n",
    "\n",
    "De misma manera debemos descubrir la probabilidad de cada evento no exitoso, lo cual resolvemos multiplicando la probabilidad de cada uno de estos e igualmente seria equivalente a elevar $q$ por el numero de todos los eventos no exitosos.\n",
    "\n",
    "Para saber cuantos eventos fallidos quedaron, simplemente tenemos que restarle a la totalidad de eventos $n$ realizados, la cantidad de eventos exitosos $k$. \n",
    "\n",
    "$\\displaystyle{\\overbrace{\\underbrace{coin ,coin ,coin }_{k},\\underbrace{\\cdots ,coin ,coin ,coin,coin}_{n-k}}^{n}}$\n",
    "\n",
    "Por lo tanto la probabilidad de fracaso quedaria elevado a la n-k \n",
    "\n",
    "Quedandonos la formula tal que:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formula de Distribucion Binomial\n",
    "\n",
    "${\\displaystyle P(X) = {\\binom {n}{k}p^{k}q^{n-k}} = {\\frac {n!}{k!\\cdot (n-k)!}\\,p^{k}q^{n-k}} }$\n",
    "\n",
    "Y asi es como damos a la formula de la Distribucion Binomial\n",
    "\n",
    "donde:\\\n",
    "$n = \\text{numero de intentos}$\\\n",
    "$k = \\text{numero de aciertos}$\\\n",
    "$p = \\text{probabilidad de exito en un intento}$\\\n",
    "$q = (1-p) \\hspace{0.5em} \\text{probabilidad de fracaso en un intento}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Asi es como definimos a la distribucion binomial, como, una distribucion o funcion de densidad de probabilidad, donde podemos calcular de una secuenccia de eventos de tipo bernuli cuantos exitos puedo tener de variables binarias.\n",
    "\n",
    "- $\\displaystyle{P(k\\;caras\\;|\\;n\\;lanzamientos)}$\n",
    "\n",
    "- $\\displaystyle{P(k;n,p) = \\binom{n}{k}p^k(1-p)^{n-k}}$\n",
    "\n",
    "Esta no es la unica distribucion que podemos trabajar con variables aleatorias binarias ya que existen varias.\\\n",
    "Donde tambien existen casos de variables aleatorias discretas no binarias, como por ejemplo la distribucion multinomial, que es la generalizacion natural de la binomial.\n",
    "\n",
    "Formula general de Distribucion multinomial\n",
    "\n",
    "$\\displaystyle{P(X_1,\\cdots,X_n) = \\frac{n!}{k_1!,\\dots,k_n!}P_1^{k_1},\\dots,P_n^{k_n} }$\n",
    "\n",
    "No profundizaremos en la distribucion multinomial, porque lo importante es entender que existen otras distribuciones para variables discretas, ccon nombres interesantes que podras impactar y asustar a tus amigos con simplemente nombrarlas.\n",
    "\n",
    "Otras distribuciones\n",
    "\n",
    "- Poison\n",
    "- Hipergeometrica    \n",
    "- Geometrica\n",
    "- Binomial negativa\n",
    "- Gamma\n",
    "- Beta\n",
    " \n",
    "Entonces nos surge la duda de ?como sabremos cuando usar cada distribucion habiendo tantas? la verdad es que exiten ciertas experiencias, investigaciones y experimentos aleatorios donde cada una de estas distribuciones se aplican de manera optima.\n",
    "\n",
    "En el siguiente capitulo veremos que hay casos donde tenemos un conjunto de datos particular y no sabemos al comienzo su distribucion, aprenderemos que existen tecnicas para ajustar la mejor distribucion de probabilidad al conjunto de datos que tengamos.\n",
    "\n",
    "Ya que en la vida real no sabemos exactamente las distribuciones en probabilidad y en conjuntos de datos, sino que tendremos que aprenderlas y tendremos ayuda de algoritmos que aprenden las distribucion a partir de los datos, dando asi el inicio al Machine Learning probabilistico!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Usando la distribuci√≥n binomial "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distribuciones continuas "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øC√≥mo estimar una distribuci√≥n?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 4: MLE (Maximum Likelihood Estimation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ¬øQu√© es MLE? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLE en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresi√≥n logica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicaci√≥n de regrsi√≥n log√≠stica "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tema 5: Inferencia bayesiana\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teoremas de Bayes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes en machine learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusiones"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "642679db579c39e8c54388d8c67ee59d6b9479549eff357c7b1dae31a7261e66"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
